{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#home","title":"Home","text":"<p>This is the documentation of the GEOIT1501 project called \"Inclusive 3D Campus Map of TU Delft\" and hosted at https://inclusivecampusmap.bk.tudelft.nl.</p> <p></p> <p>The documentation of this project is split in multiple parts. You can find documentation about:</p> <ul> <li>General information about the data pipeline used in the project in Data Pipeline.</li> <li>General information about the expected structure of data used in the project in Data Structure.</li> <li>The Python code that is used to process and format the data is in Python.</li> <li>The JavaScript app used to make the map in JavaScript.</li> <li>The setup of the server that hosts the map in Server.</li> </ul> Outdoor view Floor plan of BK"},{"location":"blender_docs/","title":"Blender","text":""},{"location":"blender_docs/#blender","title":"Blender","text":"<p>This document explains how and where Blender was used throughout the completion of this project.</p>"},{"location":"blender_docs/#introduction-to-blender","title":"Introduction to Blender","text":"<p>Blender is a free and open-source program for the creation, manipulation and rendering of 3D data formats. Being free makes it an excellent choice for projects such as this one, as it ensures the software will be able for future groups. All of the operations performed using Blender are of a beginner level and only pertain to mesh creation and manipulation. This should allow somebody with no experience in Blender to perform these tasks with only a minimal amount of practice. The web is full of tutorials that should expedite this learning process.</p>"},{"location":"blender_docs/#3dbag-mesh-reconstruction","title":"3DBAG Mesh Reconstruction","text":"<p>One of the primary tasks that Blender was used for was the reconstruction of 3DBAG building meshes. Reconstructing these meshes ensures that they are geometrically valid and aesthetically pleasing. Additionally reconstructing the meshes allows for the inclusion of overhang elements, which are not present in 3DBAG meshes.</p> <p>This reconstruction process begins with importing the 3DBAG mesh of the relevant building, as it will act as a guide. For simple building it can be enough to trace the outline and then extrude to the appropriate height. For more complex shapes we recommend first blocking out the general structure, and then adding all necessary detail. It is important to strike a balance between accuracy and simplicity. Over-complicating the building meshes will increase visual clutter and make them harder to texture.</p>"},{"location":"blender_docs/#ifc-pdf-interior-export","title":"IFC / PDF Interior Export","text":"<p>Interior data was extracted from IFC files of the interiors, which are maintained by the CREFM. These files can be opened in Blender using the free addon: Bonsai. Once these files were imported, they were flattened into their 2D footprints, and sorted into the building, building-part, building-storey hierachy. The room geometry encoded in the IFC files were correctly labled with their space-ids, making it easy to link them to their respective cityjson objects when the GLTF file was loaded.</p> <p>In the event that IFC files are not available we also tested extracting geometry from floor plan PDF files. Opening these files into a program such as Adobe Illustrator can allow for the extraction of the room geometries as SVG elements. These can then be opened in Blender and exported as geometry. The downside of the method is that room labels are not present, meaning that every map element would need to be labled by hand. Furthermore this method was only tested for Adobe Illustrator which is not a free program.</p>"},{"location":"blender_docs/#additional-geometry","title":"Additional Geometry","text":"<p>Geometry for ramps, entrances / exits, mini-stairs and other features was modeled in Blender, using the building shells and floor plan PDFs to ensure that their size and locations were correct.</p>"},{"location":"blender_docs/#positioning-the-geometry","title":"Positioning The Geometry","text":"<p>Geometry that we exported from Blender was correctly positioned in regards to CRS 28992 (the standard Dutch one). This can be achieved in Blender by moving the geometry to the correct position before exporting. Using 3DBAG geometry as a guide during the modelling process will ensure that this happens smoothly, as these geometries are correctly placed with regards to the used CRS.</p> <p>It may be desirable to work on the geometry around the file origin, and only move it into the correct position when ready to export. Blender becomes unstable when working in positions that are extremely far removed from the origin.</p>"},{"location":"blender_docs/#future-work","title":"Future Work","text":"<p>Accurate texturing of the campus buildings was one of the features requested during the interviews. This can be done in Blender, as any textures and materials will be exported along with geometry when creating a GLTF file.</p>"},{"location":"data_pipeline/","title":"Data Pipeline","text":""},{"location":"data_pipeline/#data-pipeline","title":"Data Pipeline","text":"<p>This document will explain the data pipeline of the project, starting with the principles, up until the actual commands used to execute it. We call data pipeline the process that starts from the \"raw\" input data of the map (geometry and attributes) and ends up with the final formatted data ingested by the map using JavaScript.</p>"},{"location":"data_pipeline/#prerequisites","title":"Prerequisites","text":"<p>To be able to run the commands mentioned below, you first need to install the Python environment. Read python_scripts.md for more information.</p> <p>To learn more about the data structure and conventions used in this project, please read data_structure.md.</p>"},{"location":"data_pipeline/#explanations","title":"Explanations","text":"<p>The main goals of this data pipeline are:</p> <ol> <li>Combine different data:<ul> <li>From different sources</li> <li>In different formats</li> </ul> </li> <li>Format the data into a convenient format for the web app</li> </ol> <p>This means that the pipeline can be divided between three phases:</p> <ol> <li>Initial Processing: Different branches and processes format and combine parts of the data into similarly formatted data.</li> <li>Data Combination: The results of all branches are combined into one single coherent file.</li> <li>Final Formatting: This file is converted into a convenient input for the web app.</li> </ol> <p></p>"},{"location":"data_pipeline/#initial-processing","title":"Initial Processing","text":"<p>The initial data processing and formatting is subdivided between three different branches corresponding to the different kinds of data:</p> <ol> <li>3DBAG Geometry: When a building is simply represented with its outer shell from the 3DBAG and does not include any indoor data.</li> <li>Custom Geometry: When a building has custom geometry for the outer shell and potentially indoor data.</li> <li>Outdoor Data: All the outdoor data, defined by data that is not linked to any building.</li> </ol>"},{"location":"data_pipeline/#3dbag-geometry","title":"3DBAG Geometry","text":"<p>The command to load 3DBAG data is <code>load_3dbag</code> from <code>cli.py</code>. Since the 3DBAG only contains the outer shells of the buildings, the command can take attributes about the buildings and buildings' subdivisions. A number of columns need to be present in the attributes to be able to group 3DBAG objects together, assign them a new identifier, and skip buildings that come from other sources.</p> <p>Here is an example of running the command:</p> <pre><code># From python/\nuv run data-pipeline load_3dbag \\\n    &lt;input_cityjson&gt; \\\n    &lt;output_cityjson&gt; \\\n    -b &lt;csv_buildings_attributes_path&gt; \\\n    -s &lt;csv_buildings_subdivisions_attributes_path&gt; \\\n    -vv\n</code></pre>"},{"location":"data_pipeline/#custom-geometry","title":"Custom Geometry","text":"<p>The command to load the custom geometry is <code>load_custom_building</code> from <code>cli.py</code>. Since the custom geometry is expected to have been processed for this project, there are more requirements on the expected format. The expected input must be glTF, but the hierarchy of the scene does not matter, only the identifiers of the objects are important. The glTF file is not expected to have attributes (they will be ignored if there are any), as the attributes are joined from one or multiple CSV files. However, every object identifier should have a name following this convention: <code>&lt;object_unique_id&gt;.lod_&lt;lod&gt;</code> where:</p> <ul> <li><code>&lt;object_unique_id&gt;</code> must be:<ul> <li><code>&lt;Building&gt;</code> for a building,</li> <li><code>&lt;Building&gt;.&lt;Part&gt;</code> for a building part,</li> <li><code>&lt;Building&gt;.&lt;Part&gt;.&lt;Storey&gt;</code> for a storey,</li> <li><code>&lt;Building&gt;.&lt;Part&gt;.&lt;Storey&gt;.&lt;Room&gt;</code> for a room.</li> </ul> </li> <li><code>&lt;lod&gt;</code> is the level of detail, which can only be 0, 1, 2 or 3.</li> </ul> <p>So the outer shell of a building could be <code>08.lod_2</code> while the 2D footprint of a room in the same building could be <code>08.02.00.600.lod_0</code>. The loader automatically builds a hierarchy based on this numbering, and assigns the right types to each object. It also automatically creates the intermediate levels if they do not exist (so it is not a problem if there is no <code>08.02.lod_&lt;lod&gt;</code> in the file).</p> <p>Finally, to add attributes to the geometry CSV files are once again expected. The link with the geometry will be made based on their <code>&lt;object_unique_id&gt;</code> (without <code>.lod_&lt;lod&gt;</code>) in the glTF and in the specific column from the CSV file.</p> <p>Here is an example of running the command:</p> <pre><code># From python/\nuv run data-pipeline load_custom_building \\\n    &lt;input_glb&gt; \\\n    &lt;output_cityjson&gt; \\\n    -b &lt;building_attributes_path&gt; \\\n    -p &lt;building_parts_attributes_path&gt; \\\n    -s &lt;building_storeys_attributes_path&gt; \\\n    -r &lt;building_rooms_attributes_path&gt; \\\n    -u &lt;building_units_attributes_path&gt; \\\n    -g &lt;building_units_geometry_gltf_path&gt; \\\n    -vv\n</code></pre>"},{"location":"data_pipeline/#outdoor-data","title":"Outdoor Data","text":""},{"location":"data_pipeline/#data-combination","title":"Data Combination","text":""},{"location":"data_pipeline/#final-formatting","title":"Final Formatting","text":"<p>To split the content of a CityJSON file into the geometry in glTF and the attributes in CityJSON, we use the command <code>split_cj</code> from <code>cli.py</code>. The resulting glTF and CityJSON both store the structure of the file, with the same identifiers to be able to link them together.</p> <p>You can simply call it like this:</p> <pre><code># From python/\nuv run data-pipeline split_cj &lt;cityjson_input&gt; &lt;folder_output&gt;\n</code></pre>"},{"location":"data_pipeline/#actual-commands","title":"Actual Commands","text":""},{"location":"data_pipeline/#update-the-pipeline","title":"Update the Pipeline","text":"<ol> <li> <p>Go to <code>python</code>:</p> <pre><code>cd python\n</code></pre> </li> <li> <p>Process 3DBAG data:</p> <pre><code>uv run data-pipeline load_3dbag \\\n    ../threejs/assets/processing_input/bag_geometry/subset.city.json \\\n    ../threejs/assets/processing_output/3dbag.city.json \\\n    -b ../threejs/assets/processing_input/attributes/buildings.csv \\\n    -s ../threejs/assets/processing_input/attributes/subdivisions.csv \\\n    --overwrite \\\n    -vv\n</code></pre> </li> <li> <p>Process custom geometry:</p> <pre><code>uv run data-pipeline load_custom_building \\\n    ../threejs/assets/processing_input/custom_geometry/08.glb \\\n    ../threejs/assets/processing_output/08.city.json \\\n    -b ../threejs/assets/processing_input/attributes/buildings.csv \\\n    -p ../threejs/assets/processing_input/attributes/parts.csv \\\n    -s ../threejs/assets/processing_input/attributes/storeys.csv \\\n    -r ../threejs/assets/processing_input/attributes/rooms.csv \\\n    -u ../threejs/assets/processing_input/attributes/units.csv \\\n    -g ../threejs/assets/processing_input/custom_geometry/08-navigation_elements.glb \\\n    --overwrite \\\n    -vv\n</code></pre> </li> <li> <p>Process the outdoor icons:</p> <pre><code>uv run data-pipeline load_outdoor \\\n    ../threejs/assets/processing_input/all_outdoor_objects.geojson \\\n    ../threejs/assets/processing_output/outdoor.city.json\n</code></pre> </li> <li> <p>Merge them together:</p> <pre><code>uv run cjio ../threejs/assets/processing_output/08.city.json \\\n    merge ../threejs/assets/processing_output/3dbag.city.json \\\n    merge ../threejs/assets/processing_output/outdoor.city.json \\\n    save  ../threejs/assets/processing_output/all_buildings.city.json\n</code></pre> </li> <li> <p>Split into CityJSON and glTF used by the map:</p> <pre><code>uv run data-pipeline split_cj \\\n    ../threejs/assets/processing_output/all_buildings.city.json \\\n    ../threejs/assets/threejs/buildings \\\n    --overwrite \\\n    -vv\n</code></pre> </li> </ol>"},{"location":"data_pipeline/#other-useful-commands","title":"Other Useful Commands","text":""},{"location":"data_pipeline/#extract-the-3dbag-buildings","title":"Extract the 3DBAG Buildings","text":"<p>To make one CityJSON file with all the buildings that we want, we followed this process:</p> <ol> <li>Download all the necessary tiles from the 3DBAG.</li> <li> <p>Merge them all into one with <code>cjio</code>:</p> <pre><code>uv run cjio \\\n    ../threejs/assets/processing_input/bag_geometry/all_tiles/10-284-560.city.json \\\n    merge '../threejs/assets/processing_input/bag_geometry/all_tiles/*.city.json' \\\n    save ../threejs/assets/processing_input/bag_geometry/all_merged.city.json\n</code></pre> </li> <li> <p>Extract only the necessary buildings with a custom script based on <code>cjio</code>:</p> <pre><code>uv run data-pipeline subset_cj \\\n    ../threejs/assets/processing_input/bag_geometry/all_merged.city.json \\\n    ../threejs/assets/processing_input/bag_geometry/subset.city.json \\\n    ../threejs/assets/processing_input/bag_geometry/all_bag_ids-only_tud.txt\n</code></pre> </li> </ol> <p>In practice, we also used this command to extract the different parts of a building that was removed in a subsequent 3DBAG version:</p> <pre><code>uv run cjio ../threejs/assets/processing_input/bag_geometry/all_merged_old.city.json \\\n    subset \\\n        --id NL.IMBAG.Pand.0503100000004736 \\\n        --id NL.IMBAG.Pand.0503100000016058 \\\n        --id NL.IMBAG.Pand.0503100000030991 \\\n        --id NL.IMBAG.Pand.0503100000004735 \\\n        --id NL.IMBAG.Pand.0503100000016055 \\\n        --id NL.IMBAG.Pand.0503100000016057 \\\n    save ../threejs/assets/processing_input/bag_geometry/building_60.city.json\n</code></pre>"},{"location":"data_structure/","title":"Data Structure","text":""},{"location":"data_structure/#data-structure","title":"Data Structure","text":"<p>There are two main sources for the geometry:</p> <ul> <li>The 3DBAG which provides outer shells for the buildings.   These files are expected to be in CityJSON format.</li> <li>The custom geometry which contains buildings outer shells but also potentially building parts, storeys and rooms.   These files are expected to be in glTF format.</li> </ul> <p>Both sources are expected to have coordinates following EPSG:7415.</p>"},{"location":"javascript_app/","title":"JavaScript","text":""},{"location":"javascript_app/#run-the-threejs-viewer","title":"Run the three.js viewer","text":""},{"location":"javascript_app/#run-the-app-locally-for-development","title":"Run the app locally for development","text":""},{"location":"javascript_app/#prerequisites","title":"Prerequisites","text":"<p>You need to have cloned this repository and installed <code>npm</code>. <code>npm</code> can be installed on Ubuntu withe the instructions from Nodesource.</p> <p>To install the dependencies:</p> <ol> <li> <p>Go into the <code>threejs</code> folder:</p> <pre><code>cd threejs\n</code></pre> </li> <li> <p>Install the dependencies</p> <pre><code>npm ci\n</code></pre> </li> </ol>"},{"location":"javascript_app/#run-the-app","title":"Run the app","text":"<p>First, you need to put all the latest assets in <code>/threejs/assets</code>.</p> <p>To run the app locally for development, you can use one of the commands available with <code>npm run</code>:</p> <ul> <li> <p>Only make it available locally:</p> <pre><code>npm run dev\n</code></pre> </li> <li> <p>With ports to open from another device:</p> <pre><code>npm run dev:host\n</code></pre> </li> </ul>"},{"location":"javascript_app/#run-the-app-on-the-server-for-deployment","title":"Run the app on the server for deployment","text":"<p>The instructions to run the app on the server are in the documentation about the server.</p>"},{"location":"license/","title":"License","text":""},{"location":"license/#license","title":"License","text":"<p>MIT License</p> <p>Copyright (c) 2025 Alexandre Bry, Daan Schlosser, Lars van Blokland, Mingjie Teo, Phuong Anh Ho</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"python_scripts/","title":"Python","text":""},{"location":"python_scripts/#python","title":"Python","text":""},{"location":"python_scripts/#usage","title":"Usage","text":"<p>Python is used in this project for all the data processing that is done to format and agglomerate data from different sources into a single input for the map (or more precisely, one CityJSON and one glTF file).</p>"},{"location":"python_scripts/#prerequisites","title":"Prerequisites","text":"<p>The recommended way to install and run the code is using <code>uv</code>. Instructions to install it are given on their website.</p>"},{"location":"python_scripts/#installation","title":"Installation","text":"<p>To run the Python scripts, follow these steps:</p> <ol> <li> <p>Go to the <code>src</code> folder:</p> <pre><code>cd src\n</code></pre> </li> <li> <p>Create a virtual environment:</p> <pre><code>uv venv\n</code></pre> </li> <li> <p>Install the dependencies</p> <pre><code>uv sync\n</code></pre> </li> </ol> <p>To check if the installation is correct, you can run:</p> <pre><code>uv run python cli.py --help\n</code></pre> <p>This should show you the available commands. See the next part to learn more about running commands.</p>"},{"location":"python_scripts/#run-commands","title":"Run Commands","text":"<p>To run a Python file with <code>uv</code>, the easiest is to use:</p> <pre><code>uv run python &lt;python_file&gt;\n</code></pre> <p>Here is what happens. <code>uv run</code> allows you to run commands in the context of the environment you have installed with <code>uv</code> in your current directory. Anything that comes after it is the actual command. So here you just run <code>python &lt;python_file&gt;</code>, which is the standard way to run a Python program.</p> <p>This program then comes with a CLI interface that allows to run the important steps quickly. To see which commands are available, run:</p> <pre><code>uv run python cli.py --help\n</code></pre> <p>Every command also has its own help, so you can run:</p> <pre><code>uv run python cli.py &lt;command&gt; --help\n</code></pre>"},{"location":"server/","title":"Server","text":""},{"location":"server/#server","title":"Server","text":""},{"location":"server/#server-connection","title":"Server connection","text":"<p>Connection to TU Delft servers requires to either be connected to TU Delft's eduroam or to have eduVPN installed and activated.</p> <p>These instructions are specific to this project. The jump server used here is <code>student-linux.tudelft.nl</code> which is specific to TU Delft students. For employees, it is <code>linux-bastion-ex.tudelf.nl</code>.</p> <p>Finally, these instructions are Unix-specific. To have more information about the Windows equivalent, please check these instructions.</p> <ol> <li> <p>First, set a few variables that will be used later multiple times for simplicity. These variables will disappear once you close the terminal. Replace all the values with the actual values to use:</p> <pre><code>export JUMPSERVER=student-linux.tudelft.nl  # or linux-bastion-ex.tudelf.nl for employees\nexport NETID=&lt;your-ned-id&gt;                  # your TU Delft NETID\n</code></pre> <p>In the next commands, we use variables so that you don't have to replace everything by hand. For example, every command containing <code>\"$NETID\"</code> will see this replaced by the value you set above. After you close the terminal, the variables will be deleted and you will not be able to use these exact commands anymore, unless you export the variables again as shown above. But this is expected, you will only need to remember the final command to be able to connect to the server once the whole setup is finished.</p> <p>If you are curious to see what the command actually looks like after replacing all the $ variables, you can use see it by replacing <code>&lt;command&gt;</code> by the actual command:</p> <pre><code>echo &lt;command&gt;\n</code></pre> </li> <li> <p>Create an SSH key to connect to the server:</p> <pre><code>ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519_tudelftlinux_\"$NETID\" -C \"Connect to the jump server of TU Delft\"\nssh-add ~/.ssh/id_ed25519_tudelftlinux_\"$NETID\"\n</code></pre> </li> <li> <p>Copy this key to the jump server. You will have to enter the NETID password:</p> <pre><code>ssh-copy-id -i ~/.ssh/id_ed25519_tudelftlinux_\"$NETID\" \"$NETID\"@\"$JUMPSERVER\"\n</code></pre> <p>You should now be able to connect to the jump server without any password prompt, using this:</p> <pre><code>ssh -i /home/alexandre/.ssh/id_ed25519_tudelftlinux_\"$NETID\" \"$NETID\"@\"$JUMPSERVER\"\n</code></pre> </li> <li> <p>Copy the key stored in the jump server into your local machine:</p> <pre><code>rsync \"$NETID\"@\"$JUMPSERVER\":.ssh/id_rsa.\"$NETID\" ~/.ssh/id_rsa_inclusivemap_\"$NETID\"\nssh-add ~/.ssh/id_rsa_inclusivemap_\"$NETID\"\n</code></pre> </li> <li> <p>Add a SSH config for quick connection to the server:</p> <pre><code>echo \\\n\"Host tudelft-linux\n\n    Hostname $JUMPSERVER\n\n    User $NETID\n\n    IdentityFile ~/.ssh/id_ed25519_tudelftlinux_$NETID\n\nHost inclusivemap\n\n    Hostname inclusivecampusmap01.bk.tudelft.nl\n\n    ProxyJump tudelft-linux\n\n    User $NETID\n\n    IdentityFile ~/.ssh/id_rsa_inclusivemap_\"$NETID\"\n\" &gt;&gt; ~/.ssh/config\n</code></pre> </li> <li> <p>Test the connection:</p> <pre><code>ssh inclusivemap\n</code></pre> <p>This is the command you can use from now on to connect to the server quickly!</p> </li> </ol>"},{"location":"server/#web-app","title":"Web app","text":"<p>If you have not done it yet, please follow the instructions to set up connection to the server in server.md.</p>"},{"location":"server/#installation","title":"Installation","text":"<p>Here are the steps to deploy the web page for the first time:</p> <ol> <li> <p>Connect to the server:</p> <pre><code>ssh inclusivemap\n</code></pre> </li> <li> <p>Install <code>nginx</code>:</p> <pre><code>sudo apt-get install nginx\n</code></pre> </li> <li> <p>Clone the repository using <code>git clone</code>.</p> </li> <li>Install <code>npm</code> by following these instructions from Nodesource.</li> <li> <p>Install the dependencies for the app:</p> <pre><code>cd Inclusive-TU-Delft-Map/threejs\nnpm ci\n</code></pre> </li> <li> <p>Set up HTTPS: TODO</p> </li> <li> <p>Copy the site configuration to the right place and link it properly:</p> <pre><code>sudo cp ../server/nginx_site /etc/nginx/sites-available/last_version\nsudo ln -s /etc/nginx/sites-available/last_version /etc/nginx/sites-enabled/default\n</code></pre> </li> </ol>"},{"location":"server/#update-the-map","title":"Update the map","text":"<p>Tip</p> <p>The first commands in this section must be run from your local machine.</p> <ol> <li> <p>Copy the assets to the server.     If you have them locally and you followed the setup guide, you can run this by replacing <code>&lt;NETID&gt;</code> properly:</p> <pre><code>scp -r threejs/assets/ &lt;NETID&gt;@inclusivemap:~/Inclusive-TU-Delft-Map/threejs/\n</code></pre> </li> <li> <p>Connect to the server:</p> <pre><code>ssh inclusivemap\ncd Inclusive-TU-Delft-Map/threejs\n</code></pre> </li> <li> <p>Create the new website content from the branch you want to use (replace <code>&lt;branch&gt;</code>):</p> <pre><code>git checkout &lt;branch&gt;\ngit pull\nnpm ci\nnpm run build\n</code></pre> </li> <li> <p>Replace the current website content:</p> <pre><code>rm -r /var/www/last_version/html/*\ncp -r dist/* /var/www/last_version/html/\ncp -r assets/* /var/www/last_version/html/assets/\n</code></pre> </li> <li> <p>Restart the feedback server if necessary:</p> <ul> <li> <p>If not started yet:</p> <pre><code>sudo cp ../server/feedback-service.service /etc/systemd/system/feedback-server.service\nsudo systemctl enable feedback-server.service\nsudo systemctl start feedback-server.service\n</code></pre> </li> <li> <p>If already started but requires to be updated</p> <pre><code>sudo systemctl restart feedback-server.service\n</code></pre> </li> </ul> </li> </ol>"},{"location":"_old/Database/","title":"Database Setup","text":""},{"location":"_old/Database/#database-setup","title":"Database Setup","text":"<p>[!WARNING] The content of this file is outdated, as the project does not use a database anymore. It is kept only in case future developers decide to use a database, as this can provide useful tips and information.</p> <p>For the database, we use 3D City DB v5, a database schema based on PostgreSQL and compatible with CityGML 3.0. If this documentation is unclear, feel free to look into their website which has a very good documentation. At the time of writing this (September 2025), many of the tools provided in the previous version of 3D City DB have not yet been ported to this one, so the instructions given here may not be the most straight-forward.</p> <p>To fully set up the database, you need to:</p> <ol> <li>Set up connection to the server</li> <li>Install PostgreSQL</li> <li>Install 3D City DB and set up an instance</li> </ol>"},{"location":"_old/Database/#postgresql","title":"PostgreSQL","text":""},{"location":"_old/Database/#installation","title":"Installation","text":"<p>[!NOTE] All the commands in this section must be run from the server where the database must be installed.</p> <p>To install PostgreSQL 16 on the server which uses Ubuntu 24.04, we used:</p> <pre><code>sudo apt-get install postgresql-16 postgresql-16-postgis-3\n</code></pre> <p>All the configuration files are stored at <code>/etc/postgresql/16/main</code>.</p>"},{"location":"_old/Database/#set-up-a-user","title":"Set up a user","text":"<p>[!NOTE] All the commands in this section must be run from the server where the database is installed.</p> <p>To set up a user from the server:</p> <ol> <li> <p>Create the user and set the password:</p> <pre><code>sudo -u postgres createuser \"$USER\" -d -r --pwprompt\n</code></pre> </li> <li> <p>Create a database with your user name for simplicity:</p> <pre><code>createdb \"$USER\"\n</code></pre> </li> <li> <p>Check that the database with the user name was created:</p> <pre><code>psql -c \"\\l\"\n</code></pre> </li> </ol>"},{"location":"_old/Database/#dbeaver","title":"DBeaver","text":"<p>[!NOTE] All the commands in this section can be run from the any laptop that followed the instructions to connect to the server.</p> <p>To connect to the database with DBeaver:</p> <ol> <li>Go to <code>Database/New Database Connection</code> in the top ribbon and select <code>PostgreSQL</code>.</li> <li>Click on the green <code>+ SSH, SSL, ...</code> button and select <code>SSH</code>.</li> <li>Set:<ul> <li><code>Host/IP</code>: <code>inclusivecampusmap01.bk.tudelft.nl</code></li> <li><code>User Name</code>: your NETID</li> <li><code>Authentication Method</code>: <code>Public Key</code></li> <li><code>Private Key</code>: the actual path to the SSH key that you copied to <code>~/.ssh/id_rsa_\"$HOSTCUSTOMNAME\"_\"$NETID\"</code></li> </ul> </li> <li>Open the <code>Jump servers</code> part below and click on the button with <code>+</code> (<code>Create new jump host</code>).     Now set:<ul> <li><code>Host/IP</code>: <code>student-linux.tudelft.nl</code> (students) or <code>linux-bastion-ex.tudelf.nl</code> (employees)</li> <li><code>User Name</code>: your NETID</li> <li><code>Authentication Method</code>: <code>Public Key</code></li> <li><code>Private Key</code>: the actual path to the SSH key that you copied to <code>~/.ssh/id_ed25519_tudelftlinux_$NETID</code></li> </ul> </li> <li>Click on <code>Test tunnel configuration</code>.     If everything was set up correctly, you should see <code>Connected!</code>.     Otherwise, make sure that everything you entered in the previous steps is correct (especially the paths to the SSH keys).     If it still does not work, make sure that you followed properly the instructions to connect to the server.</li> <li>Go back to the tab called <code>Main</code> and set:<ul> <li><code>Host</code>: <code>127.0.0.1</code> instead of <code>localhost</code></li> <li><code>Port</code>: <code>5432</code></li> <li><code>Username</code>: your username in the database (check these instructions if you have not created a user yet)</li> <li><code>Password</code>: the password corresponding to the username</li> </ul> </li> <li>Click on <code>Test Connection ...</code>.     If everything was set up correctly, you should see <code>Connected</code>.     Otherwise, make sure that everything you entered in the previous steps is correct, and look at the error to see if you can identify the problem (e.g. user does not exist, password is wrong, etc).</li> </ol>"},{"location":"_old/Database/#3dcitydb","title":"3DCityDB","text":"<p>[!NOTE] All the commands in this section must be run from the server where the database is installed.</p>"},{"location":"_old/Database/#prerequisites","title":"Prerequisites","text":"<p>To install 3D City DB, please follow the official instructions.</p> <p>All the commands below use bash and therefore assume a UNIX system, but the equivalent scripts for Windows are also given by 3D City DB. You just need to replace <code>unix/&lt;name&gt;.sh</code> with <code>windows/&lt;name&gt;.bat</code>.</p> <p>Moreover, we use <code>psql</code> to run the commands, but they can also be run from a graphical client like pgAdmin. There are also equivalents of the <code>.bash</code>/<code>.bat</code> commands as SQL commands that can be run in the same way.</p>"},{"location":"_old/Database/#creation","title":"Creation","text":"<p>Here are the steps to initialise 3D City DB from scratch (assuming that you have PostgreSQL and <code>psql</code> installed).</p> <ol> <li>Edit the database details in <code>citydb-tool-1.1.0/3dcitydb/postgresql/shell-scripts/unix/connection-details.sh</code></li> <li> <p>Make these variables accessible in your shell:</p> <pre><code>source citydb-tool-1.1.0/3dcitydb/postgresql/shell-scripts/unix/connection-details.sh\n</code></pre> </li> <li> <p>Create the corresponding database:</p> <pre><code>psql -h \"$PGHOST\" -p \"$PGPORT\" -U \"$PGUSER\" -c \"CREATE DATABASE \"$CITYDB\";\"\n</code></pre> <p>If you get an error similar to this:</p> <pre><code>psql: error: connection to server at \"&lt;PGHOST&gt;\" (::1), port &lt;PGPORT&gt; failed: FATAL:  database \"&lt;PGUSER&gt;\" does not exist\n</code></pre> <p>then it means that there is no database named like your username, and you can create one with:</p> <pre><code>psql -h \"$PGHOST\" -p \"$PGPORT\" -U \"$PGUSER\" -d &lt;existing_database&gt; -c \"CREATE DATABASE $PGUSER OWNER $PGUSER;\"\n</code></pre> <p>by replacing  with an existing database. Otherwise it will be necessary to specify the database to use for all the commands that do not happen on the 3DCityDB database, using the <code>-d</code> option of <code>psql</code>.</p> </li> <li> <p>Add the necessary PostGIS extensions to handle geometry:</p> <pre><code>psql -h \"$PGHOST\" -p \"$PGPORT\" -U \"$PGUSER\" -d \"$CITYDB\" -c \"CREATE EXTENSION postgis;\"\npsql -h \"$PGHOST\" -p \"$PGPORT\" -U \"$PGUSER\" -d \"$CITYDB\" -c \"CREATE EXTENSION postgis_sfcgal;\"\n</code></pre> </li> <li> <p>Initialise 3D City DB in the newly created database:</p> <pre><code>bash citydb-tool-1.1.0/3dcitydb/postgresql/shell-scripts/unix/create-db.sh\n</code></pre> <p>You will then be prompted to enter CRS information, with 4 successive prompts. In our case for the Netherlands you can use these values in this order:</p> <ul> <li>28992</li> <li>5109</li> <li>Use default (just press enter)</li> <li>Use default (just press enter)</li> </ul> </li> </ol>"},{"location":"_old/Database/#deletion","title":"Deletion","text":"<p>Here are the steps to completely remove the database.</p> <ol> <li>Make sure that the database details in <code>citydb-tool-1.1.0/3dcitydb/postgresql/shell-scripts/unix/connection-details.sh</code> are correct.</li> <li> <p>Make these variables accessible in your shell:</p> <pre><code>source citydb-tool-1.1.0/3dcitydb/postgresql/shell-scripts/unix/connection-details.sh\n</code></pre> </li> <li> <p>Drop 3D City DB:</p> <pre><code>bash citydb-tool-1.1.0/3dcitydb/postgresql/shell-scripts/unix/drop-db.sh\n</code></pre> </li> <li> <p>Remove the database:</p> <pre><code>psql -h \"$PGHOST\" -p \"$PGPORT\" -U \"$PGUSER\" -c \"DROP DATABASE \"$CITYDB\";\"\n</code></pre> </li> </ol>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>cj_helpers<ul> <li>cj_attributes</li> <li>cj_geometry</li> <li>cj_objects</li> </ul> </li> <li>cj_loading<ul> <li>cj_loader</li> <li>cj_to_gltf</li> </ul> </li> <li>cj_writing<ul> <li>bag_to_cj</li> <li>gj_to_cj</li> <li>gltf_to_cj</li> </ul> </li> <li>cli</li> <li>utils<ul> <li>codelists</li> <li>csv_utils</li> <li>geometry_utils</li> <li>icon_positions</li> <li>plane</li> </ul> </li> </ul>"},{"location":"reference/cli/","title":"cli","text":"<p>The command line interface to run the different parts of the data pipeline. Once installed, it all commands can be run with <code>uv run data-pipeline ...</code>. More information about the CLI can be obtained with:</p> <ul> <li><code>uv run data-pipeline --help</code></li> <li><code>uv run data-pipeline &lt;command&gt; --help</code></li> </ul> <p>Functions:</p> Name Description <code>format_codelist</code> <p>Format the codelist for the units from a CSV input into a JSON file.</p> <code>load_3dbag</code> <p>Load 3DBAG geometries and combines it with given attributes to export a properly formatted CityJSON file.</p> <code>load_custom_building</code> <p>Load and format the given glTF building into CityJSON by adding hierarchy, units and attributes at all level.</p> <code>load_outdoor</code> <p>Load outdoor data from a GeoJSON file containing both the geometry and the attributes.</p> <code>setup_logging</code> <p>Utility function to set up the logging parameters properly.</p> <code>split_cj</code> <p>Split a CityJSON file into a glTF file with the geometry and a CityJSON file with the attributes, both sharing the same identifiers and a similar structure.</p> <code>subset_cj</code> <p>Create a subset of a CityJSON file based on a list of identifiers in the file.</p>"},{"location":"reference/cli/#cli.format_codelist","title":"<code>format_codelist(input_csv_path, output_json_path, overwrite=False)</code>","text":"<p>Format the codelist for the units from a CSV input into a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>input_csv_path</code> <code>pathlib.Path</code> <p>Input CSV file.</p> required <code>output_json_path</code> <code>pathlib.Path</code> <p>Output JSON path.</p> required <code>overwrite</code> <code>bool</code> <p>Overwrite the output file if it already exists. By default False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input path does not end with '.csv'.</p> <code>ValueError</code> <p>If the output path does not end with '.json'.</p> <code>ValueError</code> <p>If <code>overwrite</code> is set to False but the output path already exists.</p> Source code in <code>python/src/data_pipeline/cli.py</code> <pre><code>@app.command(\n    \"format_codelist\",\n    help=\"Format the codelist for the units from a CSV input into a JSON file.\",\n)\ndef format_codelist(\n    input_csv_path: Annotated[\n        Path, typer.Argument(help=\"Input CSV file.\", exists=True)\n    ],\n    output_json_path: Annotated[Path, typer.Argument(help=\"Output JSON path.\")],\n    overwrite: Annotated[\n        bool,\n        typer.Option(\n            \"-o\",\n            \"--overwrite\",\n            help=\"Overwrite the output file if the file already exists.\",\n        ),\n    ] = False,\n):\n    \"\"\"\n    Format the codelist for the units from a CSV input into a JSON file.\n\n    Parameters\n    ----------\n    input_csv_path : Path\n        Input CSV file.\n    output_json_path : Path\n        Output JSON path.\n    overwrite : bool, optional\n        Overwrite the output file if it already exists. By default False.\n\n    Raises\n    ------\n    ValueError\n        If the input path does not end with '.csv'.\n    ValueError\n        If the output path does not end with '.json'.\n    ValueError\n        If `overwrite` is set to False but the output path already exists.\n    \"\"\"\n    if not input_csv_path.suffix == \".csv\":\n        raise ValueError(\"The input path should end with '.csv'\")\n    if not output_json_path.suffix == \".json\":\n        raise ValueError(\"The output path should end with '.json'\")\n    if output_json_path.exists() and not overwrite:\n        raise ValueError(\n            f\"There is already a file at {output_json_path.absolute()}. Set `overwrite` to True to overwrite it.\"\n        )\n\n    format_codelist_json(\n        input_csv_path=input_csv_path, output_json_path=output_json_path\n    )\n</code></pre>"},{"location":"reference/cli/#cli.load_3dbag","title":"<code>load_3dbag(input_cj_path, output_cj_path, bdgs_attr_path=None, bdgs_sub_attr_path=None, overwrite=False, verbose=0)</code>","text":"<p>Load 3DBAG geometries and combines it with given attributes to export a properly formatted CityJSON file.</p> <p>Parameters:</p> Name Type Description Default <code>input_cj_path</code> <code>pathlib.Path</code> <p>Input CityJSON file with 3DBAG data.</p> required <code>output_cj_path</code> <code>pathlib.Path</code> <p>Output CityJSON path.</p> required <code>bdgs_attr_path</code> <code>typing.Optional[pathlib.Path]</code> <p>CSV path with the buildings attributes. By default None.</p> <code>None</code> <code>bdgs_sub_attr_path</code> <code>typing.Optional[pathlib.Path]</code> <p>CSV path with the buildings subdivisions attributes. By default None.</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>Overwrite the output file if the file already exists. By default False.</p> <code>False</code> <code>verbose</code> <code>int</code> <p>How much information to provide during the execution of the script. By default 0.</p> <code>0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the output path does not end with '.json'.</p> <code>RuntimeError</code> <p>If <code>overwrite</code> is set to False but the output path already exists.</p> Source code in <code>python/src/data_pipeline/cli.py</code> <pre><code>@app.command(\n    \"load_3dbag\",\n    help=\"Load 3DBAG geometries and combines it with given attributes to export a properly formatted CityJSON file.\",\n)\ndef load_3dbag(\n    input_cj_path: Annotated[\n        Path, typer.Argument(help=\"Input CityJSON file with 3DBAG data.\", exists=True)\n    ],\n    output_cj_path: Annotated[Path, typer.Argument(help=\"Output CityJSON path.\")],\n    bdgs_attr_path: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"-b\",\n            \"--buildings\",\n            help=\"CSV path with the buildings attributes.\",\n            exists=True,\n        ),\n    ] = None,\n    bdgs_sub_attr_path: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"-s\",\n            \"--subdivisions\",\n            help=\"CSV path with the buildings subdivisions attributes.\",\n            exists=True,\n        ),\n    ] = None,\n    overwrite: Annotated[\n        bool,\n        typer.Option(\n            \"-o\",\n            \"--overwrite\",\n            help=\"Overwrite the output file if the file already exists.\",\n        ),\n    ] = False,\n    verbose: Annotated[\n        int,\n        typer.Option(\n            \"--verbose\",\n            \"-v\",\n            count=True,\n            help=\"How much information to provide during the execution of the script.\",\n        ),\n    ] = 0,\n):\n    \"\"\"\n    Load 3DBAG geometries and combines it with given attributes to export a properly formatted CityJSON file.\n\n    Parameters\n    ----------\n    input_cj_path : Path\n        Input CityJSON file with 3DBAG data.\n    output_cj_path : Path\n        Output CityJSON path.\n    bdgs_attr_path : Optional[Path], optional\n        CSV path with the buildings attributes. By default None.\n    bdgs_sub_attr_path : Optional[Path], optional\n        CSV path with the buildings subdivisions attributes. By default None.\n    overwrite : bool, optional\n        Overwrite the output file if the file already exists. By default False.\n    verbose : int, optional\n        How much information to provide during the execution of the script. By default 0.\n\n    Raises\n    ------\n    ValueError\n        If the output path does not end with '.json'.\n    RuntimeError\n        If `overwrite` is set to False but the output path already exists.\n    \"\"\"\n    if not output_cj_path.suffix == \".json\":\n        raise RuntimeError(\"The output path should end with '.json'\")\n    if output_cj_path.exists() and not overwrite:\n        raise RuntimeError(\n            f\"There is already a file at {output_cj_path.absolute()}. Set `overwrite` to True to overwrite it.\"\n        )\n\n    setup_logging(verbose=verbose)\n    with logging_redirect_tqdm():\n\n        cj_bag_data = Bag2Cityjson(\n            cj_path=input_cj_path,\n            bdgs_attr_path=bdgs_attr_path,\n            bdgs_sub_attr_path=bdgs_sub_attr_path,\n        )\n        cj_bag_data.export(output_cj_path)\n</code></pre>"},{"location":"reference/cli/#cli.load_custom_building","title":"<code>load_custom_building(input_gltf_path, output_cj_path, buidlings_path, parts_path, storeys_path, rooms_path, units_path, units_gltf_path, overwrite=False, verbose=0)</code>","text":"<p>Load and format the given glTF building into CityJSON by adding hierarchy, units and attributes at all level.</p> <p>Parameters:</p> Name Type Description Default <code>input_gltf_path</code> <code>pathlib.Path</code> <p>Input glTF file with building data and correct structure.</p> required <code>output_cj_path</code> <code>pathlib.Path</code> <p>Output CityJSON path.</p> required <code>buidlings_path</code> <code>pathlib.Path</code> <p>Path to buildings attributes in CSV format.</p> required <code>parts_path</code> <code>pathlib.Path</code> <p>Path to parts attributes in CSV format.</p> required <code>storeys_path</code> <code>pathlib.Path</code> <p>Path to storeys attributes in CSV format.</p> required <code>rooms_path</code> <code>pathlib.Path</code> <p>Path to rooms attributes in CSV format.</p> required <code>units_path</code> <code>pathlib.Path</code> <p>Path to building units in CSV format.</p> required <code>units_gltf_path</code> <code>pathlib.Path</code> <p>Path to building units in glTF format.</p> required <code>overwrite</code> <code>bool</code> <p>Overwrite the output file if the file already exists. By default False.</p> <code>False</code> <code>verbose</code> <code>int</code> <p>How much information to provide during the execution of the script. By default 0.</p> <code>0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input path does not end with '.glb' or '.gltf'.</p> <code>ValueError</code> <p>If the output path does not end with '.json'.</p> <code>ValueError</code> <p>If <code>overwrite</code> is set to False but the output path already exists.</p> Source code in <code>python/src/data_pipeline/cli.py</code> <pre><code>@app.command(\n    \"load_custom_building\",\n    help=\"Load custom geometries from glTF and combines it with given attributes to export a properly formatted CityJSON file.\",\n)\ndef load_custom_building(\n    input_gltf_path: Annotated[\n        Path,\n        typer.Argument(\n            help=\"Input glTF file with building data and correct structure.\",\n            exists=True,\n        ),\n    ],\n    output_cj_path: Annotated[Path, typer.Argument(help=\"Output CityJSON path.\")],\n    buidlings_path: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"-b\",\n            \"--buildings\",\n            help=\"Path to buildings attributes in CSV format.\",\n            exists=True,\n        ),\n    ],\n    parts_path: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"-p\",\n            \"--parts\",\n            help=\"Path to parts attributes in CSV format.\",\n            exists=True,\n        ),\n    ],\n    storeys_path: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"-s\",\n            \"--storeys\",\n            help=\"Path to storeys attributes in CSV format.\",\n            exists=True,\n        ),\n    ],\n    rooms_path: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"-r\",\n            \"--rooms\",\n            help=\"Path to rooms attributes in CSV format.\",\n            exists=True,\n        ),\n    ],\n    units_path: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"-u\",\n            \"--units\",\n            help=\"Path to building units in CSV format.\",\n            exists=True,\n        ),\n    ],\n    units_gltf_path: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"-g\",\n            \"--units_gltf\",\n            help=\"Path to building units in glTF format.\",\n            exists=True,\n        ),\n    ],\n    overwrite: Annotated[\n        bool,\n        typer.Option(\n            \"-o\",\n            \"--overwrite\",\n            help=\"Overwrite the output file if the file already exists.\",\n        ),\n    ] = False,\n    verbose: Annotated[\n        int,\n        typer.Option(\n            \"--verbose\",\n            \"-v\",\n            count=True,\n            help=\"How much information to provide during the execution of the script.\",\n        ),\n    ] = 0,\n):\n    \"\"\"\n    Load and format the given glTF building into CityJSON by adding hierarchy, units and attributes at all level.\n\n    Parameters\n    ----------\n    input_gltf_path : Path\n        Input glTF file with building data and correct structure.\n    output_cj_path : Path\n        Output CityJSON path.\n    buidlings_path : Path\n        Path to buildings attributes in CSV format.\n    parts_path : Path\n        Path to parts attributes in CSV format.\n    storeys_path : Path\n        Path to storeys attributes in CSV format.\n    rooms_path : Path\n        Path to rooms attributes in CSV format.\n    units_path : Path\n        Path to building units in CSV format.\n    units_gltf_path : Path\n        Path to building units in glTF format.\n    overwrite : bool, optional\n        Overwrite the output file if the file already exists. By default False.\n    verbose : int, optional\n        How much information to provide during the execution of the script. By default 0.\n\n    Raises\n    ------\n    ValueError\n        If the input path does not end with '.glb' or '.gltf'.\n    ValueError\n        If the output path does not end with '.json'.\n    ValueError\n        If `overwrite` is set to False but the output path already exists.\n    \"\"\"\n    if not input_gltf_path.suffix in [\".glb\", \".gltf\"]:\n        raise ValueError(\"The input path should end with '.glb' or '.gltf'.\")\n    if not output_cj_path.suffix == \".json\":\n        raise ValueError(\"The output path should end with '.json'.\")\n    if output_cj_path.exists() and not overwrite:\n        raise ValueError(\n            f\"There is already a file at {output_cj_path.absolute()}. Set `overwrite` to True to overwrite it.\"\n        )\n\n    setup_logging(verbose=verbose)\n    with logging_redirect_tqdm():\n        # Load the geometry from glTF\n        cj_file = full_building_from_gltf(gltf_path=input_gltf_path)\n\n        logging.info(\"Load the CSV attributes...\")\n\n        all_attributes: list[\n            Mapping[str, BdgAttr | BdgPartAttr | BdgStoreyAttr | BdgRoomAttr]\n        ] = []\n        if buidlings_path is not None:\n            all_attributes.append(\n                BdgAttrReader(csv_path=buidlings_path).get_key_to_attr()\n            )\n        if parts_path is not None:\n            all_attributes.append(\n                BdgPartAttrReader(csv_path=parts_path).get_key_to_attr()\n            )\n        if storeys_path is not None:\n            all_attributes.append(\n                BdgStoreyAttrReader(csv_path=storeys_path).get_key_to_attr()\n            )\n        if rooms_path is not None:\n            all_attributes.append(\n                BdgRoomAttrReader(csv_path=rooms_path).get_key_to_attr()\n            )\n\n        logging.info(\"Add the attributes to the spaces...\")\n\n        # Add the attributes to the CityJSON spaces\n        for city_object in cj_file.city_objects:\n            if isinstance(city_object, CityJSONSpace):\n                for attributes in all_attributes:\n                    if city_object.space_id not in attributes:\n                        continue\n                    attr = attributes[city_object.space_id]\n                    if isinstance(city_object, Building) and isinstance(attr, BdgAttr):\n                        city_object.apply_attr(attr, overwrite=True)\n                    if isinstance(city_object, BuildingPart) and isinstance(\n                        attr, BdgPartAttr\n                    ):\n                        city_object.apply_attr(attr, overwrite=True)\n                    if isinstance(city_object, BuildingStorey) and isinstance(\n                        attr, BdgStoreyAttr\n                    ):\n                        city_object.apply_attr(attr, overwrite=True)\n                    if isinstance(city_object, BuildingRoom) and isinstance(\n                        attr, BdgRoomAttr\n                    ):\n                        city_object.apply_attr(attr, overwrite=True)\n\n        logging.info(\"Load the units...\")\n\n        # Load the units\n        if units_path is not None:\n            load_units_from_csv(\n                cj_file=cj_file,\n                csv_path=units_path,\n                gltf_path=units_gltf_path,\n            )\n\n        logging.info(\"Check the hierarchy...\")\n\n        # Check the correctness of the hierarchy\n        cj_file.check_objects_hierarchy(n_components=2)\n\n        logging.info(\"Write the file...\")\n\n        # Write to CityJSON\n        file_json = cj_file.to_json()\n        output_cj_path.parent.mkdir(parents=True, exist_ok=True)\n        with open(Path(output_cj_path), \"w\") as f:\n            f.write(file_json)\n</code></pre>"},{"location":"reference/cli/#cli.load_outdoor","title":"<code>load_outdoor(input_gj_path, output_cj_path)</code>","text":"<p>Load outdoor data from a GeoJSON file containing both the geometry and the attributes.</p> <p>Parameters:</p> Name Type Description Default <code>input_gj_path</code> <code>pathlib.Path</code> <p>Input GeoJSON file with the outdoor data.</p> required <code>output_cj_path</code> <code>pathlib.Path</code> <p>Output CityJSON path.</p> required Source code in <code>python/src/data_pipeline/cli.py</code> <pre><code>@app.command(\n    \"load_outdoor\",\n    help=\"Load outdoor data from a GeoJSON file containing both the geometry and the attributes.\",\n)\ndef load_outdoor(\n    input_gj_path: Annotated[\n        Path,\n        typer.Argument(\n            help=\"Input GeoJSON file with the outdoor data.\",\n            exists=True,\n        ),\n    ],\n    output_cj_path: Annotated[Path, typer.Argument(help=\"Output CityJSON path.\")],\n):\n    \"\"\"\n    Load outdoor data from a GeoJSON file containing both the geometry and the attributes.\n\n    Parameters\n    ----------\n    input_gj_path : Path\n        Input GeoJSON file with the outdoor data.\n    output_cj_path : Path\n        Output CityJSON path.\n    \"\"\"\n    load_geojson_icons(gj_path=input_gj_path, output_cj_path=output_cj_path)\n</code></pre>"},{"location":"reference/cli/#cli.setup_logging","title":"<code>setup_logging(verbose)</code>","text":"<p>Utility function to set up the logging parameters properly.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>int</code> <p>Integer indicating how much information to display. Possible values are 0 (ERROR), 1 (WARNING), 2 (INFO) and 3 (DEBUG)</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>verbose</code> is not one of the expected values.</p> Source code in <code>python/src/data_pipeline/cli.py</code> <pre><code>def setup_logging(verbose: int):\n    \"\"\"\n    Utility function to set up the logging parameters properly.\n\n    Parameters\n    ----------\n    verbose : int\n        Integer indicating how much information to display.\n        Possible values are 0 (ERROR), 1 (WARNING), 2 (INFO) and 3 (DEBUG)\n\n    Raises\n    ------\n    RuntimeError\n        If `verbose` is not one of the expected values.\n    \"\"\"\n    match verbose:\n        case 0:\n            log_level = logging.ERROR\n        case 1:\n            log_level = logging.WARNING\n        case 2:\n            log_level = logging.INFO\n        case 3:\n            log_level = logging.DEBUG\n        case _:\n            raise RuntimeError(\n                f\"Verbose values can only go from 0 to 3 (nothing, '-v', '-vv' or '-vvv').\"\n            )\n    logging.basicConfig(\n        level=log_level,\n        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    )\n</code></pre>"},{"location":"reference/cli/#cli.split_cj","title":"<code>split_cj(input_cj_path, output_folder_path, overwrite=False, verbose=0)</code>","text":"<p>Split a CityJSON file into a glTF file with the geometry and a CityJSON file with the attributes, both sharing the same identifiers and a similar structure.</p> <p>Parameters:</p> Name Type Description Default <code>input_cj_path</code> <code>pathlib.Path</code> <p>Input CityJSON file.</p> required <code>output_folder_path</code> <code>pathlib.Path</code> <p>Output folder.</p> required <code>overwrite</code> <code>bool</code> <p>Overwrite the content of the folder if files with the same names exist. By default False.</p> <code>False</code> <code>verbose</code> <code>int</code> <p>How much information to provide during the execution of the script. By default 0.</p> <code>0</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>overwrite</code> is set to False but the output folder already exists.</p> Source code in <code>python/src/data_pipeline/cli.py</code> <pre><code>@app.command(\n    \"split_cj\",\n    help=\"Split a CityJSON file into a glTF file with the geometry and a CityJSON file with the attributes, both sharing the same identifiers and a similar structure.\",\n)\ndef split_cj(\n    input_cj_path: Annotated[\n        Path, typer.Argument(help=\"Input CityJSON file\", exists=True)\n    ],\n    output_folder_path: Annotated[Path, typer.Argument(help=\"Output folder\")],\n    overwrite: Annotated[\n        bool,\n        typer.Option(\n            \"-o\",\n            \"--overwrite\",\n            help=\"Overwrite the content of the folder if files with the same names exist.\",\n        ),\n    ] = False,\n    verbose: Annotated[\n        int,\n        typer.Option(\n            \"--verbose\",\n            \"-v\",\n            count=True,\n            help=\"How much information to provide during the execution of the script.\",\n        ),\n    ] = 0,\n):\n    \"\"\"\n    Split a CityJSON file into a glTF file with the geometry and a CityJSON file with the attributes, both sharing the same identifiers and a similar structure.\n\n    Parameters\n    ----------\n    input_cj_path : Path\n        Input CityJSON file.\n    output_folder_path : Path\n        Output folder.\n    overwrite : bool, optional\n        Overwrite the content of the folder if files with the same names exist. By default False.\n    verbose : int, optional\n        How much information to provide during the execution of the script. By default 0.\n\n    Raises\n    ------\n    RuntimeError\n        If `overwrite` is set to False but the output folder already exists.\n    \"\"\"\n    if output_folder_path.exists() and not overwrite:\n        raise RuntimeError(\n            f\"Path '{output_folder_path.absolute()}' already exists but `overwrite` was set to False.\"\n        )\n\n    setup_logging(verbose=verbose)\n    with logging_redirect_tqdm():\n        output_folder_path.mkdir(parents=True, exist_ok=overwrite)\n\n        cj_data = Cityjson2Gltf(input_cj_path)\n        cj_data.make_gltf_scene()\n        cj_data.export(output_folder_path, overwrite=overwrite)\n</code></pre>"},{"location":"reference/cli/#cli.subset_cj","title":"<code>subset_cj(input_cj_path, output_cj_path, subset_txt_path)</code>","text":"<p>Create a subset of a CityJSON file based on a list of identifiers in the file.</p> <p>Parameters:</p> Name Type Description Default <code>input_cj_path</code> <code>pathlib.Path</code> <p>Input CityJSON path.</p> required <code>output_cj_path</code> <code>pathlib.Path</code> <p>Output CityJSON path.</p> required <code>subset_txt_path</code> <code>pathlib.Path</code> <p>Text path containing the object ids to keep, separated with new lines.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input path does not end with '.json'.</p> <code>ValueError</code> <p>If the output path does not end with '.json'.</p> Source code in <code>python/src/data_pipeline/cli.py</code> <pre><code>@app.command(\n    \"subset_cj\",\n    help=\"Create a subset of a CityJSON file based on a list of identifiers in the file.\",\n)\ndef subset_cj(\n    input_cj_path: Annotated[\n        Path, typer.Argument(help=\"Input CityJSON path.\", exists=True)\n    ],\n    output_cj_path: Annotated[Path, typer.Argument(help=\"Output CityJSON path.\")],\n    subset_txt_path: Annotated[\n        Path,\n        typer.Argument(\n            help=\"Text path containing the object ids to keep, separated with new lines.\",\n        ),\n    ],\n):\n    \"\"\"\n    Create a subset of a CityJSON file based on a list of identifiers in the file.\n\n    Parameters\n    ----------\n    input_cj_path : Path\n        Input CityJSON path.\n    output_cj_path : Path\n        Output CityJSON path.\n    subset_txt_path : Path\n        Text path containing the object ids to keep, separated with new lines.\n\n    Raises\n    ------\n    ValueError\n        If the input path does not end with '.json'.\n    ValueError\n        If the output path does not end with '.json'.\n    \"\"\"\n    if not input_cj_path.suffix == \".json\":\n        raise ValueError(\"The input path should end with '.json'\")\n    if not output_cj_path.suffix == \".json\":\n        raise ValueError(\"The output path should end with '.json'\")\n\n    command = [\"cjio\", str(input_cj_path.absolute()), \"subset\"]\n    with open(subset_txt_path) as f:\n        for obj_key_line in f.readlines():\n            obj_key = obj_key_line.strip()\n            command.extend([\"--id\", obj_key])\n    command.extend([\"save\", str(output_cj_path.absolute())])\n    subprocess.run(command)\n</code></pre>"},{"location":"reference/cj_helpers/","title":"cj_helpers","text":"<p>Collection of scripts to help building correct and coherent CityJSON objects and files.</p> <p>Modules:</p> Name Description <code>cj_attributes</code> <p>Classes to read and process the attributes of all types of CityJSON objects in a standard way for all types and all branches of the pipeline.</p> <code>cj_geometry</code> <p>Classes to handle the geometry of the CityJSON objects.</p> <code>cj_objects</code> <p>Classes to format and normalize CityJSON objects and files.</p>"},{"location":"reference/cj_helpers/cj_attributes/","title":"cj_attributes","text":"<p>Classes to read and process the attributes of all types of CityJSON objects in a standard way for all types and all branches of the pipeline.</p> <p>Classes:</p> Name Description <code>Attr</code> <p>Base abstract class to store attributes.</p> <code>AttrReader</code> <p>Base abstract class to read attributes from CSV.</p> <code>BdgAttr</code> <p>Class to store the attributes of Building objects.</p> <code>BdgAttrReader</code> <p>Class to read attributes of Building objecys from CSV.</p> <code>BdgPartAttr</code> <p>Class to store the attributes of BuildingPart objects.</p> <code>BdgPartAttrReader</code> <p>Class to read attributes of BuildingPart objects from CSV.</p> <code>BdgRoomAttr</code> <p>Class to store the attributes of BuildingRoom objects.</p> <code>BdgRoomAttrReader</code> <p>Class to read attributes of BuildingRoom objects from CSV.</p> <code>BdgStoreyAttr</code> <p>Class to store the attributes of BuildingStorey objects.</p> <code>BdgStoreyAttrReader</code> <p>Class to read attributes of BuildingStorey objects from CSV.</p> <code>BdgSubAttr</code> <p>Class to store the attributes of building subdivisions.</p> <code>BdgSubAttrReader</code> <p>Class to read attributes of building subdivisions from CSV.</p> <code>BdgUnitAttr</code> <p>Class to store the attributes of BuildingUnit objects.</p> <code>BdgUnitAttrReader</code> <p>Class to read attributes of BuildingUnit objects from CSV.</p>"},{"location":"reference/cj_helpers/cj_attributes/#cj_helpers.cj_attributes.Attr","title":"<code>Attr</code>","text":"<p>               Bases: <code>abc.ABC</code></p> <p>Base abstract class to store attributes.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_attributes.py</code> <pre><code>class Attr(ABC):\n    \"\"\"\n    Base abstract class to store attributes.\n    \"\"\"\n\n    specific_columns: tuple[str, ...] = (KEY_COLUMN,)\n    key_index: int | None = 0\n    key_builder_index: int | None = None\n\n    def __init__(\n        self,\n        attributes: dict[str, Any],\n        cj_key: str,\n        icon_position: IconPosition | list[float] | None,\n    ) -&gt; None:\n        self.attributes = attributes\n        self.cj_key = cj_key\n        if isinstance(icon_position, IconPosition):\n            self.icon_position = icon_position\n        elif icon_position is None or len(icon_position) == 0:\n            self.icon_position = None\n        else:\n            self.icon_position = IconPosition.from_list(icon_position)\n</code></pre>"},{"location":"reference/cj_helpers/cj_attributes/#cj_helpers.cj_attributes.AttrReader","title":"<code>AttrReader</code>","text":"<p>               Bases: <code>typing.Generic[cj_helpers.cj_attributes.A]</code>, <code>abc.ABC</code></p> <p>Base abstract class to read attributes from CSV.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_attributes.py</code> <pre><code>class AttrReader(Generic[A], ABC):\n    \"\"\"\n    Base abstract class to read attributes from CSV.\n    \"\"\"\n\n    attr_class: Type[A]\n\n    def __init__(self, csv_path: Path) -&gt; None:\n        self.csv_path = csv_path\n        self.specific_columns = self.attr_class.specific_columns\n        self._key_to_attr: dict[str, A] = {}\n        self._key_builder_counts = defaultdict(lambda: 0)\n        self._read_attributes()\n        self._organise_attributes()\n\n    def _read_attributes(self) -&gt; None:\n        self.attributes_all, self.specific_values_all = csv_read_attributes(\n            csv_path=self.csv_path, specific_columns=self.specific_columns\n        )\n\n    def _organise_attributes(self) -&gt; None:\n        if (\n            self.attr_class.key_index is None\n            and self.attr_class.key_builder_index is None\n        ):\n            raise RuntimeError(\n                \"Cannot have both `key_index` and `key_builder_index` be None.\"\n            )\n\n        for attributes, specific_values in zip(\n            self.attributes_all, self.specific_values_all\n        ):\n            if self.attr_class.key_index is None:\n                col_name, key_base_value = specific_values[\n                    cast(int, self.attr_class.key_builder_index)\n                ]\n                cj_key = self._build_cj_key(col_name)\n            else:\n                _, cj_key = specific_values[self.attr_class.key_index]\n\n            specific_values_map = {}\n            for specific_col, col_name_value in zip(\n                self.attr_class.specific_columns, specific_values\n            ):\n                name = COL_TO_NAME[specific_col]\n                _, value = col_name_value\n                specific_values_map[name] = value\n\n            if self.attr_class.key_index is None:\n                specific_values_map[\"cj_key\"] = cj_key\n\n            self._key_to_attr[cj_key] = self.attr_class(\n                attributes=attributes, **specific_values_map\n            )\n\n    def _build_cj_key(self, col_name: str) -&gt; str:\n        count = self._key_builder_counts[col_name]\n        cj_key = f\"{col_name}@{count}\"\n        self._key_builder_counts[col_name] += 1\n        return cj_key\n\n    def get_key_to_attr(self):\n        return deepcopy(self._key_to_attr)\n\n    def get_attributes_by_cj_key(self, cj_key: str):\n        try:\n            return self._key_to_attr[cj_key]\n        except KeyError as exc:\n            raise ValueError(f\"Object key '{cj_key}' does not exist.\") from exc\n\n    def __len__(self):\n        return len(self._key_to_attr)\n\n    def iterator(self):\n        return iter(self._key_to_attr.items())\n</code></pre>"},{"location":"reference/cj_helpers/cj_attributes/#cj_helpers.cj_attributes.BdgAttr","title":"<code>BdgAttr</code>","text":"<p>               Bases: <code>cj_helpers.cj_attributes.Attr</code></p> <p>Class to store the attributes of Building objects.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_attributes.py</code> <pre><code>class BdgAttr(Attr):\n    \"\"\"\n    Class to store the attributes of Building objects.\n    \"\"\"\n\n    specific_columns = (\n        KEY_COLUMN,\n        SPACE_ID_COLUMN,\n        BAG_COLUMN,\n        SKIP_COLUMN,\n        ICON_POSITION_COLUMN,\n    )\n    key_index = 0\n    key_builder_index = None\n\n    def __init__(\n        self,\n        attributes: dict[str, Any],\n        cj_key: str,\n        space_id: str,\n        icon_position: IconPosition | list[float] | None,\n        bag_ids: list[str],\n        skip: bool,\n    ) -&gt; None:\n        super().__init__(\n            attributes=attributes, cj_key=cj_key, icon_position=icon_position\n        )\n        self.bag_ids = bag_ids\n        self.skip = skip\n        self.space_id = space_id\n</code></pre>"},{"location":"reference/cj_helpers/cj_attributes/#cj_helpers.cj_attributes.BdgAttrReader","title":"<code>BdgAttrReader</code>","text":"<p>               Bases: <code>cj_helpers.cj_attributes.AttrReader[cj_helpers.cj_attributes.BdgAttr]</code></p> <p>Class to read attributes of Building objecys from CSV.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_attributes.py</code> <pre><code>class BdgAttrReader(AttrReader[BdgAttr]):\n    \"\"\"\n    Class to read attributes of Building objecys from CSV.\n    \"\"\"\n\n    attr_class = BdgAttr\n\n    def __init__(self, csv_path: Path) -&gt; None:\n        super().__init__(csv_path)\n</code></pre>"},{"location":"reference/cj_helpers/cj_attributes/#cj_helpers.cj_attributes.BdgPartAttr","title":"<code>BdgPartAttr</code>","text":"<p>               Bases: <code>cj_helpers.cj_attributes.Attr</code></p> <p>Class to store the attributes of BuildingPart objects.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_attributes.py</code> <pre><code>class BdgPartAttr(Attr):\n    \"\"\"\n    Class to store the attributes of BuildingPart objects.\n    \"\"\"\n\n    specific_columns = (SPACE_ID_COLUMN,)\n    key_index = 0\n    key_builder_index = None\n\n    def __init__(\n        self,\n        attributes: dict[str, Any],\n        space_id: str,\n    ) -&gt; None:\n        super().__init__(attributes=attributes, cj_key=space_id, icon_position=None)\n        self.space_id = space_id\n</code></pre>"},{"location":"reference/cj_helpers/cj_attributes/#cj_helpers.cj_attributes.BdgPartAttrReader","title":"<code>BdgPartAttrReader</code>","text":"<p>               Bases: <code>cj_helpers.cj_attributes.AttrReader[cj_helpers.cj_attributes.BdgPartAttr]</code></p> <p>Class to read attributes of BuildingPart objects from CSV.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_attributes.py</code> <pre><code>class BdgPartAttrReader(AttrReader[BdgPartAttr]):\n    \"\"\"\n    Class to read attributes of BuildingPart objects from CSV.\n    \"\"\"\n\n    attr_class = BdgPartAttr\n\n    def __init__(self, csv_path: Path) -&gt; None:\n        super().__init__(csv_path)\n</code></pre>"},{"location":"reference/cj_helpers/cj_attributes/#cj_helpers.cj_attributes.BdgRoomAttr","title":"<code>BdgRoomAttr</code>","text":"<p>               Bases: <code>cj_helpers.cj_attributes.Attr</code></p> <p>Class to store the attributes of BuildingRoom objects.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_attributes.py</code> <pre><code>class BdgRoomAttr(Attr):\n    \"\"\"\n    Class to store the attributes of BuildingRoom objects.\n    \"\"\"\n\n    specific_columns = (SPACE_ID_COLUMN, ICON_POSITION_COLUMN, CODE_COLUMN)\n    key_index = 0\n    key_builder_index = None\n\n    def __init__(\n        self,\n        attributes: dict[str, Any],\n        space_id: str,\n        icon_position: IconPosition | list[float] | None,\n        code: str,\n    ) -&gt; None:\n        super().__init__(\n            attributes=attributes, cj_key=space_id, icon_position=icon_position\n        )\n        self.space_id = space_id\n        self.code = code\n</code></pre>"},{"location":"reference/cj_helpers/cj_attributes/#cj_helpers.cj_attributes.BdgRoomAttrReader","title":"<code>BdgRoomAttrReader</code>","text":"<p>               Bases: <code>cj_helpers.cj_attributes.AttrReader[cj_helpers.cj_attributes.BdgRoomAttr]</code></p> <p>Class to read attributes of BuildingRoom objects from CSV.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_attributes.py</code> <pre><code>class BdgRoomAttrReader(AttrReader[BdgRoomAttr]):\n    \"\"\"\n    Class to read attributes of BuildingRoom objects from CSV.\n    \"\"\"\n\n    attr_class = BdgRoomAttr\n\n    def __init__(self, csv_path: Path) -&gt; None:\n        super().__init__(csv_path)\n</code></pre>"},{"location":"reference/cj_helpers/cj_attributes/#cj_helpers.cj_attributes.BdgStoreyAttr","title":"<code>BdgStoreyAttr</code>","text":"<p>               Bases: <code>cj_helpers.cj_attributes.Attr</code></p> <p>Class to store the attributes of BuildingStorey objects.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_attributes.py</code> <pre><code>class BdgStoreyAttr(Attr):\n    \"\"\"\n    Class to store the attributes of BuildingStorey objects.\n    \"\"\"\n\n    specific_columns = (SPACE_ID_COLUMN, STOREY_LEVEL_COLUMN, STOREY_SPACE_ID_COLUMN)\n    key_index = 0\n    key_builder_index = None\n\n    def __init__(\n        self,\n        attributes: dict[str, Any],\n        space_id: str,\n        storey_level: float,\n        storey_space_id: str,\n    ) -&gt; None:\n        super().__init__(attributes=attributes, cj_key=space_id, icon_position=None)\n        self.space_id = space_id\n        self.storey_level = storey_level\n        self.storey_space_id = storey_space_id\n</code></pre>"},{"location":"reference/cj_helpers/cj_attributes/#cj_helpers.cj_attributes.BdgStoreyAttrReader","title":"<code>BdgStoreyAttrReader</code>","text":"<p>               Bases: <code>cj_helpers.cj_attributes.AttrReader[cj_helpers.cj_attributes.BdgStoreyAttr]</code></p> <p>Class to read attributes of BuildingStorey objects from CSV.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_attributes.py</code> <pre><code>class BdgStoreyAttrReader(AttrReader[BdgStoreyAttr]):\n    \"\"\"\n    Class to read attributes of BuildingStorey objects from CSV.\n    \"\"\"\n\n    attr_class = BdgStoreyAttr\n\n    def __init__(self, csv_path: Path) -&gt; None:\n        super().__init__(csv_path)\n</code></pre>"},{"location":"reference/cj_helpers/cj_attributes/#cj_helpers.cj_attributes.BdgSubAttr","title":"<code>BdgSubAttr</code>","text":"<p>               Bases: <code>cj_helpers.cj_attributes.Attr</code></p> <p>Class to store the attributes of building subdivisions.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_attributes.py</code> <pre><code>class BdgSubAttr(Attr):\n    \"\"\"\n    Class to store the attributes of building subdivisions.\n    \"\"\"\n\n    specific_columns = (\n        KEY_COLUMN,\n        SPACE_ID_COLUMN,\n        PARENT_KEY_COLUMN,\n        SKIP_COLUMN,\n        ICON_POSITION_COLUMN,\n    )\n    key_index = 0\n    key_builder_index = None\n\n    def __init__(\n        self,\n        attributes: dict[str, Any],\n        cj_key: str,\n        space_id: str,\n        icon_position: IconPosition | list[float] | None,\n        parent_cj_key: str,\n        skip: bool,\n    ) -&gt; None:\n        super().__init__(\n            attributes=attributes, cj_key=cj_key, icon_position=icon_position\n        )\n        self.parent_cj_key = parent_cj_key\n        self.skip = skip\n        self.space_id = space_id\n</code></pre>"},{"location":"reference/cj_helpers/cj_attributes/#cj_helpers.cj_attributes.BdgSubAttrReader","title":"<code>BdgSubAttrReader</code>","text":"<p>               Bases: <code>cj_helpers.cj_attributes.AttrReader[cj_helpers.cj_attributes.BdgSubAttr]</code></p> <p>Class to read attributes of building subdivisions from CSV.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_attributes.py</code> <pre><code>class BdgSubAttrReader(AttrReader[BdgSubAttr]):\n    \"\"\"\n    Class to read attributes of building subdivisions from CSV.\n    \"\"\"\n\n    attr_class = BdgSubAttr\n\n    def __init__(self, csv_path: Path) -&gt; None:\n        super().__init__(csv_path)\n</code></pre>"},{"location":"reference/cj_helpers/cj_attributes/#cj_helpers.cj_attributes.BdgUnitAttr","title":"<code>BdgUnitAttr</code>","text":"<p>               Bases: <code>cj_helpers.cj_attributes.Attr</code></p> <p>Class to store the attributes of BuildingUnit objects.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_attributes.py</code> <pre><code>class BdgUnitAttr(Attr):\n    \"\"\"\n    Class to store the attributes of BuildingUnit objects.\n    \"\"\"\n\n    specific_columns = (\n        ICON_POSITION_COLUMN,\n        CODE_COLUMN,\n        UNIT_GLTF_COLUMN,\n        UNIT_SPACES_COLUMN,\n        UNIT_STOREYS_COLUMN,\n    )\n    key_index = None\n    key_builder_index = 0\n\n    def __init__(\n        self,\n        attributes: dict[str, Any],\n        cj_key: str,\n        icon_position: IconPosition | list[float] | None,\n        code: str,\n        unit_gltf: str,\n        unit_spaces: list[str],\n        unit_storeys: list[str],\n    ) -&gt; None:\n        super().__init__(\n            attributes=attributes, cj_key=cj_key, icon_position=icon_position\n        )\n        self.code = code\n        self.unit_gltf = None if unit_gltf == \"\" else unit_gltf\n        self.unit_spaces = unit_spaces\n        self.unit_storeys = unit_storeys\n\n        if len(self.unit_storeys) == 0:\n            unit_storeys_set: set[str] = set()\n            for space in self.unit_spaces:\n                space_split = space.split(\".\")\n                if len(space.split(\".\")) &lt; 3:\n                    continue\n                storey = \".\".join(space_split[:3])\n                unit_storeys_set.add(storey)\n            self.unit_storeys = list(unit_storeys_set)\n</code></pre>"},{"location":"reference/cj_helpers/cj_attributes/#cj_helpers.cj_attributes.BdgUnitAttrReader","title":"<code>BdgUnitAttrReader</code>","text":"<p>               Bases: <code>cj_helpers.cj_attributes.AttrReader[cj_helpers.cj_attributes.BdgUnitAttr]</code></p> <p>Class to read attributes of BuildingUnit objects from CSV.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_attributes.py</code> <pre><code>class BdgUnitAttrReader(AttrReader[BdgUnitAttr]):\n    \"\"\"\n    Class to read attributes of BuildingUnit objects from CSV.\n    \"\"\"\n\n    attr_class = BdgUnitAttr\n\n    def __init__(self, csv_path: Path) -&gt; None:\n        super().__init__(csv_path)\n</code></pre>"},{"location":"reference/cj_helpers/cj_geometry/","title":"cj_geometry","text":"<p>Classes to handle the geometry of the CityJSON objects.</p> <p>Classes:</p> Name Description <code>CityJSONGeometries</code> <p>Class to handle a list of geometries and process them together.</p> <code>Geometry</code> <p>Base class for a CityJSON geometry object.</p> <code>MultiSurface</code>"},{"location":"reference/cj_helpers/cj_geometry/#cj_helpers.cj_geometry.CityJSONGeometries","title":"<code>CityJSONGeometries</code>","text":"<p>Class to handle a list of geometries and process them together.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Create a handle for multiple geometry objects.</p> <code>get_geometry_cj</code> <p>Return all the geometries in CityJSON format, with deduplicated vertices.</p> <code>get_optimal_translate</code> <p>Compute the optimal translation for the list of geometries, computed as the average of all the unique vertices.</p> <code>get_vertices_cj</code> <p>Return all the deduplicated vertices in CityJSON format, scaled and translated according to the given arguments.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_geometry.py</code> <pre><code>class CityJSONGeometries:\n    \"\"\"\n    Class to handle a list of geometries and process them together.\n    \"\"\"\n\n    def __init__(self, geometries: Sequence[Geometry]) -&gt; None:\n        \"\"\"\n        Create a handle for multiple geometry objects.\n\n        Parameters\n        ----------\n        geometries : Sequence[Geometry]\n            List of Geometry or subclasses to handle.\n        \"\"\"\n        self.geometries = list(geometries)\n        self.unique_vertices, self.boundaries = self._deduplicate_vertices()\n\n    def get_optimal_translate(self, scale: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n        \"\"\"\n        Compute the optimal translation for the list of geometries, computed as the average of all the unique vertices.\n\n        Parameters\n        ----------\n        scale : NDArray[np.float64]\n            Array of shape (3,) containing the scale used to store the vertices.\n            Used to round the computed translation.\n\n        Returns\n        -------\n        NDArray[np.float64]\n            Array of shape (3,) containing the computed translation.\n        \"\"\"\n        if self.unique_vertices.shape[0] == 0:\n            return np.array([0, 0, 0], dtype=np.float64)\n        translate = np.mean(self.unique_vertices, axis=0, dtype=np.float64)\n        # Apply the scale to have a coherent precision\n        translate = np.round(translate / scale) * scale\n        assert isinstance(translate, np.ndarray)\n        return translate\n\n    def get_geometry_cj(self) -&gt; list[dict[str, Any]]:\n        \"\"\"\n        Return all the geometries in CityJSON format, with deduplicated vertices.\n\n        Returns\n        -------\n        list[dict[str, Any]]\n            The list of all geometries\n        \"\"\"\n        formatted = []\n        for geometry, true_boundaries in zip(self.geometries, self.boundaries):\n            formatted.append(\n                geometry.to_cityjson_format(replace_boundaries=true_boundaries)\n            )\n        return formatted\n\n    def get_vertices_cj(\n        self, scale: NDArray[np.float64], translate: NDArray[np.float64]\n    ) -&gt; list[list[int]]:\n        \"\"\"\n        Return all the deduplicated vertices in CityJSON format, scaled and translated according to the given arguments.\n\n        Parameters\n        ----------\n        scale : NDArray[np.float64]\n            Array of shape (3,) containing the scale used to store the vertices.\n        translate : NDArray[np.float64]\n            Array of shape (3,) containing the translation used to store the vertices.\n\n        Returns\n        -------\n        list[list[int]]\n            List of shape (N, 3) containing all the vertices coordinates.\n        \"\"\"\n        vertices = (self.unique_vertices - translate) / scale\n        vertices_int64 = np.round(vertices).astype(np.int64)\n        vertices_int = list(map(lambda v: list(map(int, v)), vertices_int64.tolist()))\n        return vertices_int\n\n    def _deduplicate_vertices(\n        self,\n    ) -&gt; tuple[NDArray[np.float64], list[Any]]:\n        \"\"\"\n        Deduplicate the vertices and recompute the boundaries accordingly.\n\n        Returns\n        -------\n        unique_vertices: NDArray[np.float64]\n            Array of shape (N, 3) with the deduplicated vertices\n        new_boundaries: list[Any]\n            List of the new boundaries\n        \"\"\"\n        # Gather all vertices in the order they appear\n        all_vertices: list[NDArray[np.float64]] = []\n        offsets: list[int] = []\n\n        last_offset = 0\n        for geom in self.geometries:\n            offsets.append(last_offset)\n            all_vertices.append(geom.vertices)\n            last_offset += all_vertices[-1].shape[0]\n\n        # Concatenate into a single array\n        if not all_vertices:\n            return (np.empty((0, 3), dtype=np.float64), [])\n\n        concat_vertices = np.vstack(all_vertices)\n\n        # Remove duplicate vertices and store the index mapping\n        unique_vertices, old_to_new_idx = np.unique(\n            concat_vertices, return_inverse=True, axis=0\n        )\n\n        # Re\u2011index each geometry's boundaries\n        new_boundaries: list[Any] = []\n\n        for geom, offset in zip(self.geometries, offsets):\n            # Translate to the deduplicated index space.\n            remapped = _remap_boundaries(\n                boundaries=geom.boundaries, offset=offset, mapping=old_to_new_idx\n            )\n            new_boundaries.append(remapped)\n\n        return unique_vertices, new_boundaries\n</code></pre>"},{"location":"reference/cj_helpers/cj_geometry/#cj_helpers.cj_geometry.CityJSONGeometries.__init__","title":"<code>__init__(geometries)</code>","text":"<p>Create a handle for multiple geometry objects.</p> <p>Parameters:</p> Name Type Description Default <code>geometries</code> <code>typing.Sequence[cj_helpers.cj_geometry.Geometry]</code> <p>List of Geometry or subclasses to handle.</p> required Source code in <code>python/src/data_pipeline/cj_helpers/cj_geometry.py</code> <pre><code>def __init__(self, geometries: Sequence[Geometry]) -&gt; None:\n    \"\"\"\n    Create a handle for multiple geometry objects.\n\n    Parameters\n    ----------\n    geometries : Sequence[Geometry]\n        List of Geometry or subclasses to handle.\n    \"\"\"\n    self.geometries = list(geometries)\n    self.unique_vertices, self.boundaries = self._deduplicate_vertices()\n</code></pre>"},{"location":"reference/cj_helpers/cj_geometry/#cj_helpers.cj_geometry.CityJSONGeometries.get_geometry_cj","title":"<code>get_geometry_cj()</code>","text":"<p>Return all the geometries in CityJSON format, with deduplicated vertices.</p> <p>Returns:</p> Type Description <code>list[dict[str, typing.Any]]</code> <p>The list of all geometries</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_geometry.py</code> <pre><code>def get_geometry_cj(self) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Return all the geometries in CityJSON format, with deduplicated vertices.\n\n    Returns\n    -------\n    list[dict[str, Any]]\n        The list of all geometries\n    \"\"\"\n    formatted = []\n    for geometry, true_boundaries in zip(self.geometries, self.boundaries):\n        formatted.append(\n            geometry.to_cityjson_format(replace_boundaries=true_boundaries)\n        )\n    return formatted\n</code></pre>"},{"location":"reference/cj_helpers/cj_geometry/#cj_helpers.cj_geometry.CityJSONGeometries.get_optimal_translate","title":"<code>get_optimal_translate(scale)</code>","text":"<p>Compute the optimal translation for the list of geometries, computed as the average of all the unique vertices.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>Array of shape (3,) containing the scale used to store the vertices. Used to round the computed translation.</p> required <p>Returns:</p> Type Description <code>numpy.typing.NDArray[numpy.float64]</code> <p>Array of shape (3,) containing the computed translation.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_geometry.py</code> <pre><code>def get_optimal_translate(self, scale: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n    \"\"\"\n    Compute the optimal translation for the list of geometries, computed as the average of all the unique vertices.\n\n    Parameters\n    ----------\n    scale : NDArray[np.float64]\n        Array of shape (3,) containing the scale used to store the vertices.\n        Used to round the computed translation.\n\n    Returns\n    -------\n    NDArray[np.float64]\n        Array of shape (3,) containing the computed translation.\n    \"\"\"\n    if self.unique_vertices.shape[0] == 0:\n        return np.array([0, 0, 0], dtype=np.float64)\n    translate = np.mean(self.unique_vertices, axis=0, dtype=np.float64)\n    # Apply the scale to have a coherent precision\n    translate = np.round(translate / scale) * scale\n    assert isinstance(translate, np.ndarray)\n    return translate\n</code></pre>"},{"location":"reference/cj_helpers/cj_geometry/#cj_helpers.cj_geometry.CityJSONGeometries.get_vertices_cj","title":"<code>get_vertices_cj(scale, translate)</code>","text":"<p>Return all the deduplicated vertices in CityJSON format, scaled and translated according to the given arguments.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>Array of shape (3,) containing the scale used to store the vertices.</p> required <code>translate</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>Array of shape (3,) containing the translation used to store the vertices.</p> required <p>Returns:</p> Type Description <code>list[list[int]]</code> <p>List of shape (N, 3) containing all the vertices coordinates.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_geometry.py</code> <pre><code>def get_vertices_cj(\n    self, scale: NDArray[np.float64], translate: NDArray[np.float64]\n) -&gt; list[list[int]]:\n    \"\"\"\n    Return all the deduplicated vertices in CityJSON format, scaled and translated according to the given arguments.\n\n    Parameters\n    ----------\n    scale : NDArray[np.float64]\n        Array of shape (3,) containing the scale used to store the vertices.\n    translate : NDArray[np.float64]\n        Array of shape (3,) containing the translation used to store the vertices.\n\n    Returns\n    -------\n    list[list[int]]\n        List of shape (N, 3) containing all the vertices coordinates.\n    \"\"\"\n    vertices = (self.unique_vertices - translate) / scale\n    vertices_int64 = np.round(vertices).astype(np.int64)\n    vertices_int = list(map(lambda v: list(map(int, v)), vertices_int64.tolist()))\n    return vertices_int\n</code></pre>"},{"location":"reference/cj_helpers/cj_geometry/#cj_helpers.cj_geometry.Geometry","title":"<code>Geometry</code>","text":"<p>               Bases: <code>abc.ABC</code></p> <p>Base class for a CityJSON geometry object.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Base class for a CityJSON geometry object.</p> <code>to_cityjson_format</code> <p>Export the geometry to the expected CityJSON format.</p> <code>to_trimesh</code> <p>Export the geometry to a Trimesh</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_geometry.py</code> <pre><code>class Geometry(ABC):\n    \"\"\"\n    Base class for a CityJSON geometry object.\n    \"\"\"\n\n    def __init__(\n        self,\n        lod: int,\n        type_str: str,\n        vertices: NDArray[np.float64],\n        boundaries: list[Any],\n    ) -&gt; None:\n        \"\"\"\n        Base class for a CityJSON geometry object.\n\n        Parameters\n        ----------\n        lod : int\n            Level of detail.\n        type_str : str\n            Type of geometry.\n        vertices : NDArray[np.float64]\n            Array of vertices coordinates.\n        boundaries : list[Any]\n            Array of indices referencing `vertices` to define the boundaries of the geometry.\n        \"\"\"\n        self.lod = lod\n        self.type = type_str\n        self.vertices = vertices\n        self.boundaries = boundaries\n\n    @abstractmethod\n    def to_cityjson_format(\n        self, replace_boundaries: list[Any] | None\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Export the geometry to the expected CityJSON format.\n\n        Parameters\n        ----------\n        replace_boundaries : list[Any] | None\n            Whether to replace the current boundaries with new boundaries.\n\n        Returns\n        -------\n        dict[str, Any]\n            The CityJSON representation of this geometry.\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def to_trimesh(self) -&gt; Trimesh:\n        \"\"\"\n        Export the geometry to a Trimesh\n\n        Returns\n        -------\n        Trimesh\n            A Trimesh corresponding to this geometry.\n        \"\"\"\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/cj_helpers/cj_geometry/#cj_helpers.cj_geometry.Geometry.__init__","title":"<code>__init__(lod, type_str, vertices, boundaries)</code>","text":"<p>Base class for a CityJSON geometry object.</p> <p>Parameters:</p> Name Type Description Default <code>lod</code> <code>int</code> <p>Level of detail.</p> required <code>type_str</code> <code>str</code> <p>Type of geometry.</p> required <code>vertices</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>Array of vertices coordinates.</p> required <code>boundaries</code> <code>list[typing.Any]</code> <p>Array of indices referencing <code>vertices</code> to define the boundaries of the geometry.</p> required Source code in <code>python/src/data_pipeline/cj_helpers/cj_geometry.py</code> <pre><code>def __init__(\n    self,\n    lod: int,\n    type_str: str,\n    vertices: NDArray[np.float64],\n    boundaries: list[Any],\n) -&gt; None:\n    \"\"\"\n    Base class for a CityJSON geometry object.\n\n    Parameters\n    ----------\n    lod : int\n        Level of detail.\n    type_str : str\n        Type of geometry.\n    vertices : NDArray[np.float64]\n        Array of vertices coordinates.\n    boundaries : list[Any]\n        Array of indices referencing `vertices` to define the boundaries of the geometry.\n    \"\"\"\n    self.lod = lod\n    self.type = type_str\n    self.vertices = vertices\n    self.boundaries = boundaries\n</code></pre>"},{"location":"reference/cj_helpers/cj_geometry/#cj_helpers.cj_geometry.Geometry.to_cityjson_format","title":"<code>to_cityjson_format(replace_boundaries)</code>  <code>abstractmethod</code>","text":"<p>Export the geometry to the expected CityJSON format.</p> <p>Parameters:</p> Name Type Description Default <code>replace_boundaries</code> <code>list[typing.Any] | None</code> <p>Whether to replace the current boundaries with new boundaries.</p> required <p>Returns:</p> Type Description <code>dict[str, typing.Any]</code> <p>The CityJSON representation of this geometry.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_geometry.py</code> <pre><code>@abstractmethod\ndef to_cityjson_format(\n    self, replace_boundaries: list[Any] | None\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Export the geometry to the expected CityJSON format.\n\n    Parameters\n    ----------\n    replace_boundaries : list[Any] | None\n        Whether to replace the current boundaries with new boundaries.\n\n    Returns\n    -------\n    dict[str, Any]\n        The CityJSON representation of this geometry.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/cj_helpers/cj_geometry/#cj_helpers.cj_geometry.Geometry.to_trimesh","title":"<code>to_trimesh()</code>  <code>abstractmethod</code>","text":"<p>Export the geometry to a Trimesh</p> <p>Returns:</p> Type Description <code>trimesh.Trimesh</code> <p>A Trimesh corresponding to this geometry.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_geometry.py</code> <pre><code>@abstractmethod\ndef to_trimesh(self) -&gt; Trimesh:\n    \"\"\"\n    Export the geometry to a Trimesh\n\n    Returns\n    -------\n    Trimesh\n        A Trimesh corresponding to this geometry.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/cj_helpers/cj_geometry/#cj_helpers.cj_geometry.MultiSurface","title":"<code>MultiSurface</code>","text":"<p>               Bases: <code>cj_helpers.cj_geometry.Geometry</code></p> <p>Methods:</p> Name Description <code>__init__</code> <p>MultiSurface geometry object.</p> <code>from_mesh</code> <p>Generate a MultiSurface from a Trimesh object, and set its lod.</p> <code>to_cityjson_format</code> <p>Export the geometry to the expected CityJSON format.</p> <code>to_trimesh</code> <p>Export the geometry to a Trimesh</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_geometry.py</code> <pre><code>class MultiSurface(Geometry):\n\n    def __init__(\n        self,\n        lod: int,\n        vertices: NDArray[np.float64],\n        boundaries: list[list[NDArray[np.float64]]],\n    ) -&gt; None:\n        \"\"\"\n        MultiSurface geometry object.\n\n        Parameters\n        ----------\n        lod : int\n            Level of detail.\n        vertices : NDArray[np.float64]\n            Array of vertices coordinates.\n        boundaries : list[list[NDArray[np.float64]]]\n            Array of indices referencing `vertices` to define the boundaries of the geometry.\n        \"\"\"\n\n        super().__init__(\n            type_str=\"MultiSurface\", lod=lod, vertices=vertices, boundaries=boundaries\n        )\n        self.boundaries: list[list[NDArray[np.float64]]] = boundaries\n\n    @classmethod\n    def from_mesh(cls, lod: int, mesh: Trimesh) -&gt; MultiSurface:\n        \"\"\"\n        Generate a MultiSurface from a Trimesh object, and set its lod.\n\n        Parameters\n        ----------\n        lod : int\n            Level of detail.\n        mesh : Trimesh\n            Trimesh to store as a MultiSurface.\n\n        Returns\n        -------\n        MultiSurface\n            The generated MultiSurface.\n        \"\"\"\n        vertices = mesh.vertices.astype(np.float64)\n        tri_faces = mesh.faces.astype(np.int64)\n\n        # Format for CityJSON\n        surfaces = []\n        for face in tri_faces:\n            surfaces.append([face])\n\n        return cls(lod=lod, vertices=vertices, boundaries=surfaces)\n\n    def to_cityjson_format(\n        self, replace_boundaries: list[list[NDArray[np.float64]]] | None\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Export the geometry to the expected CityJSON format.\n\n        Parameters\n        ----------\n        replace_boundaries : list[list[NDArray[np.float64]]] | None\n            Whether to replace the current boundaries with new boundaries.\n\n        Returns\n        -------\n        dict[str, Any]\n            The CityJSON representation of this geometry.\n        \"\"\"\n        boundaries = (\n            self.boundaries if replace_boundaries is None else replace_boundaries\n        )\n        boundaries = [[poly.tolist() for poly in surface] for surface in boundaries]\n        return {\"type\": self.type, \"lod\": str(self.lod), \"boundaries\": boundaries}\n\n    def to_trimesh(self) -&gt; Trimesh:\n        \"\"\"\n        Export the geometry to a Trimesh\n\n        Returns\n        -------\n        Trimesh\n            A Trimesh corresponding to this geometry.\n        \"\"\"\n        tri_faces = []\n        for boundary in self.boundaries:\n            tri_faces.append(boundary[0])\n\n        return Trimesh(vertices=self.vertices, faces=tri_faces)\n</code></pre>"},{"location":"reference/cj_helpers/cj_geometry/#cj_helpers.cj_geometry.MultiSurface.__init__","title":"<code>__init__(lod, vertices, boundaries)</code>","text":"<p>MultiSurface geometry object.</p> <p>Parameters:</p> Name Type Description Default <code>lod</code> <code>int</code> <p>Level of detail.</p> required <code>vertices</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>Array of vertices coordinates.</p> required <code>boundaries</code> <code>list[list[numpy.typing.NDArray[numpy.float64]]]</code> <p>Array of indices referencing <code>vertices</code> to define the boundaries of the geometry.</p> required Source code in <code>python/src/data_pipeline/cj_helpers/cj_geometry.py</code> <pre><code>def __init__(\n    self,\n    lod: int,\n    vertices: NDArray[np.float64],\n    boundaries: list[list[NDArray[np.float64]]],\n) -&gt; None:\n    \"\"\"\n    MultiSurface geometry object.\n\n    Parameters\n    ----------\n    lod : int\n        Level of detail.\n    vertices : NDArray[np.float64]\n        Array of vertices coordinates.\n    boundaries : list[list[NDArray[np.float64]]]\n        Array of indices referencing `vertices` to define the boundaries of the geometry.\n    \"\"\"\n\n    super().__init__(\n        type_str=\"MultiSurface\", lod=lod, vertices=vertices, boundaries=boundaries\n    )\n    self.boundaries: list[list[NDArray[np.float64]]] = boundaries\n</code></pre>"},{"location":"reference/cj_helpers/cj_geometry/#cj_helpers.cj_geometry.MultiSurface.from_mesh","title":"<code>from_mesh(lod, mesh)</code>  <code>classmethod</code>","text":"<p>Generate a MultiSurface from a Trimesh object, and set its lod.</p> <p>Parameters:</p> Name Type Description Default <code>lod</code> <code>int</code> <p>Level of detail.</p> required <code>mesh</code> <code>trimesh.Trimesh</code> <p>Trimesh to store as a MultiSurface.</p> required <p>Returns:</p> Type Description <code>cj_helpers.cj_geometry.MultiSurface</code> <p>The generated MultiSurface.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_geometry.py</code> <pre><code>@classmethod\ndef from_mesh(cls, lod: int, mesh: Trimesh) -&gt; MultiSurface:\n    \"\"\"\n    Generate a MultiSurface from a Trimesh object, and set its lod.\n\n    Parameters\n    ----------\n    lod : int\n        Level of detail.\n    mesh : Trimesh\n        Trimesh to store as a MultiSurface.\n\n    Returns\n    -------\n    MultiSurface\n        The generated MultiSurface.\n    \"\"\"\n    vertices = mesh.vertices.astype(np.float64)\n    tri_faces = mesh.faces.astype(np.int64)\n\n    # Format for CityJSON\n    surfaces = []\n    for face in tri_faces:\n        surfaces.append([face])\n\n    return cls(lod=lod, vertices=vertices, boundaries=surfaces)\n</code></pre>"},{"location":"reference/cj_helpers/cj_geometry/#cj_helpers.cj_geometry.MultiSurface.to_cityjson_format","title":"<code>to_cityjson_format(replace_boundaries)</code>","text":"<p>Export the geometry to the expected CityJSON format.</p> <p>Parameters:</p> Name Type Description Default <code>replace_boundaries</code> <code>list[list[numpy.typing.NDArray[numpy.float64]]] | None</code> <p>Whether to replace the current boundaries with new boundaries.</p> required <p>Returns:</p> Type Description <code>dict[str, typing.Any]</code> <p>The CityJSON representation of this geometry.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_geometry.py</code> <pre><code>def to_cityjson_format(\n    self, replace_boundaries: list[list[NDArray[np.float64]]] | None\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Export the geometry to the expected CityJSON format.\n\n    Parameters\n    ----------\n    replace_boundaries : list[list[NDArray[np.float64]]] | None\n        Whether to replace the current boundaries with new boundaries.\n\n    Returns\n    -------\n    dict[str, Any]\n        The CityJSON representation of this geometry.\n    \"\"\"\n    boundaries = (\n        self.boundaries if replace_boundaries is None else replace_boundaries\n    )\n    boundaries = [[poly.tolist() for poly in surface] for surface in boundaries]\n    return {\"type\": self.type, \"lod\": str(self.lod), \"boundaries\": boundaries}\n</code></pre>"},{"location":"reference/cj_helpers/cj_geometry/#cj_helpers.cj_geometry.MultiSurface.to_trimesh","title":"<code>to_trimesh()</code>","text":"<p>Export the geometry to a Trimesh</p> <p>Returns:</p> Type Description <code>trimesh.Trimesh</code> <p>A Trimesh corresponding to this geometry.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_geometry.py</code> <pre><code>def to_trimesh(self) -&gt; Trimesh:\n    \"\"\"\n    Export the geometry to a Trimesh\n\n    Returns\n    -------\n    Trimesh\n        A Trimesh corresponding to this geometry.\n    \"\"\"\n    tri_faces = []\n    for boundary in self.boundaries:\n        tri_faces.append(boundary[0])\n\n    return Trimesh(vertices=self.vertices, faces=tri_faces)\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/","title":"cj_objects","text":"<p>Classes to format and normalize CityJSON objects and files.</p> <p>Classes:</p> Name Description <code>Building</code> <p>Class to store Building objects.</p> <code>BuildingPart</code> <p>Class to store BuildingPart objects.</p> <code>BuildingRoom</code> <p>Class to store BuildingRoom objects.</p> <code>BuildingStorey</code> <p>Class to store BuildingStorey objects.</p> <code>BuildingUnit</code> <p>Class used to store a single BuildingUnit object.</p> <code>BuildingUnitContainer</code> <p>Class used to group together all the BuildingUnit objects per code.</p> <code>BuildingUnitObject</code> <p>Class used to represent the object, child of the Building, that will be the parent of all the BuildingUnitContainer objects.</p> <code>CityJSONFile</code> <p>Main CityJSON file handler, allowing to store CityJSON objects and write them to a file by checking the correctness of the hierarchy.</p> <code>CityJSONObject</code> <p>Abstract base class to handle CityJSON objects.</p> <code>CityJSONSpace</code> <p>Abstract base class to handle CityJSON objects in the room hierarchy (i.e. Building,</p> <code>OutdoorObject</code> <p>Class used to represent the object, root of the file, that will be the parent of all the OutdoorUnitContainer objects.</p> <code>OutdoorUnit</code> <p>Class used to store a single OutdoorUnit object.</p> <code>OutdoorUnitContainer</code> <p>Class used to group together all the OutdoorUnit objects per code.</p>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.Building","title":"<code>Building</code>","text":"<p>               Bases: <code>cj_helpers.cj_objects.CityJSONSpace</code></p> <p>Class to store Building objects.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>class Building(CityJSONSpace):\n    \"\"\"\n    Class to store Building objects.\n    \"\"\"\n\n    type_name = \"Building\"\n    icon_z_offset = 2\n\n    def __init__(\n        self,\n        cj_key: str,\n        space_id: str,\n        attributes: dict[str, Any] | None = None,\n        geometries: Sequence[Geometry] | None = None,\n        icon_position: IconPosition | None = None,\n    ) -&gt; None:\n        super().__init__(\n            cj_key=cj_key,\n            space_id=space_id,\n            attributes=attributes,\n            geometries=geometries,\n            icon_position=icon_position,\n        )\n\n    def apply_attr(self, attr: BdgAttr, overwrite: bool) -&gt; None:\n        self.add_attributes(new_attributes=attr.attributes)\n        if attr.icon_position is not None:\n            self.set_icon(attr.icon_position, overwrite=overwrite)\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.BuildingPart","title":"<code>BuildingPart</code>","text":"<p>               Bases: <code>cj_helpers.cj_objects.CityJSONSpace</code></p> <p>Class to store BuildingPart objects.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>class BuildingPart(CityJSONSpace):\n    \"\"\"\n    Class to store BuildingPart objects.\n    \"\"\"\n\n    type_name = \"BuildingPart\"\n    icon_z_offset = 1\n\n    def __init__(\n        self,\n        cj_key: str,\n        space_id: str,\n        attributes: dict[str, Any] | None = None,\n        geometries: Sequence[Geometry] | None = None,\n        icon_position: IconPosition | None = None,\n    ) -&gt; None:\n        super().__init__(\n            cj_key=cj_key,\n            space_id=space_id,\n            attributes=attributes,\n            geometries=geometries,\n            icon_position=icon_position,\n        )\n\n    def apply_attr(self, attr: BdgPartAttr, overwrite: bool) -&gt; None:\n        self.add_attributes(new_attributes=attr.attributes)\n        if attr.icon_position is not None:\n            self.set_icon(attr.icon_position, overwrite=overwrite)\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.BuildingRoom","title":"<code>BuildingRoom</code>","text":"<p>               Bases: <code>cj_helpers.cj_objects.CityJSONSpace</code></p> <p>Class to store BuildingRoom objects.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>class BuildingRoom(CityJSONSpace):\n    \"\"\"\n    Class to store BuildingRoom objects.\n    \"\"\"\n\n    type_name = \"BuildingRoom\"\n    icon_z_offset = 0.5\n\n    def __init__(\n        self,\n        cj_key: str,\n        space_id: str,\n        attributes: dict[str, Any] | None = None,\n        geometries: Sequence[Geometry] | None = None,\n        icon_position: IconPosition | None = None,\n    ) -&gt; None:\n        super().__init__(\n            cj_key=cj_key,\n            space_id=space_id,\n            attributes=attributes,\n            geometries=geometries,\n            icon_position=icon_position,\n        )\n\n    def apply_attr(self, attr: BdgRoomAttr, overwrite: bool) -&gt; None:\n        self.add_attributes(new_attributes=attr.attributes)\n        if attr.icon_position is not None:\n            self.set_icon(attr.icon_position, overwrite=overwrite)\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.BuildingStorey","title":"<code>BuildingStorey</code>","text":"<p>               Bases: <code>cj_helpers.cj_objects.CityJSONSpace</code></p> <p>Class to store BuildingStorey objects.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>class BuildingStorey(CityJSONSpace):\n    \"\"\"\n    Class to store BuildingStorey objects.\n    \"\"\"\n\n    type_name = \"BuildingStorey\"\n    icon_z_offset = 0.5\n\n    def __init__(\n        self,\n        cj_key: str,\n        space_id: str,\n        attributes: dict[str, Any] | None = None,\n        geometries: Sequence[Geometry] | None = None,\n        icon_position: IconPosition | None = None,\n    ) -&gt; None:\n        super().__init__(\n            cj_key=cj_key,\n            space_id=space_id,\n            attributes=attributes,\n            geometries=geometries,\n            icon_position=icon_position,\n        )\n\n    def apply_attr(self, attr: BdgStoreyAttr, overwrite: bool) -&gt; None:\n        self.add_attributes(new_attributes=attr.attributes)\n        self.add_attributes(\n            new_attributes={\n                ARGUMENT_TO_NAME[\"storey_level\"]: attr.storey_level,\n                ARGUMENT_TO_NAME[\"storey_space_id\"]: attr.storey_space_id,\n            }\n        )\n        if attr.icon_position is not None:\n            self.set_icon(attr.icon_position, overwrite=overwrite)\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.BuildingUnit","title":"<code>BuildingUnit</code>","text":"<p>               Bases: <code>cj_helpers.cj_objects.CityJSONObject</code></p> <p>Class used to store a single BuildingUnit object. BuildingUnit objects can: - be linked to a group of CityJSONSpace objects, - have their own geometry, - or none of them (only the icon).</p> <p>Methods:</p> Name Description <code>unit_code_to_cj_key</code> <p>Formats the CityJSON key (i.e. the id) based on the code of the units that it stores, and a number.</p> <code>unit_code_to_code_instance</code> <p>Generate an identifier based on the given index.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>class BuildingUnit(CityJSONObject):\n    \"\"\"\n    Class used to store a single BuildingUnit object.\n    BuildingUnit objects can:\n    - be linked to a group of CityJSONSpace objects,\n    - have their own geometry,\n    - or none of them (only the icon).\n    \"\"\"\n\n    type_name = \"BuildingUnit\"\n    icon_z_offset = 0.5\n    id_prefix = \"BuildingUnit\"\n\n    def __init__(\n        self,\n        cj_key: str,\n        unit_code: str,\n        unit_storeys: list[str],\n        geometry: Geometry | None = None,\n        attributes: dict[str, Any] | None = None,\n        icon_position: IconPosition | None = None,\n    ) -&gt; None:\n        geometries = [geometry] if geometry is not None else None\n        super().__init__(\n            cj_key=cj_key,\n            geometries=geometries,\n            attributes=attributes,\n            icon_position=icon_position,\n        )\n        self.unit_code = unit_code\n        code_name = ARGUMENT_TO_NAME[\"code\"]\n        self.add_attributes({code_name: unit_code})\n\n        self.unit_storeys = unit_storeys\n        storeys_name = ARGUMENT_TO_NAME[\"unit_storeys\"]\n        self.add_attributes({storeys_name: unit_storeys})\n\n        self.unit_spaces: set[str] = set()\n\n    def _add_space(self, new_space_id: str) -&gt; None:\n        \"\"\"\n        Add a space that this unit contains.\n\n        Parameters\n        ----------\n        new_space_id : str\n            Id of the space.\n        \"\"\"\n        self.unit_spaces.add(new_space_id)\n\n    def get_cityobject(self) -&gt; dict[str, Any]:\n        unit_spaces_key = ARGUMENT_TO_NAME[\"unit_spaces\"]\n        self.add_attributes({unit_spaces_key: list(self.unit_spaces)})\n        content_dict = super().get_cityobject()\n        # Remove it from the attributes to ensure the object is unchanged\n        self.attributes.pop(unit_spaces_key)\n        return content_dict\n\n    @classmethod\n    def unit_code_to_code_instance(cls, code: str, index: int) -&gt; str:\n        \"\"\"\n        Generate an identifier based on the given index.\n        The uniqueness of the identifier is not checked, but has to be ensured by providing a combination of inputs not used by another BuildingUnit.\n\n        Parameters\n        ----------\n        code : str\n            The usage code.\n        index : int\n            The index of the unit.\n\n        Returns\n        -------\n        str\n            A formatted identifier\n        \"\"\"\n        index_str = str(index).replace(\".\", \"_\").replace(\"-\", \"_\")\n        code = code.replace(\".\", \"_\").replace(\"-\", \"_\")\n        return f\"{code}@{index_str}\"\n\n    @classmethod\n    def unit_code_to_cj_key(cls, code: str, prefix: str, index: int) -&gt; str:\n        \"\"\"\n        Formats the CityJSON key (i.e. the id) based on the code of the units that it stores, and a number.\n\n        Parameters\n        ----------\n        code : str\n            The usage code.\n        prefix : str\n            The building prefix.\n        index : int\n            The index of the unit.\n\n        Returns\n        -------\n        str\n            The id.\n        \"\"\"\n        code_instance = cls.unit_code_to_code_instance(code=code, index=index)\n        prefix = prefix.replace(\"-\", \"_\")\n        return f\"{prefix}-{cls.type_name}-{cls.id_prefix}_{code_instance}\"\n\n    def apply_attr(self, attr: BdgUnitAttr, overwrite: bool) -&gt; None:\n        self.add_attributes(new_attributes=attr.attributes)\n        if attr.icon_position is not None:\n            self.set_icon(attr.icon_position, overwrite=overwrite)\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.BuildingUnit.unit_code_to_cj_key","title":"<code>unit_code_to_cj_key(code, prefix, index)</code>  <code>classmethod</code>","text":"<p>Formats the CityJSON key (i.e. the id) based on the code of the units that it stores, and a number.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>The usage code.</p> required <code>prefix</code> <code>str</code> <p>The building prefix.</p> required <code>index</code> <code>int</code> <p>The index of the unit.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The id.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>@classmethod\ndef unit_code_to_cj_key(cls, code: str, prefix: str, index: int) -&gt; str:\n    \"\"\"\n    Formats the CityJSON key (i.e. the id) based on the code of the units that it stores, and a number.\n\n    Parameters\n    ----------\n    code : str\n        The usage code.\n    prefix : str\n        The building prefix.\n    index : int\n        The index of the unit.\n\n    Returns\n    -------\n    str\n        The id.\n    \"\"\"\n    code_instance = cls.unit_code_to_code_instance(code=code, index=index)\n    prefix = prefix.replace(\"-\", \"_\")\n    return f\"{prefix}-{cls.type_name}-{cls.id_prefix}_{code_instance}\"\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.BuildingUnit.unit_code_to_code_instance","title":"<code>unit_code_to_code_instance(code, index)</code>  <code>classmethod</code>","text":"<p>Generate an identifier based on the given index. The uniqueness of the identifier is not checked, but has to be ensured by providing a combination of inputs not used by another BuildingUnit.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>The usage code.</p> required <code>index</code> <code>int</code> <p>The index of the unit.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A formatted identifier</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>@classmethod\ndef unit_code_to_code_instance(cls, code: str, index: int) -&gt; str:\n    \"\"\"\n    Generate an identifier based on the given index.\n    The uniqueness of the identifier is not checked, but has to be ensured by providing a combination of inputs not used by another BuildingUnit.\n\n    Parameters\n    ----------\n    code : str\n        The usage code.\n    index : int\n        The index of the unit.\n\n    Returns\n    -------\n    str\n        A formatted identifier\n    \"\"\"\n    index_str = str(index).replace(\".\", \"_\").replace(\"-\", \"_\")\n    code = code.replace(\".\", \"_\").replace(\"-\", \"_\")\n    return f\"{code}@{index_str}\"\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.BuildingUnitContainer","title":"<code>BuildingUnitContainer</code>","text":"<p>               Bases: <code>cj_helpers.cj_objects.CityJSONObject</code></p> <p>Class used to group together all the BuildingUnit objects per code.</p> <p>Methods:</p> Name Description <code>unit_code_to_cj_key</code> <p>Formats the CityJSON key (i.e. the id) based on the code of the units that it stores.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>class BuildingUnitContainer(CityJSONObject):\n    \"\"\"\n    Class used to group together all the BuildingUnit objects per code.\n    \"\"\"\n\n    type_name = \"CityObjectGroup\"\n    main_parent_code = \"\"\n    id_prefix = \"BuildingUnitContainer\"\n\n    def __init__(\n        self,\n        cj_key: str,\n        unit_code: str,\n        attributes: dict[str, Any] | None = None,\n        icon_position: IconPosition | None = None,\n    ) -&gt; None:\n        super().__init__(\n            cj_key=cj_key,\n            attributes=attributes,\n            geometries=None,\n            icon_position=icon_position,\n        )\n        self.unit_code = unit_code\n        code_name = ARGUMENT_TO_NAME[\"code\"]\n        self.add_attributes({code_name: unit_code})\n\n    @classmethod\n    def unit_code_to_cj_key(cls, code: str, prefix: str) -&gt; str:\n        \"\"\"\n        Formats the CityJSON key (i.e. the id) based on the code of the units that it stores.\n\n        Parameters\n        ----------\n        code : str\n            The usage code.\n        prefix : str\n            The building prefix.\n\n        Returns\n        -------\n        str\n            The id.\n        \"\"\"\n        code = code.replace(\".\", \"_\").replace(\"-\", \"_\")\n        prefix = prefix.replace(\"-\", \"_\")\n        return f\"{prefix}-{cls.type_name}-{cls.id_prefix}_{code}\"\n\n    def apply_attr(self, attr: BdgAttr, overwrite: bool) -&gt; None:\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.BuildingUnitContainer.unit_code_to_cj_key","title":"<code>unit_code_to_cj_key(code, prefix)</code>  <code>classmethod</code>","text":"<p>Formats the CityJSON key (i.e. the id) based on the code of the units that it stores.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>The usage code.</p> required <code>prefix</code> <code>str</code> <p>The building prefix.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The id.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>@classmethod\ndef unit_code_to_cj_key(cls, code: str, prefix: str) -&gt; str:\n    \"\"\"\n    Formats the CityJSON key (i.e. the id) based on the code of the units that it stores.\n\n    Parameters\n    ----------\n    code : str\n        The usage code.\n    prefix : str\n        The building prefix.\n\n    Returns\n    -------\n    str\n        The id.\n    \"\"\"\n    code = code.replace(\".\", \"_\").replace(\"-\", \"_\")\n    prefix = prefix.replace(\"-\", \"_\")\n    return f\"{prefix}-{cls.type_name}-{cls.id_prefix}_{code}\"\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.BuildingUnitObject","title":"<code>BuildingUnitObject</code>","text":"<p>               Bases: <code>cj_helpers.cj_objects.CityJSONObject</code></p> <p>Class used to represent the object, child of the Building, that will be the parent of all the BuildingUnitContainer objects.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>class BuildingUnitObject(CityJSONObject):\n    \"\"\"\n    Class used to represent the object, child of the Building, that will be the parent of all the BuildingUnitContainer objects.\n    \"\"\"\n\n    type_name = \"CityObjectGroup\"\n    icon_z_offset = 2\n    id_prefix = \"BuildingUnitObject\"\n\n    def __init__(self, prefix: str) -&gt; None:\n        super().__init__(\n            cj_key=f\"{prefix}-{self.type_name}-{self.id_prefix}\",\n            attributes={},\n            geometries=None,\n            icon_position=None,\n        )\n\n    def apply_attr(self, attr: Attr, overwrite: bool) -&gt; None:\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONFile","title":"<code>CityJSONFile</code>","text":"<p>Main CityJSON file handler, allowing to store CityJSON objects and write them to a file by checking the correctness of the hierarchy.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Initialise the CityJSON file handler, with the properties to write the geometry.</p> <code>add_cityjson_objects</code> <p>Add a list of CityJSON objects to the file.</p> <code>check_objects_hierarchy</code> <p>Check the hierarchy of the objects to ensure that all parent/child relationships are stored in both directions.</p> <code>get_root_position</code> <p>Return the index in <code>self.city_objects</code> of the root of the file.</p> <code>to_json</code> <p>Formats all the objects into a correct CityJSON file, and dumps it into a string that can be directly written to a file.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>class CityJSONFile:\n    \"\"\"\n    Main CityJSON file handler, allowing to store CityJSON objects and write them to a file by checking the correctness of the hierarchy.\n    \"\"\"\n\n    def __init__(\n        self, scale: NDArray[np.float64], translate: NDArray[np.float64] | None\n    ) -&gt; None:\n        \"\"\"\n        Initialise the CityJSON file handler, with the properties to write the geometry.\n\n        Parameters\n        ----------\n        scale : NDArray[np.float64]\n            Array of shape (3,) containing the scale used to store the vertices.\n        translate : NDArray[np.float64] | None\n            Array of shape (3,) containing the translation used to store the vertices.\n            If None, it will be computed automatically.\n\n        Raises\n        ------\n        RuntimeError\n            If `scale` has an incorrect shape.\n        RuntimeError\n            If `translate` has an incorrect shape.\n        \"\"\"\n        self.city_objects: list[CityJSONObjectSubclass] = []\n\n        # Transform\n        scale_shape = (3,)\n        if scale.shape != scale_shape:\n            raise RuntimeError(\n                f\"The given scale has shape {scale.shape} instead of {scale_shape}.\"\n            )\n        translate_shape = (3,)\n        if translate is not None and translate.shape != translate_shape:\n            raise RuntimeError(\n                f\"The given translate has shape {translate.shape} instead of {translate_shape}.\"\n            )\n\n        self.scale = scale\n        self.translate = translate\n\n    def check_objects_hierarchy(self, n_components: int | None = None) -&gt; None:\n        \"\"\"\n        Check the hierarchy of the objects to ensure that all parent/child relationships are stored in both directions.\n        Also allows to check that the number of roots (objects without parents) corresponds to what is expected.\n\n        Parameters\n        ----------\n        n_components : int | None, optional\n            The expected number of roots.\n            If None, uses the number of Building objects.\n            By default None.\n\n        Raises\n        ------\n        RuntimeError\n            If a node is missing in the hierarchy.\n        RuntimeError\n            If a cycle is detected in the hierarchy.\n        RuntimeError\n            If the number of connected components / number of roots is different from the expected value.\n        RuntimeError\n            If an edge does not go both ways.\n        \"\"\"\n        G = nx.DiGraph()\n\n        # First add every node\n        for obj in self.city_objects:\n            G.add_node(obj.id)\n\n        # Then add directed edges parent -&gt; child\n        for obj in self.city_objects:\n            for child_id in obj.children_ids:\n                G.add_edge(obj.id, child_id)\n\n        # Look for missing nodes\n        missing = set(G.edges()) - {\n            (u, v) for u, v in G.edges() if G.has_node(u) and G.has_node(v)\n        }\n        if missing:\n            raise RuntimeError(f\"Edges reference unknown nodes: {missing}\")\n\n        # Cycle detection\n        if not nx.is_directed_acyclic_graph(G):\n            cycles = list(nx.simple_cycles(G))\n            raise RuntimeError(f\"Cycle(s) detected - e.g. {cycles[:1][0]}\")\n\n        # Connectivity (ignore direction)\n        if not nx.is_weakly_connected(G):\n            # Find the separate components for a nicer error message\n            comps = list(nx.weakly_connected_components(G))\n            # The number of expected components should be the number of buildings\n            if n_components is None:\n                expected_components = sum(\n                    map(\n                        lambda obj: isinstance(obj, Building),\n                        self.city_objects,\n                    )\n                )\n            else:\n                expected_components = n_components\n            if len(comps) != expected_components:\n                raise RuntimeError(\n                    f\"The number of connected components is {len(comps)} (expected {expected_components})\"\n                )\n\n        # Ensure every edge is mirrored in the opposite list\n        for obj in self.city_objects:\n            if obj.parent_id is not None:\n                G.add_edge(obj.id, obj.parent_id)\n\n        for u, v, d in G.edges(data=True):\n            if not G.has_edge(v, u):\n                raise RuntimeError(\n                    f\"The edge between {u} and {v} doesn't go both ways.\"\n                )\n\n    def to_json(self) -&gt; str:\n        \"\"\"\n        Formats all the objects into a correct CityJSON file, and dumps it into a string that can be directly written to a file.\n\n        Returns\n        -------\n        str\n            The formatted CityJSON file.\n        \"\"\"\n        full_object = {}\n        full_object[\"type\"] = \"CityJSON\"\n        full_object[\"version\"] = \"2.0\"\n        full_object[\"metadata\"] = {\n            \"referenceSystem\": \"https://www.opengis.net/def/crs/EPSG/0/7415\"\n        }\n\n        # Check objectw with and without the geometry\n        geometries_indices: list[list[int] | None] = []\n        next_index = 0\n        unprocessed_geoms = []\n        for obj in self.city_objects:\n            if len(obj.geometries) == 0:\n                geometries_indices.append(None)\n            else:\n                indices = []\n                for geometry in obj.geometries:\n                    unprocessed_geoms.append(geometry)\n                    indices.append(next_index)\n                    next_index += 1\n                geometries_indices.append(indices)\n\n        # Process the geometry\n        geoms_formatter = CityJSONGeometries(unprocessed_geoms)\n        self.translate = geoms_formatter.get_optimal_translate(scale=self.scale)\n        list_dict_geoms = geoms_formatter.get_geometry_cj()\n        vertices = geoms_formatter.get_vertices_cj(\n            scale=self.scale, translate=self.translate\n        )\n\n        # Write the CityObjects\n        cityobjects = {}\n        for obj, geom_indices in zip(self.city_objects, geometries_indices):\n            cityobject = obj.get_cityobject()\n            if geom_indices is not None:\n                cityobject[\"geometry\"] = [list_dict_geoms[idx] for idx in geom_indices]\n            cityobjects[obj.id] = cityobject\n        full_object[\"CityObjects\"] = cityobjects\n\n        # Write the transform\n        full_object[\"transform\"] = {\n            \"scale\": self.scale.tolist(),\n            \"translate\": self.translate.tolist(),\n        }\n\n        full_object[\"vertices\"] = vertices\n\n        return json.dumps(full_object)\n\n    def add_cityjson_objects(\n        self, cj_objects: Sequence[CityJSONObjectSubclass]\n    ) -&gt; None:\n        \"\"\"\n        Add a list of CityJSON objects to the file.\n\n        Parameters\n        ----------\n        cj_objects : Sequence[CityJSONObjectSubclass]\n            List of CityJSON objects to add.\n        \"\"\"\n        self.city_objects.extend(cj_objects)\n\n    def get_root_position(self) -&gt; int:\n        \"\"\"\n        Return the index in `self.city_objects` of the root of the file.\n        Only works if there is exactly one root.\n\n        Returns\n        -------\n        int\n            The index of the root in `self.city_objects`.\n\n        Raises\n        ------\n        RuntimeError\n            If there is not exactly one root.\n        \"\"\"\n        roots_ids: list[int] = []\n        for i, cj_obj in enumerate(self.city_objects):\n            if cj_obj.parent_id == None:\n                roots_ids.append(i)\n        if len(roots_ids) != 1:\n            raise RuntimeError(\n                f\"The current CityJSONFile instance has {len(roots_ids)} roots, but 1 was expected.\"\n            )\n        return roots_ids[0]\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONFile.__init__","title":"<code>__init__(scale, translate)</code>","text":"<p>Initialise the CityJSON file handler, with the properties to write the geometry.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>Array of shape (3,) containing the scale used to store the vertices.</p> required <code>translate</code> <code>numpy.typing.NDArray[numpy.float64] | None</code> <p>Array of shape (3,) containing the translation used to store the vertices. If None, it will be computed automatically.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>scale</code> has an incorrect shape.</p> <code>RuntimeError</code> <p>If <code>translate</code> has an incorrect shape.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>def __init__(\n    self, scale: NDArray[np.float64], translate: NDArray[np.float64] | None\n) -&gt; None:\n    \"\"\"\n    Initialise the CityJSON file handler, with the properties to write the geometry.\n\n    Parameters\n    ----------\n    scale : NDArray[np.float64]\n        Array of shape (3,) containing the scale used to store the vertices.\n    translate : NDArray[np.float64] | None\n        Array of shape (3,) containing the translation used to store the vertices.\n        If None, it will be computed automatically.\n\n    Raises\n    ------\n    RuntimeError\n        If `scale` has an incorrect shape.\n    RuntimeError\n        If `translate` has an incorrect shape.\n    \"\"\"\n    self.city_objects: list[CityJSONObjectSubclass] = []\n\n    # Transform\n    scale_shape = (3,)\n    if scale.shape != scale_shape:\n        raise RuntimeError(\n            f\"The given scale has shape {scale.shape} instead of {scale_shape}.\"\n        )\n    translate_shape = (3,)\n    if translate is not None and translate.shape != translate_shape:\n        raise RuntimeError(\n            f\"The given translate has shape {translate.shape} instead of {translate_shape}.\"\n        )\n\n    self.scale = scale\n    self.translate = translate\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONFile.add_cityjson_objects","title":"<code>add_cityjson_objects(cj_objects)</code>","text":"<p>Add a list of CityJSON objects to the file.</p> <p>Parameters:</p> Name Type Description Default <code>cj_objects</code> <code>collections.abc.Sequence[cj_helpers.cj_objects.CityJSONObjectSubclass]</code> <p>List of CityJSON objects to add.</p> required Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>def add_cityjson_objects(\n    self, cj_objects: Sequence[CityJSONObjectSubclass]\n) -&gt; None:\n    \"\"\"\n    Add a list of CityJSON objects to the file.\n\n    Parameters\n    ----------\n    cj_objects : Sequence[CityJSONObjectSubclass]\n        List of CityJSON objects to add.\n    \"\"\"\n    self.city_objects.extend(cj_objects)\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONFile.check_objects_hierarchy","title":"<code>check_objects_hierarchy(n_components=None)</code>","text":"<p>Check the hierarchy of the objects to ensure that all parent/child relationships are stored in both directions. Also allows to check that the number of roots (objects without parents) corresponds to what is expected.</p> <p>Parameters:</p> Name Type Description Default <code>n_components</code> <code>int | None</code> <p>The expected number of roots. If None, uses the number of Building objects. By default None.</p> <code>None</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If a node is missing in the hierarchy.</p> <code>RuntimeError</code> <p>If a cycle is detected in the hierarchy.</p> <code>RuntimeError</code> <p>If the number of connected components / number of roots is different from the expected value.</p> <code>RuntimeError</code> <p>If an edge does not go both ways.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>def check_objects_hierarchy(self, n_components: int | None = None) -&gt; None:\n    \"\"\"\n    Check the hierarchy of the objects to ensure that all parent/child relationships are stored in both directions.\n    Also allows to check that the number of roots (objects without parents) corresponds to what is expected.\n\n    Parameters\n    ----------\n    n_components : int | None, optional\n        The expected number of roots.\n        If None, uses the number of Building objects.\n        By default None.\n\n    Raises\n    ------\n    RuntimeError\n        If a node is missing in the hierarchy.\n    RuntimeError\n        If a cycle is detected in the hierarchy.\n    RuntimeError\n        If the number of connected components / number of roots is different from the expected value.\n    RuntimeError\n        If an edge does not go both ways.\n    \"\"\"\n    G = nx.DiGraph()\n\n    # First add every node\n    for obj in self.city_objects:\n        G.add_node(obj.id)\n\n    # Then add directed edges parent -&gt; child\n    for obj in self.city_objects:\n        for child_id in obj.children_ids:\n            G.add_edge(obj.id, child_id)\n\n    # Look for missing nodes\n    missing = set(G.edges()) - {\n        (u, v) for u, v in G.edges() if G.has_node(u) and G.has_node(v)\n    }\n    if missing:\n        raise RuntimeError(f\"Edges reference unknown nodes: {missing}\")\n\n    # Cycle detection\n    if not nx.is_directed_acyclic_graph(G):\n        cycles = list(nx.simple_cycles(G))\n        raise RuntimeError(f\"Cycle(s) detected - e.g. {cycles[:1][0]}\")\n\n    # Connectivity (ignore direction)\n    if not nx.is_weakly_connected(G):\n        # Find the separate components for a nicer error message\n        comps = list(nx.weakly_connected_components(G))\n        # The number of expected components should be the number of buildings\n        if n_components is None:\n            expected_components = sum(\n                map(\n                    lambda obj: isinstance(obj, Building),\n                    self.city_objects,\n                )\n            )\n        else:\n            expected_components = n_components\n        if len(comps) != expected_components:\n            raise RuntimeError(\n                f\"The number of connected components is {len(comps)} (expected {expected_components})\"\n            )\n\n    # Ensure every edge is mirrored in the opposite list\n    for obj in self.city_objects:\n        if obj.parent_id is not None:\n            G.add_edge(obj.id, obj.parent_id)\n\n    for u, v, d in G.edges(data=True):\n        if not G.has_edge(v, u):\n            raise RuntimeError(\n                f\"The edge between {u} and {v} doesn't go both ways.\"\n            )\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONFile.get_root_position","title":"<code>get_root_position()</code>","text":"<p>Return the index in <code>self.city_objects</code> of the root of the file. Only works if there is exactly one root.</p> <p>Returns:</p> Type Description <code>int</code> <p>The index of the root in <code>self.city_objects</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If there is not exactly one root.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>def get_root_position(self) -&gt; int:\n    \"\"\"\n    Return the index in `self.city_objects` of the root of the file.\n    Only works if there is exactly one root.\n\n    Returns\n    -------\n    int\n        The index of the root in `self.city_objects`.\n\n    Raises\n    ------\n    RuntimeError\n        If there is not exactly one root.\n    \"\"\"\n    roots_ids: list[int] = []\n    for i, cj_obj in enumerate(self.city_objects):\n        if cj_obj.parent_id == None:\n            roots_ids.append(i)\n    if len(roots_ids) != 1:\n        raise RuntimeError(\n            f\"The current CityJSONFile instance has {len(roots_ids)} roots, but 1 was expected.\"\n        )\n    return roots_ids[0]\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONFile.to_json","title":"<code>to_json()</code>","text":"<p>Formats all the objects into a correct CityJSON file, and dumps it into a string that can be directly written to a file.</p> <p>Returns:</p> Type Description <code>str</code> <p>The formatted CityJSON file.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"\n    Formats all the objects into a correct CityJSON file, and dumps it into a string that can be directly written to a file.\n\n    Returns\n    -------\n    str\n        The formatted CityJSON file.\n    \"\"\"\n    full_object = {}\n    full_object[\"type\"] = \"CityJSON\"\n    full_object[\"version\"] = \"2.0\"\n    full_object[\"metadata\"] = {\n        \"referenceSystem\": \"https://www.opengis.net/def/crs/EPSG/0/7415\"\n    }\n\n    # Check objectw with and without the geometry\n    geometries_indices: list[list[int] | None] = []\n    next_index = 0\n    unprocessed_geoms = []\n    for obj in self.city_objects:\n        if len(obj.geometries) == 0:\n            geometries_indices.append(None)\n        else:\n            indices = []\n            for geometry in obj.geometries:\n                unprocessed_geoms.append(geometry)\n                indices.append(next_index)\n                next_index += 1\n            geometries_indices.append(indices)\n\n    # Process the geometry\n    geoms_formatter = CityJSONGeometries(unprocessed_geoms)\n    self.translate = geoms_formatter.get_optimal_translate(scale=self.scale)\n    list_dict_geoms = geoms_formatter.get_geometry_cj()\n    vertices = geoms_formatter.get_vertices_cj(\n        scale=self.scale, translate=self.translate\n    )\n\n    # Write the CityObjects\n    cityobjects = {}\n    for obj, geom_indices in zip(self.city_objects, geometries_indices):\n        cityobject = obj.get_cityobject()\n        if geom_indices is not None:\n            cityobject[\"geometry\"] = [list_dict_geoms[idx] for idx in geom_indices]\n        cityobjects[obj.id] = cityobject\n    full_object[\"CityObjects\"] = cityobjects\n\n    # Write the transform\n    full_object[\"transform\"] = {\n        \"scale\": self.scale.tolist(),\n        \"translate\": self.translate.tolist(),\n    }\n\n    full_object[\"vertices\"] = vertices\n\n    return json.dumps(full_object)\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONObject","title":"<code>CityJSONObject</code>","text":"<p>               Bases: <code>abc.ABC</code></p> <p>Abstract base class to handle CityJSON objects.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Initialise a CityJSON object.</p> <code>add_attributes</code> <p>Add the given attributes to the dictionary of attributes.</p> <code>add_parent_child</code> <p>Add a parent-child relationship.</p> <code>add_unit_space</code> <p>Add a unit-space relationship.</p> <code>get_cityobject</code> <p>Returns the object formatted like a CityJSON object, but without the geometry.</p> <code>set_icon</code> <p>Set the icon position, potentially overwriting it.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>class CityJSONObject(ABC):\n    \"\"\"\n    Abstract base class to handle CityJSON objects.\n    \"\"\"\n\n    type_name = \"CityJSONObject\"\n    icon_z_offset = 2\n\n    def __init__(\n        self,\n        cj_key: str,\n        attributes: dict[str, Any] | None = None,\n        geometries: Sequence[Geometry] | None = None,\n        icon_position: IconPosition | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialise a CityJSON object.\n\n        Parameters\n        ----------\n        cj_key : str\n            Unique key of the object.\n        attributes : dict[str, Any] | None, optional\n            Dictionary of attributes.\n            If None, initialised empty.\n            By default None.\n        geometries : Sequence[Geometry] | None, optional\n            List of geometries with their associated LoDs.\n            If None, initialised empty.\n            By default None.\n        icon_position : IconPosition | None, optional\n            Position of the icon.\n            If None, initialised based on the geometry of highest LoD, or as None if there is no geometry.\n            By default None.\n\n        Raises\n        ------\n        RuntimeError\n            If `attributes` is not None or a dictionary.\n        RuntimeError\n            If any of the keys of the dictionary is not a string.\n        \"\"\"\n        if attributes is not None:\n            if not isinstance(attributes, dict):\n                raise RuntimeError(\n                    f\"The attributes of a CityJSONObject should be a dictionary or None.\"\n                )\n            for key in attributes.keys():\n                if not isinstance(key, str):\n                    raise RuntimeError(\n                        f\"The attributes of a CityJSONObject should have strings as keys.\"\n                    )\n\n        self.id = cj_key\n        self.attributes = attributes if attributes is not None else {}\n        self.parent_id = None\n        self.children_ids: set[str] = set()\n        self.geometries = list(geometries if geometries is not None else [])\n\n        # Add the key to the attributes\n        self.add_attributes({\"key\": self.id})\n\n        # Compute the icon\n        self._process_icon(icon_position)\n\n    def _process_icon(self, icon_position: IconPosition | None = None) -&gt; None:\n        \"\"\"\n        Add the icon position it to the attributes.\n        If no icon position is given, it is computed based on the geometry of highest LoD.\n\n        Parameters\n        ----------\n        icon_position : IconPosition | None, optional\n            The position of the icon on the map.\n            By default None.\n        \"\"\"\n        if (\n            icon_position is None\n            and self.geometries is not None\n            and len(self.geometries) &gt; 0\n        ):\n            # Use the highest lod to create a point\n            best_idx = 0\n            for idx in range(1, len(self.geometries)):\n                if self.geometries[idx].lod &gt; self.geometries[best_idx].lod:\n                    best_idx = idx\n\n            icon_position = IconPosition.from_mesh(\n                self.geometries[best_idx].to_trimesh(), z_offset=self.icon_z_offset\n            )\n        self.icon_position = icon_position\n        if self.icon_position is not None:\n            icon_position_name = ARGUMENT_TO_NAME[\"icon_position\"]\n            self.add_attributes(\n                {\n                    icon_position_name: [\n                        self.icon_position.x,\n                        self.icon_position.y,\n                        self.icon_position.z,\n                    ]\n                }\n            )\n\n    def set_icon(self, icon_position: IconPosition, overwrite: bool = False) -&gt; None:\n        \"\"\"\n        Set the icon position, potentially overwriting it.\n\n        Parameters\n        ----------\n        icon_position : IconPosition\n            Position of the icon.\n        overwrite : bool, optional\n            Whether to overwrite the value if a correct value (not None) is already stored.\n            By default False.\n        \"\"\"\n        self.icon_position = icon_position\n        icon_position_name = ARGUMENT_TO_NAME[\"icon_position\"]\n        self.add_attributes(\n            {\n                icon_position_name: [\n                    self.icon_position.x,\n                    self.icon_position.y,\n                    self.icon_position.z,\n                ]\n            },\n            overwrite=overwrite,\n        )\n\n    def __repr__(self) -&gt; str:\n        return f\"{type(self)}(id={self.id}, parent_id={self.parent_id}, children_ids={self.children_ids})\"\n\n    def _set_parent(self, parent_id: str, replace: bool = False) -&gt; None:\n        \"\"\"\n        Set the parent of the current object.\n\n        Warning\n        -------\n        Should not be called directly, but instead indirectly with `CityJSONObject.add_parent_child` to avoid one-way relations.\n\n        Parameters\n        ----------\n        parent_id : str\n            The id of the parent CityJSONObject.\n        replace : bool, optional\n            Whether to overwrite the value if a correct value (not None) is already stored.\n            By default False.\n\n        Raises\n        ------\n        RuntimeError\n            If `parent_id` already contains a value and `replace` was not set to True.\n        \"\"\"\n        if self.parent_id is not None and not replace:\n            raise RuntimeError(\n                \"Parent id is already set. To replace it, set `replace` to True.\"\n            )\n        self.parent_id = parent_id\n\n    def _add_child(self, child_id: str) -&gt; None:\n        \"\"\"\n        Add the given object id to the set of children of the current object.\n        Does nothing if the id was already in the list.\n\n        Warning\n        -------\n        Should not be called directly, but instead indirectly with CityJSONObject.add_parent_child to avoid one-way relations.\n\n        Parameters\n        ----------\n        child_id : str\n            The id of the child CityJSONObject.\n        \"\"\"\n        self.children_ids.add(child_id)\n\n    def get_cityobject(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Returns the object formatted like a CityJSON object, but without the geometry.\n\n        Returns\n        -------\n        dict[str, Any]\n            Dictionary following CityJSON format for a CityObject, but **without** the geometry.\n        \"\"\"\n        content_dict = {}\n        content_dict[\"type\"] = type(self).type_name\n        if self.parent_id is not None:\n            content_dict[\"parents\"] = [self.parent_id]\n        if len(self.children_ids) &gt; 0:\n            content_dict[\"children\"] = list(self.children_ids)\n        content_dict[\"attributes\"] = self.attributes.copy()\n        return content_dict\n\n    def add_attributes(\n        self, new_attributes: dict[str, Any], overwrite: bool = False\n    ) -&gt; None:\n        \"\"\"\n        Add the given attributes to the dictionary of attributes.\n\n        Parameters\n        ----------\n        new_attributes : dict[str, Any]\n            The new attributes to add.\n        overwrite : bool, optional\n            Whether an attribute with the same key as an already existing attribute should overwrite the old one.\n            By default False.\n\n        Raises\n        ------\n        RuntimeError\n            If an attribute key already existed and `overwrite` was not set to True.\n        \"\"\"\n        for key, value in new_attributes.items():\n            if key in self.attributes and not overwrite:\n                raise RuntimeError(\n                    f\"The key '{key}' is already in the attributes. Set `overwrite` to True to overwrite.\"\n                )\n            self.attributes[key] = value\n\n    @abstractmethod\n    def apply_attr(self, attr: Attr, overwrite: bool) -&gt; None:\n        raise NotImplementedError()\n\n    @classmethod\n    def add_parent_child(\n        cls, parent: CityJSONObjectSubclass, child: CityJSONObjectSubclass\n    ) -&gt; None:\n        \"\"\"\n        Add a parent-child relationship.\n        Adds the relationship to both objects.\n\n        Parameters\n        ----------\n        parent : CityJSONObjectSubclass\n            CityJSON object that is the parent of `child`.\n        child : CityJSONObjectSubclass\n            CityJSON object that is the child of `parent`.\n        \"\"\"\n        parent._add_child(child.id)\n        child._set_parent(parent.id)\n\n    @classmethod\n    def add_unit_space(cls, unit: BuildingUnit, space: CityJSONSpace) -&gt; None:\n        \"\"\"\n        Add a unit-space relationship.\n        Adds the relationship to both objects.\n\n        Parameters\n        ----------\n        unit : BuildingUnit\n            BuildingUnit that contains the `space`.\n        space : CityJSONSpace\n            CityJSONSpace that is part of the `unit`.\n        \"\"\"\n        unit._add_space(space.id)\n        space._add_unit(unit.id)\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONObject.__init__","title":"<code>__init__(cj_key, attributes=None, geometries=None, icon_position=None)</code>","text":"<p>Initialise a CityJSON object.</p> <p>Parameters:</p> Name Type Description Default <code>cj_key</code> <code>str</code> <p>Unique key of the object.</p> required <code>attributes</code> <code>dict[str, typing.Any] | None</code> <p>Dictionary of attributes. If None, initialised empty. By default None.</p> <code>None</code> <code>geometries</code> <code>collections.abc.Sequence[data_pipeline.cj_helpers.cj_geometry.Geometry] | None</code> <p>List of geometries with their associated LoDs. If None, initialised empty. By default None.</p> <code>None</code> <code>icon_position</code> <code>data_pipeline.utils.icon_positions.IconPosition | None</code> <p>Position of the icon. If None, initialised based on the geometry of highest LoD, or as None if there is no geometry. By default None.</p> <code>None</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>attributes</code> is not None or a dictionary.</p> <code>RuntimeError</code> <p>If any of the keys of the dictionary is not a string.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>def __init__(\n    self,\n    cj_key: str,\n    attributes: dict[str, Any] | None = None,\n    geometries: Sequence[Geometry] | None = None,\n    icon_position: IconPosition | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialise a CityJSON object.\n\n    Parameters\n    ----------\n    cj_key : str\n        Unique key of the object.\n    attributes : dict[str, Any] | None, optional\n        Dictionary of attributes.\n        If None, initialised empty.\n        By default None.\n    geometries : Sequence[Geometry] | None, optional\n        List of geometries with their associated LoDs.\n        If None, initialised empty.\n        By default None.\n    icon_position : IconPosition | None, optional\n        Position of the icon.\n        If None, initialised based on the geometry of highest LoD, or as None if there is no geometry.\n        By default None.\n\n    Raises\n    ------\n    RuntimeError\n        If `attributes` is not None or a dictionary.\n    RuntimeError\n        If any of the keys of the dictionary is not a string.\n    \"\"\"\n    if attributes is not None:\n        if not isinstance(attributes, dict):\n            raise RuntimeError(\n                f\"The attributes of a CityJSONObject should be a dictionary or None.\"\n            )\n        for key in attributes.keys():\n            if not isinstance(key, str):\n                raise RuntimeError(\n                    f\"The attributes of a CityJSONObject should have strings as keys.\"\n                )\n\n    self.id = cj_key\n    self.attributes = attributes if attributes is not None else {}\n    self.parent_id = None\n    self.children_ids: set[str] = set()\n    self.geometries = list(geometries if geometries is not None else [])\n\n    # Add the key to the attributes\n    self.add_attributes({\"key\": self.id})\n\n    # Compute the icon\n    self._process_icon(icon_position)\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONObject.add_attributes","title":"<code>add_attributes(new_attributes, overwrite=False)</code>","text":"<p>Add the given attributes to the dictionary of attributes.</p> <p>Parameters:</p> Name Type Description Default <code>new_attributes</code> <code>dict[str, typing.Any]</code> <p>The new attributes to add.</p> required <code>overwrite</code> <code>bool</code> <p>Whether an attribute with the same key as an already existing attribute should overwrite the old one. By default False.</p> <code>False</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If an attribute key already existed and <code>overwrite</code> was not set to True.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>def add_attributes(\n    self, new_attributes: dict[str, Any], overwrite: bool = False\n) -&gt; None:\n    \"\"\"\n    Add the given attributes to the dictionary of attributes.\n\n    Parameters\n    ----------\n    new_attributes : dict[str, Any]\n        The new attributes to add.\n    overwrite : bool, optional\n        Whether an attribute with the same key as an already existing attribute should overwrite the old one.\n        By default False.\n\n    Raises\n    ------\n    RuntimeError\n        If an attribute key already existed and `overwrite` was not set to True.\n    \"\"\"\n    for key, value in new_attributes.items():\n        if key in self.attributes and not overwrite:\n            raise RuntimeError(\n                f\"The key '{key}' is already in the attributes. Set `overwrite` to True to overwrite.\"\n            )\n        self.attributes[key] = value\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONObject.add_parent_child","title":"<code>add_parent_child(parent, child)</code>  <code>classmethod</code>","text":"<p>Add a parent-child relationship. Adds the relationship to both objects.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>cj_helpers.cj_objects.CityJSONObjectSubclass</code> <p>CityJSON object that is the parent of <code>child</code>.</p> required <code>child</code> <code>cj_helpers.cj_objects.CityJSONObjectSubclass</code> <p>CityJSON object that is the child of <code>parent</code>.</p> required Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>@classmethod\ndef add_parent_child(\n    cls, parent: CityJSONObjectSubclass, child: CityJSONObjectSubclass\n) -&gt; None:\n    \"\"\"\n    Add a parent-child relationship.\n    Adds the relationship to both objects.\n\n    Parameters\n    ----------\n    parent : CityJSONObjectSubclass\n        CityJSON object that is the parent of `child`.\n    child : CityJSONObjectSubclass\n        CityJSON object that is the child of `parent`.\n    \"\"\"\n    parent._add_child(child.id)\n    child._set_parent(parent.id)\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONObject.add_unit_space","title":"<code>add_unit_space(unit, space)</code>  <code>classmethod</code>","text":"<p>Add a unit-space relationship. Adds the relationship to both objects.</p> <p>Parameters:</p> Name Type Description Default <code>unit</code> <code>cj_helpers.cj_objects.BuildingUnit</code> <p>BuildingUnit that contains the <code>space</code>.</p> required <code>space</code> <code>cj_helpers.cj_objects.CityJSONSpace</code> <p>CityJSONSpace that is part of the <code>unit</code>.</p> required Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>@classmethod\ndef add_unit_space(cls, unit: BuildingUnit, space: CityJSONSpace) -&gt; None:\n    \"\"\"\n    Add a unit-space relationship.\n    Adds the relationship to both objects.\n\n    Parameters\n    ----------\n    unit : BuildingUnit\n        BuildingUnit that contains the `space`.\n    space : CityJSONSpace\n        CityJSONSpace that is part of the `unit`.\n    \"\"\"\n    unit._add_space(space.id)\n    space._add_unit(unit.id)\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONObject.get_cityobject","title":"<code>get_cityobject()</code>","text":"<p>Returns the object formatted like a CityJSON object, but without the geometry.</p> <p>Returns:</p> Type Description <code>dict[str, typing.Any]</code> <p>Dictionary following CityJSON format for a CityObject, but without the geometry.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>def get_cityobject(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Returns the object formatted like a CityJSON object, but without the geometry.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary following CityJSON format for a CityObject, but **without** the geometry.\n    \"\"\"\n    content_dict = {}\n    content_dict[\"type\"] = type(self).type_name\n    if self.parent_id is not None:\n        content_dict[\"parents\"] = [self.parent_id]\n    if len(self.children_ids) &gt; 0:\n        content_dict[\"children\"] = list(self.children_ids)\n    content_dict[\"attributes\"] = self.attributes.copy()\n    return content_dict\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONObject.set_icon","title":"<code>set_icon(icon_position, overwrite=False)</code>","text":"<p>Set the icon position, potentially overwriting it.</p> <p>Parameters:</p> Name Type Description Default <code>icon_position</code> <code>data_pipeline.utils.icon_positions.IconPosition</code> <p>Position of the icon.</p> required <code>overwrite</code> <code>bool</code> <p>Whether to overwrite the value if a correct value (not None) is already stored. By default False.</p> <code>False</code> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>def set_icon(self, icon_position: IconPosition, overwrite: bool = False) -&gt; None:\n    \"\"\"\n    Set the icon position, potentially overwriting it.\n\n    Parameters\n    ----------\n    icon_position : IconPosition\n        Position of the icon.\n    overwrite : bool, optional\n        Whether to overwrite the value if a correct value (not None) is already stored.\n        By default False.\n    \"\"\"\n    self.icon_position = icon_position\n    icon_position_name = ARGUMENT_TO_NAME[\"icon_position\"]\n    self.add_attributes(\n        {\n            icon_position_name: [\n                self.icon_position.x,\n                self.icon_position.y,\n                self.icon_position.z,\n            ]\n        },\n        overwrite=overwrite,\n    )\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONSpace","title":"<code>CityJSONSpace</code>","text":"<p>               Bases: <code>cj_helpers.cj_objects.CityJSONObject</code></p> <p>Abstract base class to handle CityJSON objects in the room hierarchy (i.e. Building, BuildingPart, BuildingStorey and BuildingRoom).</p> <p>Methods:</p> Name Description <code>key_to_cj_key</code> <p>Formats the CityJSON key (i.e. the id) based on the key (the space id).</p> <code>key_to_prefix</code> <p>Formats the prefix of the object based on its key.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>class CityJSONSpace(CityJSONObject):\n    \"\"\"\n    Abstract base class to handle CityJSON objects in the room hierarchy (i.e. Building,\n    BuildingPart, BuildingStorey and BuildingRoom).\n    \"\"\"\n\n    type_name = \"CityJSONSpace\"\n\n    def __init__(\n        self,\n        cj_key: str,\n        space_id: str,\n        attributes: dict[str, Any] | None = None,\n        geometries: Sequence[Geometry] | None = None,\n        icon_position: IconPosition | None = None,\n    ) -&gt; None:\n\n        super().__init__(\n            cj_key=cj_key,\n            attributes=attributes,\n            geometries=geometries,\n            icon_position=icon_position,\n        )\n        self.cj_key = cj_key\n        self.space_id = space_id\n        space_id_key = ARGUMENT_TO_NAME[\"space_id\"]\n        self.add_attributes({space_id_key: space_id})\n        self.parent_units: set[str] = set()\n\n    def _add_unit(self, new_unit_id: str) -&gt; None:\n        \"\"\"\n        Add a unit that this space is part of.\n\n        Parameters\n        ----------\n        new_unit_id : str\n            Id of the unit.\n        \"\"\"\n        self.parent_units.add(new_unit_id)\n\n    def get_cityobject(self) -&gt; dict[str, Any]:\n        parent_units_key = ARGUMENT_TO_NAME[\"parent_units\"]\n        self.add_attributes({parent_units_key: list(self.parent_units)})\n        content_dict = super().get_cityobject()\n        # Remove it from the attributes to ensure the object is unchanged\n        self.attributes.pop(parent_units_key)\n        return content_dict\n\n    @classmethod\n    def key_to_prefix(cls, key: str) -&gt; str:\n        \"\"\"\n        Formats the prefix of the object based on its key.\n\n        Parameters\n        ----------\n        key : str\n            The key of the object.\n\n        Returns\n        -------\n        str\n            The prefix of the object.\n        \"\"\"\n        return f\"Building_{key.split(\".\")[0]}\"\n\n    @classmethod\n    def key_to_cj_key(cls, key: str) -&gt; str:\n        \"\"\"\n        Formats the CityJSON key (i.e. the id) based on the key (the space id).\n\n        Parameters\n        ----------\n        key : str\n            The key of the object.\n\n        Returns\n        -------\n        str\n            The id.\n        \"\"\"\n        prefix = cls.key_to_prefix(key=key)\n        key = key.replace(\".\", \"_\").replace(\"-\", \"_\")\n        return f\"{prefix}-{cls.type_name}-{key}\"\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONSpace.key_to_cj_key","title":"<code>key_to_cj_key(key)</code>  <code>classmethod</code>","text":"<p>Formats the CityJSON key (i.e. the id) based on the key (the space id).</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the object.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The id.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>@classmethod\ndef key_to_cj_key(cls, key: str) -&gt; str:\n    \"\"\"\n    Formats the CityJSON key (i.e. the id) based on the key (the space id).\n\n    Parameters\n    ----------\n    key : str\n        The key of the object.\n\n    Returns\n    -------\n    str\n        The id.\n    \"\"\"\n    prefix = cls.key_to_prefix(key=key)\n    key = key.replace(\".\", \"_\").replace(\"-\", \"_\")\n    return f\"{prefix}-{cls.type_name}-{key}\"\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.CityJSONSpace.key_to_prefix","title":"<code>key_to_prefix(key)</code>  <code>classmethod</code>","text":"<p>Formats the prefix of the object based on its key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the object.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The prefix of the object.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>@classmethod\ndef key_to_prefix(cls, key: str) -&gt; str:\n    \"\"\"\n    Formats the prefix of the object based on its key.\n\n    Parameters\n    ----------\n    key : str\n        The key of the object.\n\n    Returns\n    -------\n    str\n        The prefix of the object.\n    \"\"\"\n    return f\"Building_{key.split(\".\")[0]}\"\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.OutdoorObject","title":"<code>OutdoorObject</code>","text":"<p>               Bases: <code>cj_helpers.cj_objects.CityJSONObject</code></p> <p>Class used to represent the object, root of the file, that will be the parent of all the OutdoorUnitContainer objects.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>class OutdoorObject(CityJSONObject):\n    \"\"\"\n    Class used to represent the object, root of the file, that will be the parent of all the OutdoorUnitContainer objects.\n    \"\"\"\n\n    type_name = \"CityObjectGroup\"\n    icon_z_offset = 2\n    id_prefix = \"OutdoorObject\"\n\n    def __init__(self, prefix: str) -&gt; None:\n        super().__init__(\n            cj_key=f\"{prefix}-{self.type_name}-{self.id_prefix}\",\n            attributes={},\n            geometries=None,\n            icon_position=None,\n        )\n\n    def apply_attr(self, attr: Attr, overwrite: bool) -&gt; None:\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.OutdoorUnit","title":"<code>OutdoorUnit</code>","text":"<p>               Bases: <code>cj_helpers.cj_objects.BuildingUnitContainer</code></p> <p>Class used to store a single OutdoorUnit object. OutdoorUnit objects can only have an icon and no geometry, but this could be extended similarly to BuildingUnit.</p> <p>Methods:</p> Name Description <code>unit_code_to_code_instance</code> <p>Generate an identifier based on the given number.</p> <code>unit_code_to_id</code> <p>Formats the CityJSON key (i.e. the id) based on the code of the units that it stores, and a number.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>class OutdoorUnit(BuildingUnitContainer):\n    \"\"\"\n    Class used to store a single OutdoorUnit object.\n    OutdoorUnit objects can only have an icon and no geometry, but this could be extended similarly to BuildingUnit.\n    \"\"\"\n\n    type_name = \"GenericCityObject\"\n    icon_z_offset = 2\n    id_prefix = \"OutdoorUnit\"\n\n    def __init__(\n        self,\n        cj_key: str,\n        unit_code: str,\n        attributes: dict[str, Any] | None = None,\n        icon_position: IconPosition | None = None,\n    ) -&gt; None:\n        super().__init__(\n            cj_key=cj_key,\n            unit_code=unit_code,\n            attributes=attributes,\n            icon_position=icon_position,\n        )\n\n    @classmethod\n    def unit_code_to_code_instance(cls, code: str, number: int) -&gt; str:\n        \"\"\"\n        Generate an identifier based on the given number.\n        The uniqueness of the identifier is not checked, but has to be ensured by providing a combination of inputs not used by another OutdoorUnit.\n\n        Parameters\n        ----------\n        code : str\n            The usage code.\n        number : int\n            The number of the unit.\n\n        Returns\n        -------\n        str\n            A formatted identifier\n        \"\"\"\n        number_str = str(number).replace(\".\", \"_\").replace(\"-\", \"_\")\n        code = code.replace(\".\", \"_\").replace(\"-\", \"_\")\n        return f\"{code}@{number_str}\"\n\n    @classmethod\n    def unit_code_to_id(cls, code: str, prefix: str, number: int) -&gt; str:\n        \"\"\"\n        Formats the CityJSON key (i.e. the id) based on the code of the units that it stores, and a number.\n\n        Parameters\n        ----------\n        code : str\n            The usage code.\n        prefix : str\n            The outdoor prefix.\n        number : int\n            The number of the unit.\n\n        Returns\n        -------\n        str\n            The id.\n        \"\"\"\n        code_instance = cls.unit_code_to_code_instance(code=code, number=number)\n        prefix = prefix.replace(\"-\", \"_\")\n        return f\"{prefix}-{cls.type_name}-{cls.id_prefix}_{code_instance}\"\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.OutdoorUnit.unit_code_to_code_instance","title":"<code>unit_code_to_code_instance(code, number)</code>  <code>classmethod</code>","text":"<p>Generate an identifier based on the given number. The uniqueness of the identifier is not checked, but has to be ensured by providing a combination of inputs not used by another OutdoorUnit.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>The usage code.</p> required <code>number</code> <code>int</code> <p>The number of the unit.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A formatted identifier</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>@classmethod\ndef unit_code_to_code_instance(cls, code: str, number: int) -&gt; str:\n    \"\"\"\n    Generate an identifier based on the given number.\n    The uniqueness of the identifier is not checked, but has to be ensured by providing a combination of inputs not used by another OutdoorUnit.\n\n    Parameters\n    ----------\n    code : str\n        The usage code.\n    number : int\n        The number of the unit.\n\n    Returns\n    -------\n    str\n        A formatted identifier\n    \"\"\"\n    number_str = str(number).replace(\".\", \"_\").replace(\"-\", \"_\")\n    code = code.replace(\".\", \"_\").replace(\"-\", \"_\")\n    return f\"{code}@{number_str}\"\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.OutdoorUnit.unit_code_to_id","title":"<code>unit_code_to_id(code, prefix, number)</code>  <code>classmethod</code>","text":"<p>Formats the CityJSON key (i.e. the id) based on the code of the units that it stores, and a number.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>The usage code.</p> required <code>prefix</code> <code>str</code> <p>The outdoor prefix.</p> required <code>number</code> <code>int</code> <p>The number of the unit.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The id.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>@classmethod\ndef unit_code_to_id(cls, code: str, prefix: str, number: int) -&gt; str:\n    \"\"\"\n    Formats the CityJSON key (i.e. the id) based on the code of the units that it stores, and a number.\n\n    Parameters\n    ----------\n    code : str\n        The usage code.\n    prefix : str\n        The outdoor prefix.\n    number : int\n        The number of the unit.\n\n    Returns\n    -------\n    str\n        The id.\n    \"\"\"\n    code_instance = cls.unit_code_to_code_instance(code=code, number=number)\n    prefix = prefix.replace(\"-\", \"_\")\n    return f\"{prefix}-{cls.type_name}-{cls.id_prefix}_{code_instance}\"\n</code></pre>"},{"location":"reference/cj_helpers/cj_objects/#cj_helpers.cj_objects.OutdoorUnitContainer","title":"<code>OutdoorUnitContainer</code>","text":"<p>               Bases: <code>cj_helpers.cj_objects.BuildingUnitContainer</code></p> <p>Class used to group together all the OutdoorUnit objects per code.</p> Source code in <code>python/src/data_pipeline/cj_helpers/cj_objects.py</code> <pre><code>class OutdoorUnitContainer(BuildingUnitContainer):\n    \"\"\"\n    Class used to group together all the OutdoorUnit objects per code.\n    \"\"\"\n\n    type_name = \"CityObjectGroup\"\n    main_parent_code = \"\"\n    id_prefix = \"OutdoorUnitContainer\"\n\n    def __init__(\n        self,\n        cj_key: str,\n        unit_code: str,\n        attributes: dict[str, Any] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            cj_key=cj_key,\n            unit_code=unit_code,\n            attributes=attributes,\n            icon_position=None,\n        )\n\n    def apply_attr(self, attr: BdgAttr, overwrite: bool) -&gt; None:\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/cj_loading/","title":"cj_loading","text":"<p>Collection of scripts to load CityJSON files and write them to other formats.</p> <p>Modules:</p> Name Description <code>cj_loader</code> <p>Scripts to load CityJSON files.</p> <code>cj_to_gltf</code> <p>Scripts to load CityJSON files exported by the other scripts and export to a dual CityJSON/glTF format by transferring all the geometry to glTF.</p>"},{"location":"reference/cj_loading/cj_loader/","title":"cj_loader","text":"<p>Scripts to load CityJSON files.</p> <p>Classes:</p> Name Description <code>CityjsonLoader</code> <p>Utility CityJSON loader that extracts all data from a CityJSON file and transforms the integer coordinates to their real coordinates.</p> <p>Functions:</p> Name Description <code>cj_object_to_mesh</code> <p>Build the Trimesh representation of the geometry, based on a full CityJSON object.</p>"},{"location":"reference/cj_loading/cj_loader/#cj_loading.cj_loader.CityjsonLoader","title":"<code>CityjsonLoader</code>","text":"<p>Utility CityJSON loader that extracts all data from a CityJSON file and transforms the integer coordinates to their real coordinates.</p> Source code in <code>python/src/data_pipeline/cj_loading/cj_loader.py</code> <pre><code>class CityjsonLoader:\n    \"\"\"\n    Utility CityJSON loader that extracts all data from a CityJSON file and transforms the integer coordinates to their real coordinates.\n    \"\"\"\n\n    def __init__(self, cj_path: Path) -&gt; None:\n        self.path = cj_path\n\n        self.data = self._cj_load()\n        self.vertices = self._cj_extract_vertices()\n\n    def _cj_load(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Load the whole file.\n\n        Returns\n        -------\n        dict[str, Any]\n            The CityJSON file directly as a dictionary.\n        \"\"\"\n        with open(self.path) as cj_file:\n            cj_data = json.load(cj_file)\n\n        return cj_data\n\n    def _cj_extract_vertices(self) -&gt; NDArray[np.float64]:\n        \"\"\"\n        Extract and transforms the vertices to their real coordinates.\n\n        Returns\n        -------\n        NDArray[np.float64]\n            The array (N, 3) of vertices coordinates.\n        \"\"\"\n        normalised_vertices = np.array(self.data[\"vertices\"], dtype=np.float64)\n        translate = np.array(self.data[\"transform\"][\"translate\"], dtype=np.float64)\n        scale = np.array(self.data[\"transform\"][\"scale\"], dtype=np.float64)\n        vertices = scale * normalised_vertices + translate\n        return vertices\n</code></pre>"},{"location":"reference/cj_loading/cj_loader/#cj_loading.cj_loader.cj_object_to_mesh","title":"<code>cj_object_to_mesh(obj_dict, vertices)</code>","text":"<p>Build the Trimesh representation of the geometry, based on a full CityJSON object. All the LoDs are created and returned.</p> <p>Parameters:</p> Name Type Description Default <code>obj_dict</code> <code>dict[str, typing.Any]</code> <p>The full CityJSON object as stored in the file. In particular, the geometry with potentally multiple LoDs is expected to be stored in \"geometry\".</p> required <code>vertices</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>The array (N,3) of the vertices coordinates, that the geometry refers to.</p> required <p>Returns:</p> Type Description <code>dict[str, trimesh.Trimesh] | None</code> <p>A dictionary mapping the LoD to its Trimesh representation.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the geometry is not one of the supported geometry types.</p> Source code in <code>python/src/data_pipeline/cj_loading/cj_loader.py</code> <pre><code>def cj_object_to_mesh(\n    obj_dict: dict[str, Any], vertices: NDArray[np.float64]\n) -&gt; dict[str, trimesh.Trimesh] | None:\n    \"\"\"\n    Build the Trimesh representation of the geometry, based on a full CityJSON object.\n    All the LoDs are created and returned.\n\n    Parameters\n    ----------\n    obj_dict : dict[str, Any]\n        The full CityJSON object as stored in the file.\n        In particular, the geometry with potentally multiple LoDs is expected to be stored in \"geometry\".\n    vertices : NDArray[np.float64]\n        The array (N,3) of the vertices coordinates, that the geometry refers to.\n\n    Returns\n    -------\n    dict[str, trimesh.Trimesh] | None\n        A dictionary mapping the LoD to its Trimesh representation.\n\n    Raises\n    ------\n    NotImplementedError\n        If the geometry is not one of the supported geometry types.\n    \"\"\"\n\n    # Return None if there is no geometry\n    if \"geometry\" not in obj_dict or len(obj_dict[\"geometry\"]) == 0:\n        return None\n\n    # CityObjects may contain several geometry entries (different LoDs)\n    meshes_lods = {}\n    for geom in obj_dict[\"geometry\"]:\n        lod = geom[\"lod\"]\n        geom_type = geom[\"type\"]\n        boundaries = geom[\"boundaries\"]\n        if geom_type == \"MultiSurface\":\n            mesh = _cj_multisurface_to_mesh(\n                boundaries=boundaries,\n                vertices=vertices,\n            )\n        elif geom_type == \"Solid\":\n            mesh = _cj_solid_to_mesh(\n                boundaries=boundaries,\n                vertices=vertices,\n            )\n        else:\n            raise NotImplementedError(f\"Unexpected geometry type: '{geom_type}'\")\n        meshes_lods[lod] = mesh\n\n    return meshes_lods\n</code></pre>"},{"location":"reference/cj_loading/cj_to_gltf/","title":"cj_to_gltf","text":"<p>Scripts to load CityJSON files exported by the other scripts and export to a dual CityJSON/glTF format by transferring all the geometry to glTF.</p> <p>Classes:</p> Name Description <code>Cityjson2Gltf</code> <p>Load a CityJSON file and transforms it into a pair formed by a glTF file storing the geometry and a CityJSON file storing the attributes.</p>"},{"location":"reference/cj_loading/cj_to_gltf/#cj_loading.cj_to_gltf.Cityjson2Gltf","title":"<code>Cityjson2Gltf</code>","text":"<p>               Bases: <code>data_pipeline.cj_loading.cj_loader.CityjsonLoader</code></p> <p>Load a CityJSON file and transforms it into a pair formed by a glTF file storing the geometry and a CityJSON file storing the attributes. The hierarchy of the CityJSON file is fully preserved, only the geometry is removed and stored in glTF, with identifiers of the form <code>&lt;cityjson_key&gt;-lod_&lt;lod&gt;</code>. The hierarchy of the CityJSON file is also reproduced in glTF, with all LoDs stored as children of their main object, which has no geometry.</p> <p>Methods:</p> Name Description <code>export</code> <p>Export the dual representation into the given folder.</p> <code>make_gltf_scene</code> <p>Create the scene for glTF, preserving the structure from the CityJSON input.</p> Source code in <code>python/src/data_pipeline/cj_loading/cj_to_gltf.py</code> <pre><code>class Cityjson2Gltf(CityjsonLoader):\n    \"\"\"\n    Load a CityJSON file and transforms it into a pair formed by a glTF file storing the geometry and a CityJSON file storing the attributes.\n    The hierarchy of the CityJSON file is fully preserved, only the geometry is removed and stored in glTF, with identifiers of the form `&lt;cityjson_key&gt;-lod_&lt;lod&gt;`.\n    The hierarchy of the CityJSON file is also reproduced in glTF, with all LoDs stored as children of their main object, which has no geometry.\n    \"\"\"\n\n    def __init__(self, cj_path: Path) -&gt; None:\n        super().__init__(cj_path)\n\n    def make_gltf_scene(self):\n        \"\"\"\n        Create the scene for glTF, preserving the structure from the CityJSON input.\n        \"\"\"\n        objects: dict[str, dict] = self.data[\"CityObjects\"]\n        scene = trimesh.Scene()\n\n        # First insert all the objects without hierarchy\n        for obj_key, obj in tqdm(objects.items(), desc=\"Inserting the objects\"):\n            meshes_lods = cj_object_to_mesh(\n                obj_dict=obj,\n                vertices=self.vertices,\n            )\n            # Insert an empty node so children can still to it\n            scene.graph.update(frame_to=obj_key, frame_from=None, matrix=np.eye(4))\n            if meshes_lods is not None:\n                for lod, mesh in meshes_lods.items():\n                    scene.add_geometry(\n                        mesh,\n                        node_name=obj_key + \"-lod_\" + lod,\n                        parent_node_name=obj_key,\n                    )\n\n        # Then set up the structure\n        for obj_key, obj in tqdm(objects.items(), desc=\"Setting up the structure\"):\n            parent = obj.get(\"parent\", None)\n            if parent is not None:\n                # Attach child node to its parent in the scene graph\n                scene.graph.update(\n                    frame_to=obj_key,\n                    frame_from=parent,\n                    matrix=np.eye(4),\n                )\n            # If the object defines explicit \"children\", ensure they are linked too\n            for child_id in obj.get(\"children\", []):\n                scene.graph.update(\n                    frame_to=child_id,\n                    frame_from=obj_key,\n                    matrix=np.eye(4),\n                )\n\n        self.scene = scene\n\n    def export(self, output_folder: Path, overwrite: bool = False) -&gt; None:\n        \"\"\"\n        Export the dual representation into the given folder.\n\n        Parameters\n        ----------\n        output_folder : Path\n            The path to the folder where the files should be written.\n        overwrite : bool, optional\n            Whether to overwrite the files if they exist.\n            By default False.\n\n        Raises\n        ------\n        RuntimeError\n            If the path of any of the two outputs already exists and `overwrite` was not set to True.\n        \"\"\"\n        output_folder.mkdir(parents=True, exist_ok=overwrite)\n        glb_path = output_folder / \"geometry.glb\"\n        cj_path = output_folder / \"attributes.city.json\"\n        if not overwrite:\n            if glb_path.exists():\n                raise RuntimeError(\n                    f\"File {glb_path} already exists. Set `overwrite` to True to overwrite.\"\n                )\n            if cj_path.exists():\n                raise RuntimeError(\n                    f\"File {cj_path} already exists. Set `overwrite` to True to overwrite.\"\n                )\n\n        # Write the glb file with geometry\n        self.scene.export(glb_path)\n\n        # Write the CityJSON file with structure and attributes\n        cj_data_copy = deepcopy(self.data)\n        objects: dict[str, dict[str, Any]] = cj_data_copy[\"CityObjects\"]\n        # Remove the geometry\n        for obj in objects.values():\n            if \"geometry\" in obj:\n                obj.pop(\"geometry\")\n        cj_data_copy[\"vertices\"] = []\n        with open(cj_path, \"w\") as cj_file:\n            json.dump(cj_data_copy, cj_file)\n</code></pre>"},{"location":"reference/cj_loading/cj_to_gltf/#cj_loading.cj_to_gltf.Cityjson2Gltf.export","title":"<code>export(output_folder, overwrite=False)</code>","text":"<p>Export the dual representation into the given folder.</p> <p>Parameters:</p> Name Type Description Default <code>output_folder</code> <code>pathlib.Path</code> <p>The path to the folder where the files should be written.</p> required <code>overwrite</code> <code>bool</code> <p>Whether to overwrite the files if they exist. By default False.</p> <code>False</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the path of any of the two outputs already exists and <code>overwrite</code> was not set to True.</p> Source code in <code>python/src/data_pipeline/cj_loading/cj_to_gltf.py</code> <pre><code>def export(self, output_folder: Path, overwrite: bool = False) -&gt; None:\n    \"\"\"\n    Export the dual representation into the given folder.\n\n    Parameters\n    ----------\n    output_folder : Path\n        The path to the folder where the files should be written.\n    overwrite : bool, optional\n        Whether to overwrite the files if they exist.\n        By default False.\n\n    Raises\n    ------\n    RuntimeError\n        If the path of any of the two outputs already exists and `overwrite` was not set to True.\n    \"\"\"\n    output_folder.mkdir(parents=True, exist_ok=overwrite)\n    glb_path = output_folder / \"geometry.glb\"\n    cj_path = output_folder / \"attributes.city.json\"\n    if not overwrite:\n        if glb_path.exists():\n            raise RuntimeError(\n                f\"File {glb_path} already exists. Set `overwrite` to True to overwrite.\"\n            )\n        if cj_path.exists():\n            raise RuntimeError(\n                f\"File {cj_path} already exists. Set `overwrite` to True to overwrite.\"\n            )\n\n    # Write the glb file with geometry\n    self.scene.export(glb_path)\n\n    # Write the CityJSON file with structure and attributes\n    cj_data_copy = deepcopy(self.data)\n    objects: dict[str, dict[str, Any]] = cj_data_copy[\"CityObjects\"]\n    # Remove the geometry\n    for obj in objects.values():\n        if \"geometry\" in obj:\n            obj.pop(\"geometry\")\n    cj_data_copy[\"vertices\"] = []\n    with open(cj_path, \"w\") as cj_file:\n        json.dump(cj_data_copy, cj_file)\n</code></pre>"},{"location":"reference/cj_loading/cj_to_gltf/#cj_loading.cj_to_gltf.Cityjson2Gltf.make_gltf_scene","title":"<code>make_gltf_scene()</code>","text":"<p>Create the scene for glTF, preserving the structure from the CityJSON input.</p> Source code in <code>python/src/data_pipeline/cj_loading/cj_to_gltf.py</code> <pre><code>def make_gltf_scene(self):\n    \"\"\"\n    Create the scene for glTF, preserving the structure from the CityJSON input.\n    \"\"\"\n    objects: dict[str, dict] = self.data[\"CityObjects\"]\n    scene = trimesh.Scene()\n\n    # First insert all the objects without hierarchy\n    for obj_key, obj in tqdm(objects.items(), desc=\"Inserting the objects\"):\n        meshes_lods = cj_object_to_mesh(\n            obj_dict=obj,\n            vertices=self.vertices,\n        )\n        # Insert an empty node so children can still to it\n        scene.graph.update(frame_to=obj_key, frame_from=None, matrix=np.eye(4))\n        if meshes_lods is not None:\n            for lod, mesh in meshes_lods.items():\n                scene.add_geometry(\n                    mesh,\n                    node_name=obj_key + \"-lod_\" + lod,\n                    parent_node_name=obj_key,\n                )\n\n    # Then set up the structure\n    for obj_key, obj in tqdm(objects.items(), desc=\"Setting up the structure\"):\n        parent = obj.get(\"parent\", None)\n        if parent is not None:\n            # Attach child node to its parent in the scene graph\n            scene.graph.update(\n                frame_to=obj_key,\n                frame_from=parent,\n                matrix=np.eye(4),\n            )\n        # If the object defines explicit \"children\", ensure they are linked too\n        for child_id in obj.get(\"children\", []):\n            scene.graph.update(\n                frame_to=child_id,\n                frame_from=obj_key,\n                matrix=np.eye(4),\n            )\n\n    self.scene = scene\n</code></pre>"},{"location":"reference/cj_writing/","title":"cj_writing","text":"<p>Collection of scripts to load files from various formats and write them to CityJSON.</p> <p>Modules:</p> Name Description <code>bag_to_cj</code> <p>Scripts to load 3DBAG building shells and export them to CityJSON after adding custom attributes.</p> <code>gj_to_cj</code> <p>Scripts to load icons from GeoJSON and export them to CityJSON.</p> <code>gltf_to_cj</code> <p>Scripts to load custom geometry (building shells and rooms) and export them to CityJSON after adding custom attributes.</p>"},{"location":"reference/cj_writing/bag_to_cj/","title":"bag_to_cj","text":"<p>Scripts to load 3DBAG building shells and export them to CityJSON after adding custom attributes.</p> <p>Classes:</p> Name Description <code>Bag2Cityjson</code> <p>Class to process the 3DBAG building shells and combine them with attributes.</p> <p>Functions:</p> Name Description <code>process_bag_geoms</code> <p>Process the geometry of multiple CityJSON objects and combines them into one mesh, for each LoD.</p>"},{"location":"reference/cj_writing/bag_to_cj/#cj_writing.bag_to_cj.Bag2Cityjson","title":"<code>Bag2Cityjson</code>","text":"<p>               Bases: <code>data_pipeline.cj_loading.cj_loader.CityjsonLoader</code></p> <p>Class to process the 3DBAG building shells and combine them with attributes.</p> <p>Methods:</p> Name Description <code>export</code> <p>Export the result to the given path.</p> Source code in <code>python/src/data_pipeline/cj_writing/bag_to_cj.py</code> <pre><code>class Bag2Cityjson(CityjsonLoader):\n    \"\"\"\n    Class to process the 3DBAG building shells and combine them with attributes.\n    \"\"\"\n\n    def __init__(\n        self,\n        cj_path: Path,\n        bdgs_attr_path: Optional[Path],\n        bdgs_sub_attr_path: Optional[Path],\n    ) -&gt; None:\n        super().__init__(cj_path)\n\n        self.cj_file = self._connect_buildings_attributes(\n            bdgs_attr_path=bdgs_attr_path,\n            bdgs_sub_attr_path=bdgs_sub_attr_path,\n        )\n\n    def _connect_buildings_attributes(\n        self,\n        bdgs_attr_path: Optional[Path],\n        bdgs_sub_attr_path: Optional[Path],\n    ) -&gt; CityJSONFile:\n        \"\"\"\n        Very big (too big) function that iterates over the given attributes and extract their associated geometries, formatting them into a CityJSONFile instance that can then be exported.\n\n        Parameters\n        ----------\n        bdgs_attr_path : Optional[Path]\n            Path to the CSV attributes of buildings.\n        bdgs_sub_attr_path : Optional[Path]\n            Path to the CSV attributes of buildings subdivisions.\n\n        Returns\n        -------\n        CityJSONFile\n            All the buildings with their attributes and units.\n\n        Raises\n        ------\n        RuntimeError\n            If the same CityJSON key is created twice for two different objects.\n        \"\"\"\n\n        # Used to remember which 3DBAG buildings have already been processed\n        unprocessed_bag_ids: set[str] = set(self.data[\"CityObjects\"].keys())\n\n        # Initialise CityJSON objects lists\n        all_objects_cj: dict[str, CityJSONObjectSubclass] = {}\n\n        def _process_bag_element(\n            obj_key: str,\n            bag_ids: list[str],\n            unprocessed_bag_ids: set[str] | None = None,\n            skip: bool = False,\n        ) -&gt; list[MultiSurface] | None:\n            logging.log(logging.DEBUG, f\"Processing {obj_key}\")\n\n            # Check if the key is already used\n            if obj_key in all_objects_cj.keys():\n                raise RuntimeError(\n                    f\"Object id {obj_key} already corresponds to another building.\"\n                )\n\n            # Skip the building if using custom geometry instead\n            if skip:\n                if unprocessed_bag_ids is not None:\n                    unprocessed_bag_ids -= set(bag_ids)\n                return\n\n            all_geoms, processed_bag_ids = process_bag_geoms(\n                cj_objects=self.data[\"CityObjects\"],\n                vertices=self.vertices,\n                bag_2d_ids=bag_ids,\n            )\n\n            # Update the list of unprocessed bag ids\n            if unprocessed_bag_ids is not None:\n                unprocessed_bag_ids -= set(processed_bag_ids)\n\n            return all_geoms\n\n        # Iterate over the buildings\n        if bdgs_attr_path is not None:\n            bdgs_attributes_all = BdgAttrReader(csv_path=bdgs_attr_path)\n            bdgs_iterator = bdgs_attributes_all.iterator()\n            for key, bdg_attributes in tqdm(\n                bdgs_iterator,\n                desc=\"Processing the buildings with attributes\",\n                total=len(bdgs_attributes_all),\n            ):\n                space_id = bdg_attributes.space_id\n                obj_key = Building.key_to_cj_key(key=bdg_attributes.cj_key)\n\n                geoms = _process_bag_element(\n                    obj_key=obj_key,\n                    bag_ids=bdg_attributes.bag_ids,\n                    unprocessed_bag_ids=unprocessed_bag_ids,\n                    skip=bdg_attributes.skip,\n                )\n\n                if geoms is not None:\n                    building = Building(\n                        cj_key=obj_key,\n                        space_id=space_id,\n                        geometries=geoms,\n                        icon_position=bdg_attributes.icon_position,\n                    )\n                    building.add_attributes(bdg_attributes.attributes)\n                    all_objects_cj[obj_key] = building\n\n        # Iterate over the units\n        if bdgs_sub_attr_path is not None:\n            bdgs_sub_attributes_all = BdgSubAttrReader(csv_path=bdgs_sub_attr_path)\n            bdgs_sub_iterator = bdgs_sub_attributes_all.iterator()\n        for key, bdgs_sub_attributes in tqdm(\n            bdgs_sub_iterator,\n            desc=\"Processing the units\",\n            total=len(bdgs_sub_attributes_all),\n        ):\n            space_id = bdgs_sub_attributes.space_id\n            parent_key = bdgs_sub_attributes.parent_cj_key\n            prefix = CityJSONSpace.key_to_prefix(key=parent_key)\n\n            # Add the missing hierarchy in the codes\n            main_container_id = BuildingUnitContainer.unit_code_to_cj_key(\n                code=BuildingUnitContainer.main_parent_code, prefix=prefix\n            )\n            if main_container_id not in all_objects_cj:\n                main_container = BuildingUnitContainer(\n                    cj_key=main_container_id,\n                    unit_code=BuildingUnitContainer.main_parent_code,\n                )\n                bdg_obj_key = Building.key_to_cj_key(key=parent_key)\n                bdg_obj = all_objects_cj[bdg_obj_key]\n                all_objects_cj[main_container_id] = main_container\n                CityJSONObject.add_parent_child(parent=bdg_obj, child=main_container)\n\n            z_container_id = BuildingUnitContainer.unit_code_to_cj_key(\n                code=\"BS-SP\", prefix=prefix\n            )\n            if z_container_id not in all_objects_cj:\n                z_container = BuildingUnitContainer(\n                    cj_key=z_container_id, unit_code=\"BS-SP\"\n                )\n                all_objects_cj[z_container_id] = z_container\n                CityJSONObject.add_parent_child(\n                    parent=main_container, child=z_container\n                )\n            z_container = all_objects_cj[z_container_id]\n            assert isinstance(z_container, BuildingUnitContainer)\n\n            # Find the number of units with the same code\n            units_same_code = len(z_container.children_ids)\n\n            obj_key = BuildingUnit.unit_code_to_cj_key(\n                code=\"BS-SP\", prefix=prefix, index=units_same_code\n            )\n\n            unit = BuildingUnit(\n                cj_key=obj_key,\n                unit_code=\"BS-SP\",\n                unit_storeys=[],\n                icon_position=bdgs_sub_attributes.icon_position,\n            )\n            unit.add_attributes({\"subdivision_number\": space_id})\n            unit.add_attributes(bdgs_sub_attributes.attributes)\n            all_objects_cj[obj_key] = unit\n\n            # Connect to the parent building\n            CityJSONObject.add_parent_child(parent=z_container, child=unit)\n\n        # Add the remaining buildings\n        for bag_2d_id in tqdm(\n            unprocessed_bag_ids, desc=\"Processing the remaining buildings\"\n        ):\n            # Skip the children\n            if bag_2d_id[-2] == \"-\":\n                continue\n\n            obj_key = Building.key_to_cj_key(key=bag_2d_id)\n\n            geoms = _process_bag_element(\n                obj_key=obj_key,\n                bag_ids=[bag_2d_id],\n            )\n\n            if geoms is not None:\n\n                building = Building(\n                    cj_key=obj_key, space_id=bag_2d_id, geometries=geoms\n                )\n                all_objects_cj[obj_key] = building\n\n        cj_file = CityJSONFile(\n            scale=np.array([0.00001, 0.00001, 0.00001], dtype=np.float64),\n            translate=np.array([0, 0, 0], dtype=np.float64),\n        )\n        cj_file.add_cityjson_objects(list(all_objects_cj.values()))\n\n        return cj_file\n\n    def export(self, output_cj_path: Path) -&gt; None:\n        \"\"\"\n        Export the result to the given path.\n\n        Parameters\n        ----------\n        output_cj_path : Path\n            The path to export to.\n        \"\"\"\n        # Check the correctness of the hierarchy\n        self.cj_file.check_objects_hierarchy()\n\n        # Write to CityJSON\n        output_cj_path.parent.mkdir(parents=True, exist_ok=True)\n        file_json = self.cj_file.to_json()\n        with open(output_cj_path, \"w\") as f:\n            f.write(file_json)\n</code></pre>"},{"location":"reference/cj_writing/bag_to_cj/#cj_writing.bag_to_cj.Bag2Cityjson.export","title":"<code>export(output_cj_path)</code>","text":"<p>Export the result to the given path.</p> <p>Parameters:</p> Name Type Description Default <code>output_cj_path</code> <code>pathlib.Path</code> <p>The path to export to.</p> required Source code in <code>python/src/data_pipeline/cj_writing/bag_to_cj.py</code> <pre><code>def export(self, output_cj_path: Path) -&gt; None:\n    \"\"\"\n    Export the result to the given path.\n\n    Parameters\n    ----------\n    output_cj_path : Path\n        The path to export to.\n    \"\"\"\n    # Check the correctness of the hierarchy\n    self.cj_file.check_objects_hierarchy()\n\n    # Write to CityJSON\n    output_cj_path.parent.mkdir(parents=True, exist_ok=True)\n    file_json = self.cj_file.to_json()\n    with open(output_cj_path, \"w\") as f:\n        f.write(file_json)\n</code></pre>"},{"location":"reference/cj_writing/bag_to_cj/#cj_writing.bag_to_cj.process_bag_geoms","title":"<code>process_bag_geoms(cj_objects, vertices, bag_2d_ids)</code>","text":"<p>Process the geometry of multiple CityJSON objects and combines them into one mesh, for each LoD.</p> <p>Parameters:</p> Name Type Description Default <code>cj_objects</code> <code>dict[str, dict[str, typing.Any]]</code> <p>The input CityJSON file as a dictionary.</p> required <code>vertices</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>The vertices correctly transformed to their actual coordinates.</p> required <code>bag_2d_ids</code> <code>list[str]</code> <p>The IDs of the objects to extract from <code>cj_objects</code> and to combine into one mesh.</p> required <p>Returns:</p> Type Description <code>list[data_pipeline.cj_helpers.cj_geometry.MultiSurface]</code> <p>All the geometries.</p> <code>list[str]</code> <p>All the IDs from 3DBAG that were included in the geometry.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If an object from <code>cj_objects</code> has no geometry, which is not expected from the 3DBAG.</p> Source code in <code>python/src/data_pipeline/cj_writing/bag_to_cj.py</code> <pre><code>def process_bag_geoms(\n    cj_objects: dict[str, dict[str, Any]],\n    vertices: NDArray[np.float64],\n    bag_2d_ids: list[str],\n) -&gt; tuple[list[MultiSurface], list[str]]:\n    \"\"\"\n    Process the geometry of multiple CityJSON objects and combines them into one mesh, for each LoD.\n\n    Parameters\n    ----------\n    cj_objects : dict[str, dict[str, Any]]\n        The input CityJSON file as a dictionary.\n    vertices : NDArray[np.float64]\n        The vertices correctly transformed to their actual coordinates.\n    bag_2d_ids : list[str]\n        The IDs of the objects to extract from `cj_objects` and to combine into one mesh.\n\n    Returns\n    -------\n    list[MultiSurface]\n        All the geometries.\n    list[str]\n        All the IDs from 3DBAG that were included in the geometry.\n\n    Raises\n    ------\n    RuntimeError\n        If an object from `cj_objects` has no geometry, which is not expected from the\n        3DBAG.\n    \"\"\"\n    # Extract the ids of all the BAG buidlings that constitue this building\n    bag_3d_ids = []\n\n    if len(bag_2d_ids) == 0:\n        return [], []\n\n    # Load all the geometries as Trimesh\n    all_meshes: dict[int, list[trimesh.Trimesh]] = {0: [], 1: [], 2: []}\n    for bag_2d_id in bag_2d_ids:\n        # Extract LoD 0 geometry\n        bag_2d = cj_objects[bag_2d_id]\n        meshes_lods = cj_object_to_mesh(obj_dict=bag_2d, vertices=vertices)\n        if meshes_lods is None:\n            raise RuntimeError(\n                f\"An object without geometry is unexpected in the 3DBAG.\"\n            )\n        all_meshes[0].append(meshes_lods[\"0\"])\n\n        # Process the children\n        for bag_3d_id in bag_2d[\"children\"]:\n            bag_3d_ids.append(bag_3d_id)\n            obj_3d = cj_objects[bag_3d_id]\n            meshes_lods = cj_object_to_mesh(obj_dict=obj_3d, vertices=vertices)\n            if meshes_lods is None:\n                raise RuntimeError(\n                    f\"An object without geometry is unexpected in the 3DBAG.\"\n                )\n            all_meshes[1].append(meshes_lods[\"1.3\"])\n            all_meshes[2].append(meshes_lods[\"2.2\"])\n\n    # Merge all the meshes at the same LoD\n    final_meshes: dict[int, trimesh.Trimesh] = {}\n    for lod, meshes in all_meshes.items():\n        full_mesh = merge_trimeshes(meshes=meshes, fix_geometry=True)\n        final_meshes[lod] = full_mesh\n\n    all_geoms = []\n\n    # # Add LoD 0 geometry\n    #\n    # lod_0_mesh = flatten_trimesh(final_meshes[1])\n    # all_geoms.append(MultiSurface.from_mesh(lod=0, mesh=lod_0_mesh))\n\n    # Add the other geoms\n    orient_polygons_z_up(final_meshes[0])\n    all_geoms.append(MultiSurface.from_mesh(lod=0, mesh=final_meshes[0]))\n    all_geoms.append(MultiSurface.from_mesh(lod=1, mesh=final_meshes[1]))\n    all_geoms.append(MultiSurface.from_mesh(lod=2, mesh=final_meshes[2]))\n\n    return (all_geoms, bag_2d_ids + bag_3d_ids)\n</code></pre>"},{"location":"reference/cj_writing/gj_to_cj/","title":"gj_to_cj","text":"<p>Scripts to load icons from GeoJSON and export them to CityJSON.</p> <p>Functions:</p> Name Description <code>load_geojson_icons</code> <p>Load the icons from a GeoJSON file.</p>"},{"location":"reference/cj_writing/gj_to_cj/#cj_writing.gj_to_cj.load_geojson_icons","title":"<code>load_geojson_icons(gj_path, output_cj_path)</code>","text":"<p>Load the icons from a GeoJSON file.</p> <p>Parameters:</p> Name Type Description Default <code>gj_path</code> <code>pathlib.Path</code> <p>Path of GeoJSON file storing the icons.</p> required <code>output_cj_path</code> <code>pathlib.Path</code> <p>CityJSON path to export the icons to.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the data is not a FeatureCollection.</p> <code>NotImplementedError</code> <p>If the CRS is not EPSG:7415.</p> <code>RuntimeError</code> <p>If a feature does not have a code.</p> <code>NotImplementedError</code> <p>If a feature is not a Point.</p> Source code in <code>python/src/data_pipeline/cj_writing/gj_to_cj.py</code> <pre><code>def load_geojson_icons(gj_path: Path, output_cj_path: Path):\n    \"\"\"\n    Load the icons from a GeoJSON file.\n\n    Parameters\n    ----------\n    gj_path : Path\n        Path of GeoJSON file storing the icons.\n    output_cj_path : Path\n        CityJSON path to export the icons to.\n\n    Raises\n    ------\n    NotImplementedError\n        If the data is not a FeatureCollection.\n    NotImplementedError\n        If the CRS is not EPSG:7415.\n    RuntimeError\n        If a feature does not have a code.\n    NotImplementedError\n        If a feature is not a Point.\n    \"\"\"\n    with open(gj_path) as gj_file:\n        gj_data: dict[str, Any] = json.load(gj_file)\n    if gj_data.get(\"type\", \"\") != \"FeatureCollection\":\n        raise NotImplementedError(\n            f\"Only 'FeatureCollection' is supported for now, not '{gj_data.get(\"type\", \"\")}'\"\n        )\n    if (\n        gj_data.get(\"crs\", {}).get(\"properties\", {}).get(\"name\", \"\")\n        != \"urn:ogc:def:crs:EPSG::7415\"\n    ):\n        raise NotImplementedError(\n            f\"Only 'EPSG:7415' is supported for now, not '{gj_data.get(\"crs\", {})}'\"\n        )\n\n    prefix = \"Outdoor\"\n    outdoor_container = OutdoorObject(prefix=prefix)\n\n    all_units: dict[str, list[OutdoorUnit]] = defaultdict(lambda: [])\n    for feature in gj_data.get(\"features\", []):\n        # Extract the code\n        attributes = feature[\"properties\"]\n        code_column = \"Type Code [str]\"\n        if code_column not in attributes:\n            raise RuntimeError(\n                \"At least one feature is missing the attribute 'code_column'\"\n            )\n        unit_code = attributes[code_column]\n        if unit_code is None:\n            continue\n\n        # Compute the id\n        current_units_same_code = len(all_units[unit_code])\n        unit_id = OutdoorUnit.unit_code_to_id(\n            code=unit_code, prefix=prefix, number=current_units_same_code\n        )\n\n        # Get the icon position\n        geometry = feature[\"geometry\"]\n        if geometry.get(\"type\", \"\") != \"Point\":\n            raise NotImplementedError(\n                f\"Only the 'Point' geometry is supported, not '{geometry.get(\"type\", \"\")}\"\n            )\n\n        icon_coordinates: list[float] = geometry[\"coordinates\"]\n        if len(geometry) == 2:\n            icon_coordinates.append(0)\n        icon_position = IconPosition.from_list(icon_coordinates)\n\n        attributes = {}\n        for key, value in feature[\"properties\"].items():\n            if key.endswith(\"]\"):\n                col_name, col_value = csv_get_row_value(row={key: value}, column=key)\n                attributes[col_name] = col_value\n\n        # Create the outdoor unit\n        unit = OutdoorUnit(\n            cj_key=unit_id,\n            unit_code=unit_code,\n            attributes=attributes,\n            icon_position=icon_position,\n        )\n        all_units[unit_code].append(unit)\n\n    # Create the unit containers\n    unit_containers: list[OutdoorUnitContainer] = []\n    for code, units in all_units.items():\n        unit_container_id = OutdoorUnitContainer.unit_code_to_cj_key(\n            code=code, prefix=prefix\n        )\n        unit_container = OutdoorUnitContainer(\n            cj_key=unit_container_id, unit_code=code, attributes={}\n        )\n        unit_containers.append(unit_container)\n\n        CityJSONObject.add_parent_child(parent=outdoor_container, child=unit_container)\n        for unit in units:\n            CityJSONObject.add_parent_child(parent=unit_container, child=unit)\n\n    cj_file = CityJSONFile(\n        scale=np.array([0.00001, 0.00001, 0.00001], dtype=np.float64),\n        translate=np.array([0, 0, 0], dtype=np.float64),\n    )\n\n    cj_file.add_cityjson_objects([outdoor_container])\n    cj_file.add_cityjson_objects(unit_containers)\n    cj_file.add_cityjson_objects(\n        [unit for units in all_units.values() for unit in units]\n    )\n\n    # Check the correctness of the hierarchy\n    cj_file.check_objects_hierarchy()\n\n    # Write to CityJSON\n    output_cj_path.parent.mkdir(parents=True, exist_ok=True)\n    file_json = cj_file.to_json()\n    with open(output_cj_path, \"w\") as f:\n        f.write(file_json)\n</code></pre>"},{"location":"reference/cj_writing/gltf_to_cj/","title":"gltf_to_cj","text":"<p>Scripts to load custom geometry (building shells and rooms) and export them to CityJSON after adding custom attributes.</p> <p>Functions:</p> Name Description <code>full_building_from_gltf</code> <p>Load and structure the building shell/parts/storeys/rooms from a glTF path based on the IDs of the objects.</p> <code>load_units_from_csv</code> <p>Load the units from the given CSV file and attach them to their geometry in the given CityJSONFile.</p>"},{"location":"reference/cj_writing/gltf_to_cj/#cj_writing.gltf_to_cj.full_building_from_gltf","title":"<code>full_building_from_gltf(gltf_path)</code>","text":"<p>Load and structure the building shell/parts/storeys/rooms from a glTF path based on the IDs of the objects.</p> <p>Parameters:</p> Name Type Description Default <code>gltf_path</code> <code>pathlib.Path</code> <p>The glTF path containing the building shell and rooms.</p> required <p>Returns:</p> Type Description <code>data_pipeline.cj_helpers.cj_objects.CityJSONFile</code> <p>All the geometry formatted and structured properly.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the space ID has an unexpected format.</p> Source code in <code>python/src/data_pipeline/cj_writing/gltf_to_cj.py</code> <pre><code>def full_building_from_gltf(gltf_path: Path) -&gt; CityJSONFile:\n    \"\"\"\n    Load and structure the building shell/parts/storeys/rooms from a glTF path based on the IDs of the objects.\n\n    Parameters\n    ----------\n    gltf_path : Path\n        The glTF path containing the building shell and rooms.\n\n    Returns\n    -------\n    CityJSONFile\n        All the geometry formatted and structured properly.\n\n    Raises\n    ------\n    RuntimeError\n        If the space ID has an unexpected format.\n    \"\"\"\n    # Load the scene\n    scene = trimesh.load_scene(gltf_path)\n\n    graph: nx.DiGraph = scene.graph.to_networkx()  # type: ignore\n\n    # Start from the root\n    root_id = \"world\"\n\n    # Get the scene collection\n    all_objects_ids = list(graph.successors(root_id))\n    all_objects_geoms: dict[str, list[Geometry]] = defaultdict(lambda: [])\n\n    # Process all the objects and their geometries\n    for obj_key in tqdm(all_objects_ids, desc=\"Process all geometries\"):\n        geom, name = _geom_and_name_from_scene_id(scene=scene, cj_key=obj_key)\n        all_objects_geoms[name].append(geom)\n\n    # # Add LoD 0 geometry to all objects that only have higher geometries\n    # for object_geoms in tqdm(\n    #     all_objects_geoms.values(), desc=\"Build missing LoD 0 geometries\"\n    # ):\n    #     lods_to_geoms = {geom.lod: geom for geom in object_geoms}\n    #     if len(lods_to_geoms) &gt; 0 and not 0 in lods_to_geoms.keys():\n    #         smallest_lod = min(lods_to_geoms.keys())\n    #         base_mesh = lods_to_geoms[smallest_lod].to_trimesh()\n    #         lod_0_mesh = flatten_trimesh(base_mesh)\n    #         object_geoms.append(MultiSurface.from_mesh(lod=0, mesh=lod_0_mesh))\n\n    logging.info(\"Add the missing hierarchy.\")\n\n    # Add the missing hierarchy without geometry\n    current_objects = list(all_objects_geoms.keys())\n    for space_id in current_objects:\n        last_dot_position = space_id.rfind(\".\")\n        while last_dot_position != -1:\n            parent_space_id = space_id[:last_dot_position]\n            if parent_space_id not in all_objects_geoms.keys():\n                all_objects_geoms[parent_space_id] = []\n            last_dot_position = parent_space_id.rfind(\".\")\n\n    logging.info(\"Transform into actual CityJSON objects.\")\n\n    # Store the geometry into actual objects\n    all_objects_cj: dict[str, CityJSONObjectSubclass] = {}\n    for space_id, geoms in all_objects_geoms.items():\n        hierarchy_level = space_id.count(\".\")\n        if hierarchy_level == 0:\n            obj_func = Building\n        elif hierarchy_level == 1:\n            obj_func = BuildingPart\n        elif hierarchy_level == 2:\n            obj_func = BuildingStorey\n        elif hierarchy_level == 3:\n            obj_func = BuildingRoom\n        else:\n            raise RuntimeError(\n                f\"Unexpected format for an object space id: '{space_id}'\"\n            )\n\n        obj_key = obj_func.key_to_cj_key(key=space_id)\n\n        all_objects_cj[space_id] = obj_func(\n            cj_key=obj_key, space_id=space_id, geometries=geoms\n        )\n\n    logging.info(\"Apply the parent-child relationships.\")\n\n    # Apply the parent-child relationships\n    for obj_name in all_objects_cj.keys():\n        last_dot_position = obj_name.rfind(\".\")\n        if last_dot_position != -1:\n            obj_parent_name = obj_name[:last_dot_position]\n            CityJSONObject.add_parent_child(\n                parent=all_objects_cj[obj_parent_name], child=all_objects_cj[obj_name]\n            )\n\n    cj_file = CityJSONFile(\n        scale=np.array([0.00001, 0.00001, 0.00001], dtype=np.float64),\n        translate=np.array([0, 0, 0], dtype=np.float64),\n    )\n    cj_file.add_cityjson_objects(list(all_objects_cj.values()))\n\n    logging.info(\"Done processing the full building.\")\n\n    return cj_file\n</code></pre>"},{"location":"reference/cj_writing/gltf_to_cj/#cj_writing.gltf_to_cj.load_units_from_csv","title":"<code>load_units_from_csv(cj_file, csv_path, gltf_path)</code>","text":"<p>Load the units from the given CSV file and attach them to their geometry in the given CityJSONFile. Also accepts an optional glTF path containing the geometry of the units that have geometry.</p> <p>Parameters:</p> Name Type Description Default <code>cj_file</code> <code>data_pipeline.cj_helpers.cj_objects.CityJSONFile</code> <p>The CityJSON objects, already containing the spaces.</p> required <code>csv_path</code> <code>pathlib.Path</code> <p>The CSV path to the units attributes.</p> required <code>gltf_path</code> <code>pathlib.Path | None</code> <p>The glTF path to the units geometry.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the root of <code>cj_file</code> is not a Building.</p> Source code in <code>python/src/data_pipeline/cj_writing/gltf_to_cj.py</code> <pre><code>def load_units_from_csv(\n    cj_file: CityJSONFile,\n    csv_path: Path,\n    gltf_path: Path | None,\n) -&gt; None:\n    \"\"\"\n    Load the units from the given CSV file and attach them to their geometry in the given CityJSONFile.\n    Also accepts an optional glTF path containing the geometry of the units that have geometry.\n\n    Parameters\n    ----------\n    cj_file : CityJSONFile\n        The CityJSON objects, already containing the spaces.\n    csv_path : Path\n        The CSV path to the units attributes.\n    gltf_path : Path | None\n        The glTF path to the units geometry.\n\n    Raises\n    ------\n    RuntimeError\n        If the root of `cj_file` is not a Building.\n    \"\"\"\n    root_pos = cj_file.get_root_position()\n    root = cj_file.city_objects[root_pos]\n    if not isinstance(root, Building):\n        raise RuntimeError(\n            f\"The root of the `cj_file` should be a Building, not a {type(root)}\"\n        )\n    prefix = CityJSONSpace.key_to_prefix(key=root.space_id)\n    unit_main_container = BuildingUnitObject(prefix=prefix)\n    CityJSONObject.add_parent_child(parent=root, child=unit_main_container)\n\n    # Read the units geometry\n    if gltf_path is not None:\n        scene = trimesh.load_scene(gltf_path)\n\n    all_units: dict[str, list[BuildingUnit]] = defaultdict(lambda: [])\n\n    # Process the CSV file to find all the units\n    unit_to_spaces: dict[str, list[str]] = {}\n    units_attributes_all = BdgUnitAttrReader(csv_path=csv_path)\n    units_attributes_iterator = units_attributes_all.iterator()\n    for cj_key, units_attributes in units_attributes_iterator:\n        unit_code = units_attributes.code\n\n        # Get the potential geometry\n        unit_geometry = None\n        if gltf_path is not None:\n            unit_gltf = units_attributes.unit_gltf\n            if unit_gltf is not None:\n                unit_geometry = _get_unit_geometry_from_id(\n                    scene=scene, cj_key=unit_gltf\n                )\n\n        current_units_same_code = len(all_units[unit_code])\n        unit_id = BuildingUnit.unit_code_to_cj_key(\n            code=unit_code, prefix=prefix, index=current_units_same_code\n        )\n\n        unit = BuildingUnit(\n            cj_key=unit_id,\n            unit_code=unit_code,\n            unit_storeys=units_attributes.unit_storeys,\n            geometry=unit_geometry,\n            attributes=units_attributes.attributes,\n            icon_position=units_attributes.icon_position,\n        )\n        unit_to_spaces[unit.id] = units_attributes.unit_spaces\n        all_units[unit_code].append(unit)\n\n    unit_containers: list[BuildingUnitContainer] = []\n    for code, units in all_units.items():\n        unit_container_id = BuildingUnitContainer.unit_code_to_cj_key(\n            code=code, prefix=prefix\n        )\n        unit_container = BuildingUnitContainer(\n            cj_key=unit_container_id, unit_code=code, attributes={}\n        )\n        unit_containers.append(unit_container)\n\n        CityJSONObject.add_parent_child(\n            parent=unit_main_container, child=unit_container\n        )\n        for unit in units:\n            CityJSONObject.add_parent_child(parent=unit_container, child=unit)\n\n    # Extract all the spaces from the given CityJSON file\n    spaces_ids_to_pos = {}\n    for i, cj_obj in enumerate(cj_file.city_objects):\n        # We search for the actual spaces\n        if isinstance(cj_obj, CityJSONSpaceSubclass):\n            spaces_ids_to_pos[cj_obj.space_id] = i\n\n    # Add the links from spaces to the units they belong in\n    all_units_flattened = [unit for units in all_units.values() for unit in units]\n    for unit in all_units_flattened:\n        for space_id in unit_to_spaces[unit.id]:\n            cj_file_pos = spaces_ids_to_pos[space_id]\n            space = cj_file.city_objects[cj_file_pos]\n            assert isinstance(space, CityJSONSpaceSubclass)\n            CityJSONObject.add_unit_space(unit=unit, space=space)\n\n    # Compute the icon positions of the units\n    for unit in all_units_flattened:\n        meshes: list[trimesh.Trimesh] = []\n        for space_id in unit_to_spaces[unit.id]:\n            cj_file_pos = spaces_ids_to_pos[space_id]\n            space = cj_file.city_objects[cj_file_pos]\n            assert isinstance(space, CityJSONSpaceSubclass)\n            if space.geometries is None or len(space.geometries) == 0:\n                continue\n            best_idx = -1\n            best_lod = -1\n            for idx in range(0, len(space.geometries)):\n                if space.geometries[idx].lod &gt; best_lod:\n                    best_idx = idx\n                    best_lod = space.geometries[best_idx].lod\n            if best_idx &gt;= 0:\n                meshes.append(space.geometries[best_idx].to_trimesh())\n\n        if len(meshes) == 0:\n            continue\n\n        merged_mesh = merge_trimeshes(meshes=meshes, fix_geometry=False)\n        icon_position = IconPosition.from_mesh(\n            merged_mesh, z_offset=BuildingUnit.icon_z_offset\n        )\n        unit.set_icon(icon_position=icon_position)\n\n    cj_file.add_cityjson_objects([unit_main_container])\n    cj_file.add_cityjson_objects(unit_containers)\n    cj_file.add_cityjson_objects(\n        [unit for units in all_units.values() for unit in units]\n    )\n</code></pre>"},{"location":"reference/utils/","title":"utils","text":"<p>Collection of various scripts to help extract CSV information, format JSON files, compute the position of icons, and manipulate geometry.</p> <p>Modules:</p> Name Description <code>codelists</code> <p>Format the usage codelist into a convenient JSON file for the JavaScript app.</p> <code>csv_utils</code> <p>Process CSV files and add more robustness to the data manipulation by extracting and using a data type stored in the header of the CSV for each column.</p> <code>geometry_utils</code> <p>Utilities to process geometry (validation, triangulation, fusion, etc).</p> <code>icon_positions</code> <p>Utilities to store and compute 3D icon positions.</p> <code>plane</code> <p>Utilities to compute planes from points and manipulate points between 3D and 2D.</p>"},{"location":"reference/utils/codelists/","title":"codelists","text":"<p>Format the usage codelist into a convenient JSON file for the JavaScript app.</p> <p>Functions:</p> Name Description <code>format_codelist_json</code> <p>Helper script to format the CSV codelist into a more convenient JSON file.</p>"},{"location":"reference/utils/codelists/#utils.codelists.format_codelist_json","title":"<code>format_codelist_json(input_csv_path, output_json_path)</code>","text":"<p>Helper script to format the CSV codelist into a more convenient JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>input_csv_path</code> <code>pathlib.Path</code> <p>The input CSV path to the codelist.</p> required <code>output_json_path</code> <code>pathlib.Path</code> <p>The output JSON path of the formatted codelist.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If a code is duplicated in the input.</p> <code>RuntimeError</code> <p>If a CSV row does not have a code.</p> Source code in <code>python/src/data_pipeline/utils/codelists.py</code> <pre><code>def format_codelist_json(input_csv_path: Path, output_json_path: Path):\n    \"\"\"\n    Helper script to format the CSV codelist into a more convenient JSON file.\n\n    Parameters\n    ----------\n    input_csv_path : Path\n        The input CSV path to the codelist.\n    output_json_path : Path\n        The output JSON path of the formatted codelist.\n\n    Raises\n    ------\n    RuntimeError\n        If a code is duplicated in the input.\n    RuntimeError\n        If a CSV row does not have a code.\n    \"\"\"\n    specific_columns = (\"Code [str]\", \"Implies [list,str]\")\n    attributes_all, specific_values_all = csv_read_attributes(\n        csv_path=input_csv_path, specific_columns=specific_columns\n    )\n    codes_attributes = {}\n    codes_implied_by = defaultdict(lambda: [])\n    for attributes, specific_values in zip(attributes_all, specific_values_all):\n        _, code = specific_values[0]\n        implies_column, implies_value = specific_values[1]\n        if code in codes_attributes:\n            raise RuntimeError(f\"The code '{code}' is duplicated in the input.\")\n        if code == \"\":\n            raise RuntimeError(\"One row misses its code.\")\n        attributes[implies_column] = implies_value\n        codes_attributes[code] = attributes\n\n        # Store the implication backwards\n        for code_implied in implies_value:\n            codes_implied_by[code_implied].append(code)\n\n    # Compute the implication backwards\n    for code in codes_attributes.keys():\n        codes_attributes[code][\"Implied by\"] = codes_implied_by[code]\n\n    output_json_path.parent.mkdir(parents=True, exist_ok=True)\n    with open(output_json_path, \"w\") as f:\n        f.write(json.dumps(codes_attributes))\n</code></pre>"},{"location":"reference/utils/csv_utils/","title":"csv_utils","text":"<p>Process CSV files and add more robustness to the data manipulation by extracting and using a data type stored in the header of the CSV for each column.</p> <p>Functions:</p> Name Description <code>check_type</code> <p>Check if the type of the given value is one of the given expected types.</p> <code>csv_format_type</code> <p>Convert a given value extracted from CSV into the given type.</p> <code>csv_get_row_value</code> <p>Extract the value of a specific column of the given row, and convert it ot the type specified by the column header.</p> <code>csv_read_attributes</code> <p>Read all the values from a given CSV file and convert all the values according to the types specified by the header.</p> <code>string_to_type</code> <p>Return the actual Python type corresponding to the string.</p>"},{"location":"reference/utils/csv_utils/#utils.csv_utils.check_type","title":"<code>check_type(value, column_types)</code>","text":"<p>Check if the type of the given value is one of the given expected types.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>typing.Any</code> <p>Value to check.</p> required <code>column_types</code> <code>list[str]</code> <p>List of allowed types, represented as strings.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the type of the value is one of the expected types.</p> Source code in <code>python/src/data_pipeline/utils/csv_utils.py</code> <pre><code>def check_type(value: Any, column_types: list[str]) -&gt; bool:\n    \"\"\"\n    Check if the type of the given value is one of the given expected types.\n\n    Parameters\n    ----------\n    value : Any\n        Value to check.\n    column_types : list[str]\n        List of allowed types, represented as strings.\n\n    Returns\n    -------\n    bool\n        Whether the type of the value is one of the expected types.\n    \"\"\"\n    for column_type in column_types:\n        real_type = string_to_type(column_type)\n        if real_type == list:\n            if not isinstance(value, list):\n                continue\n\n            list_info = column_type[len(\"list\") :]\n            separator = list_info[0]\n            other_type = list_info[1:]\n            if all([check_type(item, [other_type]) for item in value]):\n                return True\n        elif isinstance(value, real_type):\n            return True\n\n    return False\n</code></pre>"},{"location":"reference/utils/csv_utils/#utils.csv_utils.csv_format_type","title":"<code>csv_format_type(value, column_type)</code>","text":"<p>Convert a given value extracted from CSV into the given type.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>Initial value.</p> required <code>column_type</code> <code>str</code> <p>Type to transform it into.</p> required <p>Returns:</p> Type Description <code>typing.Any</code> <p>The converted value.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the given type is unsupported.</p> Source code in <code>python/src/data_pipeline/utils/csv_utils.py</code> <pre><code>def csv_format_type(value: str, column_type: str) -&gt; Any:\n    \"\"\"\n    Convert a given value extracted from CSV into the given type.\n\n    Parameters\n    ----------\n    value : str\n        Initial value.\n    column_type : str\n        Type to transform it into.\n\n    Returns\n    -------\n    Any\n        The converted value.\n\n    Raises\n    ------\n    NotImplementedError\n        If the given type is unsupported.\n    \"\"\"\n    if column_type == \"str\":\n        return str(value)\n    elif column_type == \"float\":\n        if value == \"\":\n            return None\n        return float(value.replace(\",\", \".\"))\n    elif column_type == \"int\":\n        if value == \"\":\n            return None\n        return int(value)\n    elif column_type == \"bool\":\n        if value == \"\":\n            return None\n        return value.lower() == \"true\"\n    elif column_type.startswith(\"list\"):\n        if value == \"\":\n            return []\n        list_info = column_type[len(\"list\") :]\n        separator = list_info[0]\n        other_type = list_info[1:]\n        return [\n            csv_format_type(value=v, column_type=other_type)\n            for v in value.split(separator)\n        ]\n    else:\n        raise NotImplementedError(\n            f\"Support for type '{column_type}' is not implemented yet.\"\n        )\n</code></pre>"},{"location":"reference/utils/csv_utils/#utils.csv_utils.csv_get_row_value","title":"<code>csv_get_row_value(row, column)</code>","text":"<p>Extract the value of a specific column of the given row, and convert it ot the type specified by the column header.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>dict[str, str]</code> <p>The row as a mapping the column name to the value.</p> required <code>column</code> <code>str</code> <p>The column to extract.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The actual name of the column without the type.</p> <code>typing.Any</code> <p>The value of the column.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the column header is not formatted properly.</p> <code>RuntimeError</code> <p>If the type of the output is not correct.</p> Source code in <code>python/src/data_pipeline/utils/csv_utils.py</code> <pre><code>def csv_get_row_value(row: dict[str, str], column: str) -&gt; tuple[str, Any]:\n    \"\"\"\n    Extract the value of a specific column of the given row, and convert it ot the type specified by the column header.\n\n    Parameters\n    ----------\n    row : dict[str, str]\n        The row as a mapping the column name to the value.\n    column : str\n        The column to extract.\n\n    Returns\n    -------\n    str\n        The actual name of the column without the type.\n    Any\n        The value of the column.\n\n    Raises\n    ------\n    RuntimeError\n        If the column header is not formatted properly.\n    RuntimeError\n        If the type of the output is not correct.\n    \"\"\"\n    column_split = column.split(\" [\")\n    if len(column_split) != 2:\n        raise RuntimeError(\n            f\"The column name should look like this: '&lt;Name&gt; [&lt;type&gt;]', but it is '{column}'.\"\n        )\n    column_type = column_split[1][:-1]\n    column_name = column_split[0]\n\n    value = row[column]\n    if isinstance(value, str):\n        value = csv_format_type(value=value.strip(), column_type=column_type)\n\n    if check_type(value=value, column_types=[column_type]) or value is None:\n        pass\n    else:\n        raise RuntimeError(\n            f\"The column '{column}' gave a value of type {type(value)} ({value}).\"\n        )\n\n    return column_name, value\n</code></pre>"},{"location":"reference/utils/csv_utils/#utils.csv_utils.csv_read_attributes","title":"<code>csv_read_attributes(csv_path, specific_columns=())</code>","text":"<p>Read all the values from a given CSV file and convert all the values according to the types specified by the header. Some specific columns that have to be in the file can be specified.</p> <p>Parameters:</p> Name Type Description Default <code>csv_path</code> <code>pathlib.Path</code> <p>The path to the CSV file.</p> required <code>specific_columns</code> <code>tuple[str, ...]</code> <p>The mandatory columns. By default ().</p> <code>()</code> <p>Returns:</p> Name Type Description <code>attributes_all</code> <code>list[dict[str, typing.Any]]</code> <p>All the values of all the rows, except the ones given in <code>specific_columns</code>. Stored as dictionaries mapping the actual column name (without the type) to the value converted to the right type.</p> <code>specific_values_all</code> <code>list[tuple[tuple[str, typing.Any], ...]]</code> <p>The values of the columns specified in <code>specific_columns</code>, in the same order. Each element of the list corresponds to one row, in the same order as in <code>attributes_all</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If two columns end up with the same name after removing the type.</p> Source code in <code>python/src/data_pipeline/utils/csv_utils.py</code> <pre><code>def csv_read_attributes(\n    csv_path: Path, specific_columns: tuple[str, ...] = ()\n) -&gt; tuple[list[dict[str, Any]], list[tuple[tuple[str, Any], ...]]]:\n    \"\"\"\n    Read all the values from a given CSV file and convert all the values according to the types specified by the header.\n    Some specific columns that have to be in the file can be specified.\n\n    Parameters\n    ----------\n    csv_path : Path\n        The path to the CSV file.\n    specific_columns : tuple[str, ...], optional\n        The mandatory columns.\n        By default ().\n\n    Returns\n    -------\n    attributes_all: list[dict[str, Any]]\n        All the values of all the rows, except the ones given in `specific_columns`.\n        Stored as dictionaries mapping the actual column name (without the type) to the value converted to the right type.\n    specific_values_all: list[tuple[tuple[str, Any], ...]]\n        The values of the columns specified in `specific_columns`, in the same order.\n        Each element of the list corresponds to one row, in the same order as in `attributes_all`.\n\n    Raises\n    ------\n    RuntimeError\n        If two columns end up with the same name after removing the type.\n    \"\"\"\n    attributes_all: list[dict[str, Any]] = []\n    specific_values_all: list[tuple[tuple[str, Any], ...]] = []\n\n    with open(csv_path, encoding=\"utf-8-sig\") as csvfile:\n        reader = csv.DictReader(csvfile, delimiter=\";\")\n        for row in reader:\n            # Skip empty rows\n            if not any(cell != \"\" for cell in row.values()):\n                continue\n            # Process the specific columns\n            specific_values_list: list[tuple[str, Any]] = []\n            for specific_column in specific_columns:\n                specific_values_list.append(\n                    csv_get_row_value(row=row, column=specific_column)\n                )\n                row.pop(specific_column)\n            specific_values_all.append(tuple(specific_values_list))\n\n            # Load as attributes the columns that contain a type\n            attributes = {}\n            for col_name_type in row.keys():\n                # Skip columns that don't have a type\n                if col_name_type.find(\" [\") == -1:\n                    continue\n                # Add the column and its value to the attributes\n                col_name, col_value = csv_get_row_value(row=row, column=col_name_type)\n                if col_name in attributes:\n                    raise RuntimeError(\n                        f\"Two columns have the same name '{col_name}' in {str(csv_path)}\"\n                    )\n                attributes[col_name] = col_value\n            attributes_all.append(attributes)\n\n    return attributes_all, specific_values_all\n</code></pre>"},{"location":"reference/utils/csv_utils/#utils.csv_utils.string_to_type","title":"<code>string_to_type(type_string)</code>","text":"<p>Return the actual Python type corresponding to the string.</p> <p>Parameters:</p> Name Type Description Default <code>type_string</code> <code>str</code> <p>The type represented as a string.</p> required <p>Returns:</p> Type Description <code>type</code> <p>The actual type.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the given type is unsupported.</p> Source code in <code>python/src/data_pipeline/utils/csv_utils.py</code> <pre><code>def string_to_type(type_string: str) -&gt; type:\n    \"\"\"\n    Return the actual Python type corresponding to the string.\n\n    Parameters\n    ----------\n    type_string : str\n        The type represented as a string.\n\n    Returns\n    -------\n    type\n        The actual type.\n\n    Raises\n    ------\n    NotImplementedError\n        If the given type is unsupported.\n    \"\"\"\n    if type_string == \"str\":\n        real_type = str\n    elif type_string == \"float\":\n        real_type = float\n    elif type_string == \"int\":\n        real_type = int\n    elif type_string == \"bool\":\n        real_type = bool\n    elif type_string.startswith(\"list\"):\n        real_type = list\n    else:\n        raise NotImplementedError(\n            f\"Support for type '{type_string}' is not implemented yet.\"\n        )\n    return real_type\n</code></pre>"},{"location":"reference/utils/geometry_utils/","title":"geometry_utils","text":"<p>Utilities to process geometry (validation, triangulation, fusion, etc).</p> <p>Functions:</p> Name Description <code>fix_polygon_2d</code> <p>Transform an input polygon into one or multiple valid polygons.</p> <code>flatten_trimesh</code> <p>Flatten the mesh on the Z-axis, and triangulate it.</p> <code>merge_trimeshes</code> <p>Merge the given Trimesh objects into a single Trimesh.</p> <code>orient_polygons_z_up</code> <p>Orient the given mesh so that the normal of all its triangles point up.</p> <code>triangulate_linear_ring_2d</code> <p>Triangulate a 2D LinearRing.</p> <code>triangulate_polygon_2d</code> <p>Triangulate a 2D Polygon.</p> <code>triangulate_surface_3d</code> <p>Triangulate a 3D Surface.</p>"},{"location":"reference/utils/geometry_utils/#utils.geometry_utils.fix_polygon_2d","title":"<code>fix_polygon_2d(polygon)</code>","text":"<p>Transform an input polygon into one or multiple valid polygons.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>shapely.Polygon</code> <p>The potentially invalid 2D polygon.</p> required <p>Returns:</p> Type Description <code>list[shapely.Polygon]</code> <p>The valid polygons equivalent to the input polygon.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the operations don't succeed to make valid polygons.</p> Source code in <code>python/src/data_pipeline/utils/geometry_utils.py</code> <pre><code>def fix_polygon_2d(polygon: Polygon) -&gt; list[Polygon]:\n    \"\"\"\n    Transform an input polygon into one or multiple valid polygons.\n\n    Parameters\n    ----------\n    polygon : Polygon\n        The potentially invalid 2D polygon.\n\n    Returns\n    -------\n    list[Polygon]\n        The valid polygons equivalent to the input polygon.\n\n    Raises\n    ------\n    RuntimeError\n        If the operations don't succeed to make valid polygons.\n    \"\"\"\n    polygon = shapely.remove_repeated_points(polygon)\n    if not shapely.is_valid(polygon):\n        valid_geometry = shapely.make_valid(polygon, method=\"structure\")\n    else:\n        valid_geometry = polygon\n    if isinstance(valid_geometry, MultiPolygon):\n        return list(valid_geometry.geoms)\n    elif isinstance(valid_geometry, Polygon):\n        return [valid_geometry]\n    elif isinstance(valid_geometry, LineString):\n        # if valid_geometry.is_closed:\n        #     return [Polygon(shell=valid_geometry)]\n        # else:\n        #     return []\n        return []\n    else:\n        raise RuntimeError(\n            f\"Unexpected output after making the polygon valid: {valid_geometry}\"\n        )\n</code></pre>"},{"location":"reference/utils/geometry_utils/#utils.geometry_utils.flatten_trimesh","title":"<code>flatten_trimesh(mesh, z_value=None)</code>","text":"<p>Flatten the mesh on the Z-axis, and triangulate it.</p> Warning <p>This function is a bit buggy, and the triangulating algorithm sometimes crashes without giving any error message. This seems to be often related to problems in the input that are not well handled by the algorithm, such as duplicate vertices.</p> <p>Parameters:</p> Name Type Description Default <code>mesh</code> <code>trimesh.Trimesh</code> <p>The Trimesh to flatten.</p> required <code>z_value</code> <code>numpy.float64 | None</code> <p>The Z value to assign to all vertices. If None, it is the minimum of the Z values of all vertices in the mesh. By default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>trimesh.Trimesh</code> <p>The flattened Trimesh.</p> Source code in <code>python/src/data_pipeline/utils/geometry_utils.py</code> <pre><code>def flatten_trimesh(\n    mesh: trimesh.Trimesh, z_value: np.float64 | None = None\n) -&gt; trimesh.Trimesh:\n    \"\"\"\n    Flatten the mesh on the Z-axis, and triangulate it.\n\n    Warning\n    -------\n    This function is a bit buggy, and the triangulating algorithm sometimes crashes without giving any error message.\n    This seems to be often related to problems in the input that are not well handled by the algorithm, such as duplicate vertices.\n\n    Parameters\n    ----------\n    mesh : trimesh.Trimesh\n        The Trimesh to flatten.\n    z_value : np.float64 | None, optional\n        The Z value to assign to all vertices.\n        If None, it is the minimum of the Z values of all vertices in the mesh.\n        By default None.\n\n    Returns\n    -------\n    trimesh.Trimesh\n        The flattened Trimesh.\n    \"\"\"\n    try:\n        logging.debug(\"Start flattening\")\n        z_value = np.min(mesh.vertices[:, 2]) if z_value is None else z_value\n        # apad is set to 1\u00a0mm to prevent errors from araising with triangulation\n        # TODO: understand the error better and fix it in a better way?\n        flatten_path_2D: Path2D = mesh.projected(normal=(0, 0, 1), apad=0.001)\n        logging.debug(\"Start triangulating\")\n        vertices, faces = flatten_path_2D.triangulate(\n            **{\"engine\": \"triangle\", \"triangle_args\": \"p\"}\n        )\n        flat_mesh = trimesh.Trimesh(vertices=vertices, faces=faces)\n        flat_mesh.vertices = np.hstack(\n            (flat_mesh.vertices, np.full((flat_mesh.vertices.shape[0], 1), z_value))\n        )\n        orient_polygons_z_up(flat_mesh)\n        return flat_mesh\n    except Exception as e:\n        logging.error(f\"Error during flattening the Trimesh: {e}\")\n        raise e\n</code></pre>"},{"location":"reference/utils/geometry_utils/#utils.geometry_utils.merge_trimeshes","title":"<code>merge_trimeshes(meshes, fix_geometry)</code>","text":"<p>Merge the given Trimesh objects into a single Trimesh. Optionally fix the geometry of the final mesh.</p> <p>Parameters:</p> Name Type Description Default <code>meshes</code> <code>list[trimesh.Trimesh]</code> <p>List of meshes to merge.</p> required <code>fix_geometry</code> <code>bool</code> <p>Whether to apply different operations to fix the mesh.</p> required <p>Returns:</p> Type Description <code>trimesh.Trimesh</code> <p>The merged mesh.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the object obtained from merging is not a Trimesh.</p> Source code in <code>python/src/data_pipeline/utils/geometry_utils.py</code> <pre><code>def merge_trimeshes(\n    meshes: list[trimesh.Trimesh], fix_geometry: bool\n) -&gt; trimesh.Trimesh:\n    \"\"\"\n    Merge the given Trimesh objects into a single Trimesh.\n    Optionally fix the geometry of the final mesh.\n\n    Parameters\n    ----------\n    meshes : list[trimesh.Trimesh]\n        List of meshes to merge.\n    fix_geometry : bool\n        Whether to apply different operations to fix the mesh.\n\n    Returns\n    -------\n    trimesh.Trimesh\n        The merged mesh.\n\n    Raises\n    ------\n    RuntimeError\n        If the object obtained from merging is not a Trimesh.\n    \"\"\"\n    full_mesh = trimesh.util.concatenate(meshes)\n    if not isinstance(full_mesh, trimesh.Trimesh):\n        raise RuntimeError(\"The combination of the meshes isn't a Trimesh.\")\n    if full_mesh.is_empty:\n        logging.debug(\"Empty!\")\n        return full_mesh\n    if fix_geometry:\n        full_mesh.process(validate=True)\n        full_mesh.update_faces(full_mesh.unique_faces())\n        full_mesh.fix_normals()\n        full_mesh.fill_holes()\n    else:\n        full_mesh.process()\n    return full_mesh\n</code></pre>"},{"location":"reference/utils/geometry_utils/#utils.geometry_utils.orient_polygons_z_up","title":"<code>orient_polygons_z_up(mesh)</code>","text":"<p>Orient the given mesh so that the normal of all its triangles point up. The input mesh is expected to be flat, parallel to the x,y plane.</p> Warning <p>This function modifies the mesh directly.</p> <p>Parameters:</p> Name Type Description Default <code>mesh</code> <code>trimesh.Trimesh</code> <p>The input flat mesh.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the mesh has a triangle that is not parallel to the x,y plane, with a difference larger than the threshold used.</p> Source code in <code>python/src/data_pipeline/utils/geometry_utils.py</code> <pre><code>def orient_polygons_z_up(mesh: trimesh.Trimesh) -&gt; None:\n    \"\"\"\n    Orient the given mesh so that the normal of all its triangles point up.\n    The input mesh is expected to be flat, parallel to the x,y plane.\n\n    Warning\n    -------\n    This function modifies the mesh directly.\n\n    Parameters\n    ----------\n    mesh : trimesh.Trimesh\n        The input flat mesh.\n\n    Raises\n    ------\n    RuntimeError\n        If the mesh has a triangle that is not parallel to the x,y plane, with a difference larger than the threshold used.\n    \"\"\"\n    faces = mesh.faces.copy()\n    for i, normal in enumerate(mesh.face_normals):\n        # Check if the face is actually in the x,y plane\n        if not np.all(np.abs(normal[:2]) &lt; 1e-3):\n            raise RuntimeError(\n                f\"A value is larger than expected in absolute value: {np.max(np.abs(normal[:2]))}\"\n            )\n\n        if normal[2] &lt; 0:\n            faces[i, 1], faces[i, 2] = faces[i, 2], faces[i, 1]\n\n    mesh.faces = faces\n</code></pre>"},{"location":"reference/utils/geometry_utils/#utils.geometry_utils.triangulate_linear_ring_2d","title":"<code>triangulate_linear_ring_2d(lring_2d, holes_lrings_2d=None)</code>","text":"<p>Triangulate a 2D LinearRing.</p> <p>Parameters:</p> Name Type Description Default <code>lring_2d</code> <code>shapely.geometry.LinearRing</code> <p>The outer boundary of the 2D LinearRing to triangulate.</p> required <code>holes_lrings_2d</code> <code>list[shapely.geometry.LinearRing] | None</code> <p>The list of 2D LinearRings representing the holes. By default None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>vertices</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>The vertices of the output triangulation.</p> <code>triangles</code> <code>numpy.typing.NDArray[numpy.int64]</code> <p>The triangles of the output triangulation, refering to <code>vertices</code>.</p> Source code in <code>python/src/data_pipeline/utils/geometry_utils.py</code> <pre><code>def triangulate_linear_ring_2d(\n    lring_2d: sg.LinearRing,\n    holes_lrings_2d: list[sg.LinearRing] | None = None,\n) -&gt; Tuple[NDArray[np.float64], NDArray[np.int64]]:\n    \"\"\"\n    Triangulate a 2D LinearRing.\n\n    Parameters\n    ----------\n    lring_2d : sg.LinearRing\n        The outer boundary of the 2D LinearRing to triangulate.\n    holes_lrings_2d : list[sg.LinearRing] | None, optional\n        The list of 2D LinearRings representing the holes.\n        By default None.\n\n    Returns\n    -------\n    vertices: NDArray[np.float64]\n        The vertices of the output triangulation.\n    triangles: NDArray[np.int64]\n        The triangles of the output triangulation, refering to `vertices`.\n    \"\"\"\n    # Check that the holes inputs are correct\n    if holes_lrings_2d is None:\n        holes_lrings_2d = []\n\n    # Prepare the triangulation\n    points_2d = np.array(lring_2d.coords[:-1], dtype=np.float64)[::-1]\n    ring_segments = [(i, (i + 1) % len(points_2d)) for i in range(len(points_2d))]\n\n    for hole_lring in holes_lrings_2d:\n        offset = points_2d.shape[0]\n        hole_points_2d = np.array(hole_lring.coords[:-1], dtype=np.float64)[::-1]\n        ring_segments.extend(\n            [\n                (offset + i, offset + (i + 1) % len(hole_points_2d))\n                for i in range(len(hole_points_2d))\n            ]\n        )\n        points_2d = np.concat((points_2d, hole_points_2d))\n\n    # Remove duplicate vertices\n    tol = 1e-6\n    scale = 1.0 / tol\n    rounded = np.round(points_2d * scale).astype(np.int64)\n\n    # Use a structured array so np.unique can work on rows efficiently\n    dtype = np.dtype([(\"x\", np.int64), (\"y\", np.int64)])\n    structured = rounded.view(dtype).reshape(-1)\n\n    _, uniq_idx, inv_map = np.unique(structured, return_index=True, return_inverse=True)\n\n    previous_len = points_2d.shape[0]\n    points_2d = points_2d[uniq_idx]\n    if points_2d.shape[0] != previous_len:\n        logging.debug(f\"{previous_len} -&gt; {points_2d.shape[0]}\")\n    ring_segments = [inv_map[np.array(segment)] for segment in ring_segments]\n\n    triangulation_input = {\"vertices\": points_2d, \"segments\": ring_segments}\n    # logging.debug(triangulation_input)\n    polygon_2d = sg.Polygon(lring_2d, holes=holes_lrings_2d)\n    # logging.debug(polygon_2d)\n\n    triangulation = tri.triangulate(triangulation_input, \"p\")\n    if \"triangles\" not in triangulation:\n        logging.debug(\"No triangle!\")\n        # logging.debug(f\"{np.array(lring_2d.coords) = }\")\n        # logging.debug(f\"{holes_lrings_2d = }\")\n        return np.empty((0, 2), dtype=np.float64), np.empty((0, 3), dtype=np.int64)\n    vertices = np.array(triangulation[\"vertices\"], dtype=np.float64)\n    triangles = np.array(triangulation[\"triangles\"], dtype=np.int64)\n\n    # Remove triangles that are outside the polygon (especially holes)\n    triangles_to_keep = []\n    polygon_2d = sg.Polygon(lring_2d, holes=holes_lrings_2d)\n    for i, triangle in enumerate(triangles):\n        # Check if the centroid of the triangle is in the polygon\n        v0, v1, v2 = vertices[triangle]\n        centroid = sg.Point((v0 + v1 + v2) / 3)\n        if polygon_2d.contains(centroid):\n            triangles_to_keep.append(i)\n\n    triangles = triangles[triangles_to_keep]\n\n    return vertices, triangles\n</code></pre>"},{"location":"reference/utils/geometry_utils/#utils.geometry_utils.triangulate_polygon_2d","title":"<code>triangulate_polygon_2d(polygon)</code>","text":"<p>Triangulate a 2D Polygon.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>shapely.Polygon</code> <p>The 2D Polygon to triangulate.</p> required <p>Returns:</p> Name Type Description <code>vertices</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>The vertices of the output triangulation.</p> <code>triangles</code> <code>numpy.typing.NDArray[numpy.int64]</code> <p>The triangles of the output triangulation, refering to <code>vertices</code>.</p> <code>valid</code> <code>bool</code> <p>Whether the output is a valid triangulation.</p> Source code in <code>python/src/data_pipeline/utils/geometry_utils.py</code> <pre><code>def triangulate_polygon_2d(\n    polygon: Polygon,\n) -&gt; Tuple[NDArray[np.float64], NDArray[np.int64], bool]:\n    \"\"\"\n    Triangulate a 2D Polygon.\n\n    Parameters\n    ----------\n    polygon : Polygon\n        The 2D Polygon to triangulate.\n\n    Returns\n    -------\n    vertices: NDArray[np.float64]\n        The vertices of the output triangulation.\n    triangles: NDArray[np.int64]\n        The triangles of the output triangulation, refering to `vertices`.\n    valid: bool\n        Whether the output is a valid triangulation.\n    \"\"\"\n    # Return nothing if the ring doesn't have enough points to compute a normal\n    all_points = list(polygon.exterior.coords[:-1])\n    for interior in polygon.interiors:\n        all_points.extend(interior.coords[:-1])\n    unique_points = np.unique(np.concat(all_points), axis=0)\n    if unique_points.shape[0] &lt; 3:\n        return (\n            np.zeros((0, 2), dtype=np.float64),\n            np.zeros((0, 2), dtype=np.int64),\n            False,\n        )\n\n    # Triangulate the polygon\n    holes_lrings_2d = list(polygon.interiors)\n    tri_vertices, tri_faces = triangulate_linear_ring_2d(\n        polygon.exterior,\n        holes_lrings_2d=holes_lrings_2d,\n    )\n\n    return tri_vertices, tri_faces, True\n</code></pre>"},{"location":"reference/utils/geometry_utils/#utils.geometry_utils.triangulate_surface_3d","title":"<code>triangulate_surface_3d(outer_boundary, holes, vertices)</code>","text":"<p>Triangulate a 3D Surface.</p> <p>Parameters:</p> Name Type Description Default <code>outer_boundary</code> <code>numpy.typing.NDArray[numpy.int64]</code> <p>Outer boundary of the Surface, referring to <code>vertices</code>.</p> required <code>holes</code> <code>list[numpy.typing.NDArray[numpy.int64]]</code> <p>Holes of the Surface, referring to <code>vertices</code></p> required <code>vertices</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>The vertices to extract the boundaries from.</p> required <p>Returns:</p> Name Type Description <code>tri_vertices</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>The vertices of the output triangulation.</p> <code>tri_triangles</code> <code>numpy.typing.NDArray[numpy.int64]</code> <p>The triangles of the output triangulation, refering to <code>tri_vertices</code>.</p> <code>valid</code> <code>bool</code> <p>Whether the output is a valid triangulation.</p> Source code in <code>python/src/data_pipeline/utils/geometry_utils.py</code> <pre><code>def triangulate_surface_3d(\n    outer_boundary: NDArray[np.int64],\n    holes: list[NDArray[np.int64]],\n    vertices: NDArray[np.float64],\n) -&gt; Tuple[NDArray[np.float64], NDArray[np.int64], bool]:\n    \"\"\"\n    Triangulate a 3D Surface.\n\n    Parameters\n    ----------\n    outer_boundary : NDArray[np.int64]\n        Outer boundary of the Surface, referring to `vertices`.\n    holes : list[NDArray[np.int64]]\n        Holes of the Surface, referring to `vertices`\n    vertices : NDArray[np.float64]\n        The vertices to extract the boundaries from.\n\n    Returns\n    -------\n    tri_vertices: NDArray[np.float64]\n        The vertices of the output triangulation.\n    tri_triangles: NDArray[np.int64]\n        The triangles of the output triangulation, refering to `tri_vertices`.\n    valid: bool\n        Whether the output is a valid triangulation.\n    \"\"\"\n    # Do nothing if the object is already a triangle\n    if outer_boundary.shape == 3 and len(holes) == 0:\n        tri_vertices = vertices[outer_boundary]\n        tri_faces = np.array([0, 1, 2]).reshape(1, 3)\n        return tri_vertices, tri_faces, True\n\n    # Compute the plane of the surface\n    used_ids = np.unique(np.concatenate([outer_boundary] + holes))\n    unique_points = np.unique(vertices[used_ids], axis=0)\n    plane = Plane3D.from_points(unique_points)\n    if not plane.is_valid:\n        logging.debug(\"Invalid plane!\")\n        return (\n            np.zeros((0, 3), dtype=np.float64),\n            np.zeros((0, 3), dtype=np.int64),\n            False,\n        )\n\n    # Compute the 2D points\n    outer_boundary_2d = plane.project_points(vertices[outer_boundary])\n    holes_2d = [plane.project_points(vertices[hole]) for hole in holes]\n\n    # Create the polygon (repeat the first point for the rings)\n    exterior = np.vstack((outer_boundary_2d, outer_boundary_2d[:1]))\n    interiors = [np.vstack((hole_2d, hole_2d[:1])) for hole_2d in holes_2d]\n    poly = Polygon(shell=exterior, holes=interiors)\n\n    # Fix the polygon in case of problems\n    polys = fix_polygon_2d(polygon=poly)\n\n    # Triangulate all the polygons\n    tri_vertices_2d_all = np.empty((0, 2), dtype=np.float64)\n    tri_faces_all = np.empty((0, 3), dtype=np.int64)\n    worked_all = []\n    for poly in polys:\n        tri_vertices, tri_faces, worked = triangulate_polygon_2d(poly)\n        tri_faces_all = np.vstack(\n            (tri_faces_all, tri_faces + tri_vertices_2d_all.shape[0])\n        )\n        tri_vertices_2d_all = np.vstack((tri_vertices_2d_all, tri_vertices))\n        worked_all.append(worked)\n    worked = any(worked_all)\n\n    # Unproject the points\n    tri_vertices_all = plane.unproject_points(tri_vertices_2d_all)\n\n    return tri_vertices_all, tri_faces_all, worked\n</code></pre>"},{"location":"reference/utils/icon_positions/","title":"icon_positions","text":"<p>Utilities to store and compute 3D icon positions.</p> <p>Classes:</p> Name Description <code>IconPosition</code> <p>Helper class to compute and store positions for icons.</p> <p>Functions:</p> Name Description <code>height_at_xy</code> <p>Compute a value for the height of a mesh at the given x and y coordinates, based on vertices around the given position.</p> <code>icon_position_from_mesh</code> <p>Compute a hopefully good position for an icon for the given mesh.</p>"},{"location":"reference/utils/icon_positions/#utils.icon_positions.IconPosition","title":"<code>IconPosition</code>","text":"<p>Helper class to compute and store positions for icons.</p> Source code in <code>python/src/data_pipeline/utils/icon_positions.py</code> <pre><code>class IconPosition:\n    \"\"\"\n    Helper class to compute and store positions for icons.\n    \"\"\"\n\n    def __init__(self, x: float, y: float, z: float) -&gt; None:\n        self.x = x\n        self.y = y\n        self.z = z\n\n    @classmethod\n    def from_list(cls, xyz: list[float]) -&gt; Self:\n        if len(xyz) != 3:\n            raise ValueError(\n                f\"IconPosition.from_list requires a input of length 3, not '{xyz}'\"\n            )\n        return cls(x=xyz[0], y=xyz[1], z=xyz[2])\n\n    @classmethod\n    def from_mesh(cls, mesh: trimesh.Trimesh, z_offset: float) -&gt; Self:\n        if not isinstance(mesh, trimesh.Trimesh):\n            raise TypeError(\n                f\"IconPosition.from_geometry expects a `MultiSurface` instance, not `{type(mesh)}`.\"\n            )\n\n        pos_array = icon_position_from_mesh(mesh=mesh, z_offset=z_offset)\n        return cls(x=pos_array[0], y=pos_array[1], z=pos_array[2])\n\n    def to_list(self) -&gt; list[float]:\n        return [self.x, self.y, self.z]\n</code></pre>"},{"location":"reference/utils/icon_positions/#utils.icon_positions.height_at_xy","title":"<code>height_at_xy(mesh, xy, radii=[1, 3, 10, 30, 100], z_offset=0.5)</code>","text":"<p>Compute a value for the height of a mesh at the given x and y coordinates, based on vertices around the given position. It selects points in a radius around the queried position and takes the highest value.</p> <p>Parameters:</p> Name Type Description Default <code>mesh</code> <code>trimesh.Trimesh</code> <p>The mesh to compute the height of.</p> required <code>xy</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>The (N, 2) array storing the position to compute the height at.</p> required <code>radii</code> <code>list[float]</code> <p>The radii to try successively if no point is found in the previous one. By default <code>[1, 3, 10, 30, 100]</code>.</p> <code>[1, 3, 10, 30, 100]</code> <code>z_offset</code> <code>float</code> <p>The offset to add to the final value. By default <code>0.5</code>.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>float</code> <p>The final computed height with the offset.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If no point was found after trying all radii.</p> Source code in <code>python/src/data_pipeline/utils/icon_positions.py</code> <pre><code>def height_at_xy(\n    mesh: trimesh.Trimesh,\n    xy: NDArray[np.float64],\n    radii: list[float] = [1, 3, 10, 30, 100],\n    z_offset: float = 0.5,\n) -&gt; float:\n    \"\"\"\n    Compute a value for the height of a mesh at the given x and y coordinates, based on vertices around the given position.\n    It selects points in a radius around the queried position and takes the highest value.\n\n    Parameters\n    ----------\n    mesh : trimesh.Trimesh\n        The mesh to compute the height of.\n    xy : NDArray[np.float64]\n        The (N, 2) array storing the position to compute the height at.\n    radii : list[float], optional\n        The radii to try successively if no point is found in the previous one.\n        By default `[1, 3, 10, 30, 100]`.\n    z_offset : float, optional\n        The offset to add to the final value.\n        By default `0.5`.\n\n    Returns\n    -------\n    float\n        The final computed height with the offset.\n\n    Raises\n    ------\n    RuntimeError\n        If no point was found after trying all radii.\n    \"\"\"\n    # Compute distances from every vertex to the XY query point\n    verts_xy = mesh.vertices[:, :2]\n    dists = np.linalg.norm(verts_xy - xy, axis=1)\n\n    # Keep vertices inside the radius\n    for radius in radii:\n        mask = dists &lt;= radius\n        if np.any(mask):\n            return mesh.vertices[mask, 2].max() + z_offset\n\n    raise RuntimeError(\"No vertex was found in any of the given radii from the point.\")\n</code></pre>"},{"location":"reference/utils/icon_positions/#utils.icon_positions.icon_position_from_mesh","title":"<code>icon_position_from_mesh(mesh, neighbourhood_radii=[1, 3, 10, 30, 100], z_offset=0.5)</code>","text":"<p>Compute a hopefully good position for an icon for the given mesh. Puts a point at the center of the axis-aligned bounding box and computes a height for it based on the points in the mesh that are closest to it.</p> <p>Parameters:</p> Name Type Description Default <code>mesh</code> <code>trimesh.Trimesh</code> <p>The mesh to compute an icon position for.</p> required <code>neighbourhood_radii</code> <code>list[float]</code> <p>The radii to try successively if no point is found in the previous one. By default <code>[1, 3, 10, 30, 100]</code>.</p> <code>[1, 3, 10, 30, 100]</code> <code>z_offset</code> <code>float</code> <p>The offset to add to the final value. By default <code>0.5</code>.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>The final icon position.</p> Source code in <code>python/src/data_pipeline/utils/icon_positions.py</code> <pre><code>def icon_position_from_mesh(\n    mesh: trimesh.Trimesh,\n    neighbourhood_radii: list[float] = [1, 3, 10, 30, 100],\n    z_offset: float = 0.5,\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute a hopefully good position for an icon for the given mesh.\n    Puts a point at the center of the axis-aligned bounding box and computes a height for it based on the points in the mesh that are closest to it.\n\n    Parameters\n    ----------\n    mesh : trimesh.Trimesh\n        The mesh to compute an icon position for.\n    neighbourhood_radii : list[float], optional\n        The radii to try successively if no point is found in the previous one.\n        By default `[1, 3, 10, 30, 100]`.\n    z_offset : float, optional\n        The offset to add to the final value.\n        By default `0.5`.\n\n    Returns\n    -------\n    np.ndarray\n        The final icon position.\n    \"\"\"\n    logging.debug(\"Start computing icon position...\")\n\n    # # Flatten the mesh\n    # flat_mesh = flatten_trimesh(mesh=mesh)\n\n    # Find the centroid\n    bounds = mesh.bounds\n    xy_center = np.array((bounds[0, :2] + bounds[1, :2]) / 2.0, dtype=np.float64)\n    chosen_xy = xy_center\n\n    # Compute a proper Z value\n    chosen_z = height_at_xy(\n        mesh, chosen_xy, radii=neighbourhood_radii, z_offset=z_offset\n    )\n\n    return np.array([chosen_xy[0], chosen_xy[1], chosen_z])\n</code></pre>"},{"location":"reference/utils/plane/","title":"plane","text":"<p>Utilities to compute planes from points and manipulate points between 3D and 2D.</p> <p>Classes:</p> Name Description <code>Plane3D</code> <p>Functions:</p> Name Description <code>normal_from_points</code> <p>Compute the normal of the plane defined by a set of points with PCA.</p>"},{"location":"reference/utils/plane/#utils.plane.Plane3D","title":"<code>Plane3D</code>","text":"<p>Methods:</p> Name Description <code>__init__</code> <p>Plane defined by the equation ax + by + cz + d = 0.</p> <code>from_points</code> <p>Create a plane from an array of points.</p> <code>project_points</code> <p>Project the given 3D points onto the plane, giving 2D coordinates.</p> <code>unproject_points</code> <p>Transforms the given 2D points in the plane's coordinate system back into their 3D coordinates in the main coordinate system.</p> Source code in <code>python/src/data_pipeline/utils/plane.py</code> <pre><code>class Plane3D:\n\n    def __init__(\n        self,\n        a: np.float64,\n        b: np.float64,\n        c: np.float64,\n        d: np.float64,\n        valid: bool = True,\n    ) -&gt; None:\n        \"\"\"\n        Plane defined by the equation ax + by + cz + d = 0.\n\n        Parameters\n        ----------\n        a : np.float64\n        b : np.float64\n        c : np.float64\n        d : np.float64\n        valid : bool, optional\n            Whether the plane is valid and usable. By default True.\n        \"\"\"\n        self.a = a\n        self.b = b\n        self.c = c\n        self.d = d\n        self.is_valid = valid\n\n        if not self.is_valid:\n            return\n\n        self.normal = np.array([a, b, c], dtype=np.float64)\n\n        self._compute_plane_origin()\n        self._compute_plane_basis()\n\n    def _compute_plane_origin(self):\n        n = np.array([self.a, self.b, self.c], dtype=float)\n        denom = np.dot(n, n)\n        if denom == 0:\n            raise ValueError(\"Invalid plane coefficients\")\n        self.origin = -self.d / denom * n\n\n    def _compute_plane_basis(self):\n        # Compute two vectors spanning the plane\n        arbitrary = np.array([1.0, 0.0, 0.0], dtype=np.float64)\n        if np.allclose(arbitrary, np.abs(self.normal)):\n            arbitrary = np.array([0.0, 1.0, 0.0], dtype=np.float64)\n        u = np.cross(self.normal, arbitrary).astype(np.float64)\n        u /= np.linalg.norm(u)\n        v = np.cross(self.normal, u).astype(np.float64)\n\n        self.u = u\n        self.v = v\n\n    @classmethod\n    def from_points(cls, points: NDArray[np.float64]) -&gt; Plane3D:\n        \"\"\"\n        Create a plane from an array of points.\n\n        Parameters\n        ----------\n        points : NDArray[np.float64]\n            An array of 3D points of shape (N, 3).\n\n        Returns\n        -------\n        Plane3D\n            Plane that best fits through the points.\n        \"\"\"\n        # Compute the normal\n        normal, normal_valid = normal_from_points(points)\n        # logging.log(logging.DEBUG, f\"{normal = }\")\n        # logging.log(logging.DEBUG, f\"{normal_valid = }\")\n\n        # Compute the plane parameters\n        a, b, c, d = _plane_abcd_from_point_normal(\n            point=points.mean(axis=0), normal=normal\n        )\n        return cls(a=a, b=b, c=c, d=d, valid=normal_valid)\n\n    def project_points(self, points_3D: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n        \"\"\"\n        Project the given 3D points onto the plane, giving 2D coordinates.\n\n        Parameters\n        ----------\n        points_3D : NDArray[np.float64]\n            An array of 3D points of shape (N, 3).\n\n        Returns\n        -------\n        NDArray[np.float64]\n            An array of shape (N, 2) with the projected 2D points.\n\n        Raises\n        ------\n        RuntimeError\n            If the plane is invalid.\n        \"\"\"\n        if not self.is_valid:\n            raise RuntimeError(\"Cannot use `project_points` with an invalid plane.\")\n        shifted_points_3D = points_3D - self.origin\n        points_projected = np.column_stack(\n            (shifted_points_3D @ self.u, shifted_points_3D @ self.v)\n        )\n        return points_projected\n\n    def unproject_points(self, points_2D: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n        \"\"\"\n        Transforms the given 2D points in the plane's coordinate system back into their 3D coordinates in the main coordinate system.\n        The output points of this function are all on the plane.\n\n        Warning\n        -------\n        This is the inverse of `project_points` ONLY IF the points are actually on the plane.\n\n        Parameters\n        ----------\n        points_2D : NDArray[np.float64]\n            An array of shape (N, 2) containing 2D points in the plane's coordinate\n            system.\n\n        Returns\n        -------\n        NDArray[np.float64]\n            An array of shape (N, 3) containing the 3D coordinates of the given points\n            in the main 3D coordinate system.\n\n        Raises\n        ------\n        RuntimeError\n            If the plane is invalid.\n        \"\"\"\n        if not self.is_valid:\n            raise RuntimeError(\"Cannot use `project_points` with an invalid plane.\")\n        points_unprojected = (\n            points_2D[:, 0:1] * self.u + points_2D[:, 1:2] * self.v + self.origin\n        )\n        return points_unprojected\n</code></pre>"},{"location":"reference/utils/plane/#utils.plane.Plane3D.__init__","title":"<code>__init__(a, b, c, d, valid=True)</code>","text":"<p>Plane defined by the equation ax + by + cz + d = 0.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>numpy.float64</code> required <code>b</code> <code>numpy.float64</code> required <code>c</code> <code>numpy.float64</code> required <code>d</code> <code>numpy.float64</code> required <code>valid</code> <code>bool</code> <p>Whether the plane is valid and usable. By default True.</p> <code>True</code> Source code in <code>python/src/data_pipeline/utils/plane.py</code> <pre><code>def __init__(\n    self,\n    a: np.float64,\n    b: np.float64,\n    c: np.float64,\n    d: np.float64,\n    valid: bool = True,\n) -&gt; None:\n    \"\"\"\n    Plane defined by the equation ax + by + cz + d = 0.\n\n    Parameters\n    ----------\n    a : np.float64\n    b : np.float64\n    c : np.float64\n    d : np.float64\n    valid : bool, optional\n        Whether the plane is valid and usable. By default True.\n    \"\"\"\n    self.a = a\n    self.b = b\n    self.c = c\n    self.d = d\n    self.is_valid = valid\n\n    if not self.is_valid:\n        return\n\n    self.normal = np.array([a, b, c], dtype=np.float64)\n\n    self._compute_plane_origin()\n    self._compute_plane_basis()\n</code></pre>"},{"location":"reference/utils/plane/#utils.plane.Plane3D.from_points","title":"<code>from_points(points)</code>  <code>classmethod</code>","text":"<p>Create a plane from an array of points.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>An array of 3D points of shape (N, 3).</p> required <p>Returns:</p> Type Description <code>utils.plane.Plane3D</code> <p>Plane that best fits through the points.</p> Source code in <code>python/src/data_pipeline/utils/plane.py</code> <pre><code>@classmethod\ndef from_points(cls, points: NDArray[np.float64]) -&gt; Plane3D:\n    \"\"\"\n    Create a plane from an array of points.\n\n    Parameters\n    ----------\n    points : NDArray[np.float64]\n        An array of 3D points of shape (N, 3).\n\n    Returns\n    -------\n    Plane3D\n        Plane that best fits through the points.\n    \"\"\"\n    # Compute the normal\n    normal, normal_valid = normal_from_points(points)\n    # logging.log(logging.DEBUG, f\"{normal = }\")\n    # logging.log(logging.DEBUG, f\"{normal_valid = }\")\n\n    # Compute the plane parameters\n    a, b, c, d = _plane_abcd_from_point_normal(\n        point=points.mean(axis=0), normal=normal\n    )\n    return cls(a=a, b=b, c=c, d=d, valid=normal_valid)\n</code></pre>"},{"location":"reference/utils/plane/#utils.plane.Plane3D.project_points","title":"<code>project_points(points_3D)</code>","text":"<p>Project the given 3D points onto the plane, giving 2D coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>points_3D</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>An array of 3D points of shape (N, 3).</p> required <p>Returns:</p> Type Description <code>numpy.typing.NDArray[numpy.float64]</code> <p>An array of shape (N, 2) with the projected 2D points.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the plane is invalid.</p> Source code in <code>python/src/data_pipeline/utils/plane.py</code> <pre><code>def project_points(self, points_3D: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n    \"\"\"\n    Project the given 3D points onto the plane, giving 2D coordinates.\n\n    Parameters\n    ----------\n    points_3D : NDArray[np.float64]\n        An array of 3D points of shape (N, 3).\n\n    Returns\n    -------\n    NDArray[np.float64]\n        An array of shape (N, 2) with the projected 2D points.\n\n    Raises\n    ------\n    RuntimeError\n        If the plane is invalid.\n    \"\"\"\n    if not self.is_valid:\n        raise RuntimeError(\"Cannot use `project_points` with an invalid plane.\")\n    shifted_points_3D = points_3D - self.origin\n    points_projected = np.column_stack(\n        (shifted_points_3D @ self.u, shifted_points_3D @ self.v)\n    )\n    return points_projected\n</code></pre>"},{"location":"reference/utils/plane/#utils.plane.Plane3D.unproject_points","title":"<code>unproject_points(points_2D)</code>","text":"<p>Transforms the given 2D points in the plane's coordinate system back into their 3D coordinates in the main coordinate system. The output points of this function are all on the plane.</p> Warning <p>This is the inverse of <code>project_points</code> ONLY IF the points are actually on the plane.</p> <p>Parameters:</p> Name Type Description Default <code>points_2D</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>An array of shape (N, 2) containing 2D points in the plane's coordinate system.</p> required <p>Returns:</p> Type Description <code>numpy.typing.NDArray[numpy.float64]</code> <p>An array of shape (N, 3) containing the 3D coordinates of the given points in the main 3D coordinate system.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the plane is invalid.</p> Source code in <code>python/src/data_pipeline/utils/plane.py</code> <pre><code>def unproject_points(self, points_2D: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n    \"\"\"\n    Transforms the given 2D points in the plane's coordinate system back into their 3D coordinates in the main coordinate system.\n    The output points of this function are all on the plane.\n\n    Warning\n    -------\n    This is the inverse of `project_points` ONLY IF the points are actually on the plane.\n\n    Parameters\n    ----------\n    points_2D : NDArray[np.float64]\n        An array of shape (N, 2) containing 2D points in the plane's coordinate\n        system.\n\n    Returns\n    -------\n    NDArray[np.float64]\n        An array of shape (N, 3) containing the 3D coordinates of the given points\n        in the main 3D coordinate system.\n\n    Raises\n    ------\n    RuntimeError\n        If the plane is invalid.\n    \"\"\"\n    if not self.is_valid:\n        raise RuntimeError(\"Cannot use `project_points` with an invalid plane.\")\n    points_unprojected = (\n        points_2D[:, 0:1] * self.u + points_2D[:, 1:2] * self.v + self.origin\n    )\n    return points_unprojected\n</code></pre>"},{"location":"reference/utils/plane/#utils.plane.normal_from_points","title":"<code>normal_from_points(points)</code>","text":"<p>Compute the normal of the plane defined by a set of points with PCA.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>numpy.typing.NDArray[numpy.float64]</code> <p>Set of 3D points (N, 3).</p> required <p>Returns:</p> Type Description <code>numpy.typing.NDArray[numpy.float64]</code> <p>Normal vector (3,).</p> <code>bool</code> <p>Whether the normal is valid (False if the points were collinear for example).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the input points are not 3D.</p> Source code in <code>python/src/data_pipeline/utils/plane.py</code> <pre><code>def normal_from_points(\n    points: NDArray[np.float64],\n) -&gt; tuple[NDArray[np.float64], bool]:\n    \"\"\"\n    Compute the normal of the plane defined by a set of points with PCA.\n\n    Parameters\n    ----------\n    points : NDArray[np.float64]\n        Set of 3D points (N, 3).\n\n    Returns\n    -------\n    NDArray[np.float64]\n        Normal vector (3,).\n    bool\n        Whether the normal is valid (False if the points were collinear for example).\n\n    Raises\n    ------\n    RuntimeError\n        If the input points are not 3D.\n    \"\"\"\n    if points.shape[1] != 3:\n        raise RuntimeError(\"3D points are expected.\")\n    if points.shape[0] &lt; 3:\n        return np.zeros(3), False\n\n    # Center the data\n    centroid = points.mean(axis=0)\n    centered = points - centroid\n\n    # Compute the SVD of the centered coordinates.\n    U, s, Vt = np.linalg.svd(centered, full_matrices=False)\n\n    # The normal is the singular vector associated with the smallest singular value,\n    normal = Vt[-1]\n    normal /= np.linalg.norm(normal)\n\n    # Check if the points seem to be in the same plane:\n    planarity_ratio = (s[0] - s[2]) / s[0]\n    linearity_ratio = (s[0] - s[1]) / s[0]\n    # valid = planarity_ratio &gt; 0.999 and linearity_ratio &lt; 0.999\n    valid = planarity_ratio &gt; 0.999\n    if not valid:\n        logging.log(logging.DEBUG, \"Invalid plane:\")\n        logging.log(logging.DEBUG, f\"{s = }\")\n        logging.log(logging.DEBUG, f\"{planarity_ratio = }\")\n        logging.log(logging.DEBUG, f\"{linearity_ratio = }\")\n        logging.log(logging.DEBUG, f\"{points = }\")\n\n    return normal, valid\n</code></pre>"}]}